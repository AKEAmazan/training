<meta http-equiv='Content-Type' content='text/html; charset=utf-8' /> 
<style>
pre{background:#F8F8FF; border:black dashed 1px; padding:6px}
</style>

TODO corriger les \_

# Index 

* [ Performance et analyse d'apache](#performance) 
       * [ Visualisation de la situation](#perf_view) 
       * [ Simulation de charge sur le serveur](#perf_simulation) 
           * [ Utilisation du logiciel ApacheBench (AB)](#perf_bench_ab) 
               * [ Utilisation du logiciel ApacheBench (AB) avec Authentification](#perf_bench_ab_auth) 
           * [ Utilisation du Siege ](#perf_bench_seige) 
               * [ Utilisation du logiciel Siege  avec Authentification](#perf_bench_siege_auth) 
               * [ Avantage de l'utilisation du logiciel Siege](#perf_bench_siege_plus) 
           * [ Utilisation de JMeter](#perf_bench_jmeter) 
           * [ Utilisation de Ngrinder](#perf_bench_ngrinder) 
       * [ Analyse des performances ](#perf_view) 
           * [ Visualisation des processus Apache](#perf_view_apache_process) 
           * [ Visualisation des pages traité par le processus](#perf_view_apache_process_status) 
           * [ Analyse problème de charge CPU](#perf_view_cpu_prob) 
               * [ Utilisation de mod_cache](#perf_mod_cache) 
               * [ Augmentation de la charge du à un problème d'Input/Output (tmpfs)](#perf_wait_access) 
           * [ Configuration de l'exécution d'apache (Worker vs Prefork)](#perf_conf_worker_prefork) 
               * [ MPM prefork](#perf_prefork) 
                   * [ MPM prefork Optimisation](#perf_prefork_optimisation) 
               * [ MPM worker](#perf_worker) 
                   * [ MPM Worker Optimisation](#perf_worker_optimisation) 
           * [ Amélioration des performances de php](#perf_php) 
               * [ Utilisation en mode cgi (php5-fpm)](#perf_php_php5-fpm) 
               * [ Installation & configuration de php5-fpm](#perf_php_php5-fpm_installation) 
               * [ test de performance avec php5-fpm](#perf_php_php5-fpm_perf) 
               * [ Comparatif avec prefork et mod_php5](#perf_php_php5-fpm_perf_vs_mod_php5) 
* [ Référence :](#Reference) 

# <a name="performance" /> Performance et analyse d'apache

Il est très difficile de faire une section performance, car les problèmes peuvent être très varié. Une configuration peut avoir un impacte d'amélioration signification pour un environnement et dans un autre environnement avoir un impacte négatif. De plus selon le point de vue la perception peut être différente , exemple de propos :

* le sysadmin dit : "Le problème est le code, le développeur à mal codé son truc :P "
* Le développeur dit : "Ça marche très bien sur mon poste , le problème est au niveau du serveur "
* Le chargé de projet : "Les accès au système sont plus nombreux que planifié "

Où est la vérité dans tous ça ? Je vous dirai que la réalité est un mixe dans tous ça , il y a probablement une amélioration du code possible car le serveur est différent du poste de travail du développeur. Le sysadmin doit être en mesure d'ajuster ça configuration pour les applications qui est installé sur la machine. N'oublions pas le chargé de projet :P , il faut être en mesure de réaliser des testes de performance sur le système avant afin de connaître le nombre de client que l'on peut prendre en charge.

Quelles sont les problèmes classiques que nous retrouvons :

* Problème de __DNS__
* La charge sur la machine est trop haute ( utilisation du CPU ) 
* L'utilisation de la mémoire est élevé
* Les pages mettes beaucoup de temps à répondre  , c'est tellement générale que ça ne donne pas beaucoup d'information 
* L'accès aux ressources sur le disque dur est lent 
* Selon la période de la journée, le site réponds difficilement
* L'utilisation de la bande passante est saturé 

## <a name="perf_view" /> Visualisation de la situation

Avant de commencé à mettre des efforts pour corriger le / les problème(s) essayons de les identifier. Évidement nous allons voir quelques applications qui ne touche pas apache, mais qui sont purement système. 
Idéalement vous avez un système de monitoring et d'historique d'utilisation qui vous permet d'identifier la période du problème. Lors que je fais mention de monitoring de fait référence à un système de type [nagios](https://www.nagios.com/) qui permet de recevoir courriel ou __SMS__ lors de problème. Si votre système de monitoring ne vous permet pas de conserver des graphiques sur les valeurs dans le passé , je vous conseille d'en mettre un en place pour pouvoir identifier après coup une période en problème. Vous avez [cacti](http://www.cacti.net/) qui permet de réaliser cette opération. 
Nous y reviendrons probablement , je vais tous de même fournir une liste d'outils qui nous permette de réaliser l'analyse sur le moment sans ces outils.

Débutons avec un problème d'utilisation du CPU.

## <a name="perf_simulation" /> Simulation de charge sur le serveur

En tant lors des formations sur la performance nous terminons avec la simulation de charge cependant si je veux vous présenter les outils avec la configuration que j'ai actuellement uniquement avec mon portable sans client **réelle** ceci risque d'être un peu compliqué. Nous allons donc voir tous de suite la simulation de charge ceci peut être aussi utile en début de projet si vous désirez valider votre application avant de vous lancer en production. 

Nous allons voir plusieurs outils certain plus complexe que d'autre, malheureusement ceci sera encore un survole car pour faire de bon teste de performance il faut que ces derniers soit en lien avec votre application. Ceci vous offrira un point de départ pour réaliser votre configuration.
Nous commencerons par des applications simple et nous monterons en puissance à ce stade nous analyserons uniquement les logs pour voir  les accès par la suite nous regarderons les outils d'analyse de performance pour apache.

L'utilisation des utilitaires présentés par la suite devrons être exécuté sur une autre machine que le serveur. Ceci afin de valider aussi l'ensemble de l'infrastructure réseau. Le comportement en local et à distance peut varier, de plus vos clients seront à distance donc autant simulé le même comportement. Si vous réalisez des testes de performance je vous invite aussi à utiliser plusieurs machines afin de monter en charge le serveur avec plusieurs sources de connexion.

### <a name="perf_bench_ab" /> Utilisation du logiciel ApacheBench (AB)

**ApacheBench** (**ab**) est un programme en ligne de commande pour la mesure de performance et les tests de charge de serveur HTTP. À l'origine conçu pour Apache HTTP Serveur, il est désormais utilisable sur tous les serveurs HTTP classiques. L'application est disponible bien entendu sous GNU/Linux et Windows (probablement Mac). 

Installons l'application :

        $ sudo apt-get install apache2-utils

Débutons avec une petite requête simple nous allons réaliser au total 100 requêtes donc 10 simultanés sur la pages principale du site. Avec l'option **-w** vous pouvez avoir le résultat en format __HTML__  ça peut être pratique: 

        $ ab  -n 100 -c 10 -l https://www.linux202-siteA.com/
        [ ... OUTPUT COUPÉ ... ]
        Benchmarking www.linux202-siteA.com (be patient).....done

        Server Software:        Apache/2.4.7
        Server Hostname:        www.linux202-siteA.com
        Server Port:            443
        SSL/TLS Protocol:       TLSv1.2,ECDHE-RSA-AES256-GCM-SHA384,2048,256

        Document Path:          /
        Document Length:        Variable

        Concurrency Level:      10
        Time taken for tests:   2.263 seconds
        Complete requests:      100
        Failed requests:        0
        Total transferred:      36900 bytes
        HTML transferred:       10000 bytes
        Requests per second:    44.19 [#/sec] (mean)
        Time per request:       226.313 [ms] (mean)
        Time per request:       22.631 [ms] (mean, across all concurrent requests)
        Transfer rate:          15.92 [Kbytes/sec] received

        Connection Times (ms)
                      min  mean[+/-sd] median   max
        Connect:       33  189  77.2    201     456
        Processing:     1   22  19.3     19      86
        Waiting:        0   16  16.5      9      76
        Total:         34  210  82.5    215     457

        Percentage of the requests served within a certain time (ms)
        50%    215
        66%    237
        75%    253
        80%    258
        90%    288
        95%    363
        98%    403
        99%    457
        100%   457 (longest request)


Explication des arguments :

* **-n** : Nombre total de requête qui seront transmise 
* **-c** : Nombre de requête concurrente transmise 
* **-l** : L'application ne va pas rapporter d'erreur si le temps de traitement de la requête n'est pas identique à la première réalisé . Si votre site est dynamique il est fort probable que le temps de traitement varie quelque peu.


Explication du résultat :

        Concurrency Level:      10
        Time taken for tests:   2.263 seconds
        Complete requests:      100
        Failed requests:        0
        Total transferred:      36900 bytes
        HTML transferred:       10000 bytes
        Requests per second:    44.19 [#/sec] (mean)
        Time per request:       226.313 [ms] (mean)
        Time per request:       22.631 [ms] (mean, across all concurrent requests)
        Transfer rate:          15.92 [Kbytes/sec] received

* __Concurrency Level: 10__ : Information sur le nombre de connexion concurrente 
* __Time taken for tests: 2.263 seconds__ : Le temps total du teste de charge
* __Complete requests: 100__ : Le nombre total de requête
* __Failed requests: 0__ : Le nombre de requête en erreur 
* __Total transferred: 36900 bytes__ : La quantité de donnée transmis lors du teste
* __HTML transferred: 10000 bytes__ : La quantité de donnée __HTML__, excluant les images et autres média
* __Requests per second: 44.19 \[#/sec\] (mean)__ : Le nombre de requête par seconde
* __Time per request: 226.313 \[ms\] (mean)__: Le temps requis pris pour chaque requête
* __Time per request: 22.631 \[ms\] (mean, across all concurrent requests)__ : Le temps par requête en gros ceci reprend la valeur mentionné plus tôt divisé par le nombre de requête concurrent.
* __Transfer rate: 15.92 \[Kbytes/sec\] received__ : Le taux de transfert

La seconde partie :

                      min  mean[+/-sd] median   max
        Connect:       33  189  77.2    201     456
        Processing:     1   22  19.3     19      86
        Waiting:        0   16  16.5      9      76
        Total:         34  210  82.5    215     457

* __Connect__: Le temps pris pour établir une connexion au serveur
* __Processing__: Le temps pris pour transmettre les premiers __bytes__ au serveur et recevoir les premiers __bytes__ de réponses
* __Waiting__ : Le temps entre l'envoie du premier __bytes__ de donnée et le dernier __bytes__

#### <a name="perf_bench_ab_auth" /> Utilisation du logiciel ApacheBench (AB) avec Authentification

Nous avons vu précédemment la possibilité de mettre en place un système d'authentification sur des sections du site, nous l'avons fait pour une section d'administrateur ou lors de la mise en place de la solution __WebDav__. Il est donc probable que vous désiriez valider ces sections aussi. 
Si vous avez mis en place une authentification de type apache (__htaccess__) vous pouvez utiliser l'option **-A** :

        $ ab  -n 100 -c 10 -l -A admin:mot_passe  https://www.linux202-siteA.com/admin/

Cependant si vous avez mis en place une authentification dans votre application ceci ne fonctionnera pas , vous avez probablement utilisé une méthode utilisant une session / cookie. Si c'est le cas vous devez utiliser une autre option :

        $ ab  -n 100 -c 10 -l -C '_x3access_session=BAh7CUkiD3Nlc...' https://www.linux202-siteA.com/

REF : http://work.stevegrossi.com/2015/02/07/load-testing-rails-apps-with-apache-bench-siege-and-jmeter/


### <a name="perf_bench_seige" /> Utilisation du Siege 

__ApacheBench__ (ab) est bien mais voyons un autre produit qui offre d'autre possibilité , la combinaison des 2 nous permettra de mieux valider les capacités de notre serveurs. Reprenons globalement le même teste qui fut réalisé avec __ApacheBench__ afin de nous faire la main avec quelque chose de connu, par la suite nous explorons l'avantage de __Siege__.

Cette fois ci le nom du pacquage est plus claire :

        $ sudo apt-get install siege 

Les arguments sont un peu différent d'__ab__ nous allons donc refaire les 100 requêtes totale donc 10 concurrentes. Voici la "formule" avec __siege__.

        $ siege  -r 10 -c 10  https://www.linux202-siteA.com/
        ** SIEGE 3.0.5
        ** Preparing 10 concurrent users for battle.
        The server is now under siege..      done.

        Transactions:                    100 hits
        Availability:                 100.00 %
        Elapsed time:                   6.75 secs
        Data transferred:               0.01 MB
        Response time:                  0.06 secs
        Transaction rate:              14.81 trans/sec
        Throughput:                     0.00 MB/sec
        Concurrency:                    0.89
        Successful transactions:         100
        Failed transactions:               0
        Longest transaction:            0.19
        Shortest transaction:           0.03


Explication des arguments :

* **-r** : Le nombre de requêtes ici 10 
* **-c** : Le de requêtes concurrente ici 10

Résultat nous aurons 10 requête (-r) \* 10 requêtes concurrentes (-c) = 100 Requêtes totales

Le résultat de __siege__ est moins détaillé que __ApacheBench__, bien que ceci peut être suffisant selon le besoin établie. Je pense  que l'information transmise est claire si ce n'est pas le cas m'informer je tenterai de mettre à jour le document. 


#### <a name="perf_bench_siege_auth" /> Utilisation du logiciel Siege  avec Authentification

Tous comme __ApacheBench__ __siege__ est en mesure de gérer l'authentification apache ou d'utiliser un code de __cookie sessions__.

Pour l'authentification de type Apache vous devez éditer / créer le fichier **.siegerc** dans votre répertoire personnel, avec la ligne suivante :

        login = admin:mot_de_passe

Pour l'utilisation de session __cookie__ vous définirez un __header__ avec l'information :

        $ siege  -r 10 -c 10 -H 'Cookie:_x3access_session=BAh7CUkiD3Nlc...'  https://www.linux202-siteA.com/

#### <a name="perf_bench_siege_plus" /> Avantage de l'utilisation du logiciel Siege

À ce stade __siege__ et __ApacheBench__ réalise la même opération voyons ce qui démarque __siege__.
Lors des 2 testes précédent nous réalisions un teste de charge uniquement sur UNE __URL__, __siege__ nous permet de définir un fichier contenant plusieurs __URL__ ceci nous permettant de valider non pas seulement la page principale mais une série de page du site web , car soyons réaliste vos utilisateurs ne se contenterons pas d'une page.

L'option **-f** nous permet de définir une liste d'__URL__ __siege__ va utilisez ses dernières de manière aléatoire pour réaliser les requêtes au site web. Démonstration :

        $ cat sitea_urls.txt 
        https://www.linux202-sitea.com/
        https://www.linux202-sitea.com/info.php
        https://www.linux202-sitea.com/articles/2016/super_validation
        https://www.linux202-sitea.com/app.php

        $ sudo siege  -r 10 -c 10  -f sitea_urls.txt
        ** SIEGE 3.0.5
        ** Preparing 10 concurrent users for battle.
        The server is now under siege..      done.

        Transactions:                    100 hits
        Availability:                 100.00 %
        Elapsed time:                   8.20 secs
        Data transferred:               0.52 MB
        Response time:                  0.10 secs
        Transaction rate:              12.20 trans/sec
        Throughput:                     0.06 MB/sec
        Concurrency:                    1.22
        Successful transactions:         100
        Failed transactions:               0
        Longest transaction:            0.40
        Shortest transaction:           0.03


Si vous consultez le fichier de logs du site web nous voyons clairement le coté aléatoire des requêtes 

        $ tail -f /data/vhosts/siteA/logs/ssl_access.log
        [ ... OUTPUT COUPÉ ... ]
        172.17.0.2 - - [17/Jun/2016:08:12:01 -0400] "GET / HTTP/1.1" 200 2146 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"
        172.17.0.2 - - [17/Jun/2016:08:12:01 -0400] "GET /articles/2016/super_validation HTTP/1.1" 200 2798 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"
        172.17.0.2 - - [17/Jun/2016:08:12:01 -0400] "GET / HTTP/1.1" 200 2146 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"
        172.17.0.2 - - [17/Jun/2016:08:12:01 -0400] "GET /info.php HTTP/1.1" 200 19541 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"
        172.17.0.2 - - [17/Jun/2016:08:12:01 -0400] "GET /info.php HTTP/1.1" 200 19545 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"
        172.17.0.2 - - [17/Jun/2016:08:12:01 -0400] "GET /info.php HTTP/1.1" 200 19539 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"
        172.17.0.2 - - [17/Jun/2016:08:12:02 -0400] "GET /app.php HTTP/1.1" 200 1923 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"
        172.17.0.2 - - [17/Jun/2016:08:12:02 -0400] "GET / HTTP/1.1" 200 2146 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"
        172.17.0.2 - - [17/Jun/2016:08:12:02 -0400] "GET /info.php HTTP/1.1" 200 19538 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"


Tous en utilisant la possibilité d'utiliser une suite d'__URL__ aléatoire nous allons définir un nombre d'utilisateur concurrent pour une période de temps. Nous allons aussi définir un délais entre chaque requête des utilisateurs par défaut le délais entre chaque requêtes est de 1 secondes , cependant pour simulé le temps de "lecture" ou de prise de conscience du contenu nous allons définir 5 secondes entres les requêtes.

Donc 25 utilisateurs concurrent, pendant 5 minutes , avec 5 secondes de délais entre les requêtes pour une période de 5 minutes.

        $ siege -c 25 -t 5M -d 5 -f sitea_urls.txt
        ** SIEGE 3.0.5
        ** Preparing 25 concurrent users for battle.
        The server is now under siege...
        Lifting the server siege...      done.

        Transactions:                   2950 hits
        Availability:                 100.00 %
        Elapsed time:                 299.19 secs
        Data transferred:              13.05 MB
        Response time:                  0.04 secs
        Transaction rate:               9.86 trans/sec
        Throughput:                     0.04 MB/sec
        Concurrency:                    0.44
        Successful transactions:        2950
        Failed transactions:               0
        Longest transaction:            0.36
        Shortest transaction:           0.03

Nous nous retrouvons avec un teste plus représentatif de l'utilisation dans la nature de notre site web, le problème avec cette solution est votre teste n'est pas reproductible. En effet comme le choix des URL est réalisé de manière aléatoire 2 testes même consécutif ne réaliserons pas les même accès, nous pouvons dire que ceci est bien car il est peut probable que vos utilisateurs accèdes toujours dans la même séquence vos pages mais le résultat des chiffres sont plus compliqué à interpréter.


### <a name="perf_bench_jmeter" /> Utilisation de JMeter



REF : 

* http://jmeter.apache.org/

### <a name="perf_bench_ngrinder" /> Utilisation de Ngrinder


REF :

* https://hub.docker.com/r/ngrinder/controller/
* https://github.com/naver/ngrinder/wiki/

## <a name="perf_view" /> Analyse des performances 

Maintenant que nous sommes en mesure de simuler du trafic sur notre serveur nous allons être en mesure de visualiser le comportement de ce dernier. Nous allons voir le comportement d'apache lors de la monté en charge, cette partie de visualisation est aussi importante que la section configuration. Chaque combinaisons serveur / site web étant unique vous devez être en mesure d'identifier le point problématique pour être en mesure de l'améliorer. Il n'y a pas de recette qui s'applique peut importe la sauce. 

### <a name="perf_view_apache_process" /> Visualisation des processus Apache

Commençons par la visualisation des processus Apache, le serveur web peut fonctionner en 2 mode :

* [prefork](https://httpd.apache.org/docs/2.4/fr/mod/prefork.html) : Ce module multi-processus (MPM) implémente un serveur web avec démarrage anticipé de processus. Chaque processus du serveur peut répondre aux requêtes entrantes, et un processus parent contrôle la taille du jeu de processus enfants. Nous avons donc le processus Apache qui démarre généralement sous l'utilisateur **root** afin de pouvoir écouter sur le port 80 et/ou 443 , par la suite les autres processus sont **forké** sous l'utilisateur Apache.
Heu **for** quoi ?? Chaque nouveau processus est démarré suivant le principe de **fork** . La fonction **fork** fait partie des appels système standard d'__UNIX__ (norme __POSIX__). Cette fonction permet à un processus (un programme en cours d'exécution) de donner naissance à un nouveau processus qui est sa copie conforme, par exemple en vue de réaliser un second traitement parallèlement au premier. Un bon moyen de visualiser l'effet d'un **fork** sur un processus est d'imaginer une bactérie qui se coupe en deux. 
En d'autre mot une copie complète du processus avec un nouveau **PID** est généré sur le système, l'ensemble des allocations mémoire réalisé du processus parent sont transmis au processus enfant. 
Apache essaie toujours de maintenir plusieurs processus serveurs __inactifs ou en réserve__, afin de pouvoir traiter les requêtes entrantes. De cette façon, les clients n'ont pas besoin d'attendre le démarrage d'un nouveau processus enfant pour que leurs requêtes puissent être traitées.
La directive [MaxConnectionsPerChild](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#maxconnectionsperchild) permet de contrôler la fréquence à laquelle le serveur recycle ses processus en arrêtant les plus anciens et en en lançant de nouveaux.
* [worker](https://httpd.apache.org/docs/2.4/fr/mod/worker.html) : Ce module multi-processus (MPM) implémente un serveur hybride multi-processus multi-thread. En utilisant les __threads__ pour servir les requêtes, il peut en traiter un grand nombre tout en consommant moins de ressources qu'un serveur à base de processus. Cependant, il conserve une grande partie de la stabilité d'un serveur à base de processus en maintenant plusieurs processus disponibles, chacun de ces derniers possédant de nombreux __threads__. Un processus de contrôle unique (le parent) a pour tâche de lancer les processus enfants. Chaque processus enfant crée un nombre fixe de __threads__ serveurs selon la valeur de la directive __ThreadsPerChild__, ainsi qu'un __thread__ chargé d'attendre les connexions et de les passer à un __thread__ serveur pour traitement au fur et à mesure de leur arrivée.
Le serveur HTTP Apache essaie toujours de maintenir un jeu de __threads__ serveurs inactifs ou en réserve, qui se tiennent prêts à traiter les requêtes entrantes. De cette façon, les clients n'ont pas besoin d'attendre la création d'un nouveau __thread__ ou d'un nouveau processus pour que leurs requêtes puissent être traitées. 
Le gros avantage de ce module est que contrairement au système __fork__ ce n'est pas une copie complète du processus parent qui est dupliqué mais uniquement un processus démarrer, il utilise aussi moins de mémoire car les __threads__ partage un espace mémoire afin d'échanger de l'information sur le serveur. Cependant l'ensemble des module apache ne fonctionne pas tous en mode __threadé__ le plus connue **php** ne fonctionne pas à ce jour (2016) en mode __worker__.


Voici une représentation graphique des 2 modes :

![prefork-vs-worker.png](./imgs/prefork-vs-worker.png)

Je vais me concentré sur le système **mpm_prefork**, je vous laisserai le plaisir si votre système utilise **worker** de réaliser la corrélation avec l'autre mode. 

Visualisons la configuration actuelle du mode __mpm_prefork__ : 

        $ cat /etc/apache2/mods-enabled/mpm_prefork.conf 
        # prefork MPM
        # StartServers: number of server processes to start
        # MinSpareServers: minimum number of server processes which are kept spare
        # MaxSpareServers: maximum number of server processes which are kept spare
        # MaxRequestWorkers: maximum number of server processes allowed to start
        # MaxConnectionsPerChild: maximum number of requests a server process serves

        <IfModule mpm_prefork_module>
            StartServers                     5
            MinSpareServers           5
            MaxSpareServers          10
            MaxRequestWorkers         150
            MaxConnectionsPerChild   0
        </IfModule>

Quand nous démarrons le service **httpd** nous aurons donc 5 processus __apache__ disponible (**StartServers**).

        $ sudo /etc/init.d/apache2 start
        * Starting web server apache2
        * 
        $ ps aux | grep apache
        root        51  0.6  0.9  90420 19460 ?        Ss   17:04   0:00 /usr/sbin/apache2 -k start
        www-data    56  0.0  0.2  90452  5376 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    57  0.0  0.2  90452  5380 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    58  0.0  0.2  90452  5380 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    59  0.0  0.2  90452  5380 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    60  0.0  0.2  90452  5380 ?        S    17:04   0:00 /usr/sbin/apache2 -k start


Si j'accède au site web 1 des processus ci-dessus prendra la tâche et fournira l'information demandé au client. Si nous montons en charge le système va créer d'autre processus pour répondre à la demande . Démonstration, vous pouvez utiliser la commande **top** pour visualiser en direct l'augmentation de processus ...

        [client ]$ ab  -n 100 -c 10 -l https://www.linux202-siteA.com/

        [server ]$ ps aux | grep apache 
        root        51  0.0  0.9  90420 19460 ?        Ss   17:04   0:00 /usr/sbin/apache2 -k start
        www-data    56  0.1  0.4  90512  8432 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    57  0.1  0.4  90512  8432 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    58  0.1  0.4  90512  8432 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    59  0.1  0.4  90512  8432 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    60  0.1  0.4  90512  8432 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    70  5.2  0.4  90512  8432 ?        S    17:10   0:00 /usr/sbin/apache2 -k start
        www-data    71  2.1  0.4  90512  8432 ?        S    17:10   0:00 /usr/sbin/apache2 -k start
        www-data    72  1.7  0.4  90512  8432 ?        S    17:10   0:00 /usr/sbin/apache2 -k start

Donc nous voyons qu'a présent nous avec 9 processus apache.
Soyons un peu plus brutal à présent :

        [client]$ ab  -n 200 -c 20 -l https://www.linux202-siteA.com/
        
        [server]$ ps aux | grep apache
        root        51  0.0  0.9  90420 19460 ?        Ss   17:04   0:00 /usr/sbin/apache2 -k start
        www-data    56  0.2  0.4  90512  8436 ?        S    17:04   0:01 /usr/sbin/apache2 -k start
        www-data    57  0.2  0.4  90512  8436 ?        S    17:04   0:01 /usr/sbin/apache2 -k start
        www-data    58  0.2  0.4  90512  8436 ?        S    17:04   0:01 /usr/sbin/apache2 -k start
        www-data    59  0.2  0.4  90512  8436 ?        S    17:04   0:01 /usr/sbin/apache2 -k start
        www-data    60  0.2  0.4  90512  8436 ?        S    17:04   0:01 /usr/sbin/apache2 -k start
        www-data    70  0.6  0.4  90512  8436 ?        S    17:10   0:01 /usr/sbin/apache2 -k start
        www-data    71  0.6  0.4  90512  8436 ?        S    17:10   0:00 /usr/sbin/apache2 -k start
        www-data    72  0.5  0.4  90512  8436 ?        S    17:10   0:00 /usr/sbin/apache2 -k start
        www-data   130  2.5  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   136  1.9  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   161  6.6  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   164  4.5  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   165  3.5  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   168  2.3  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   169  3.3  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   170  2.3  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   171  5.0  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   174  1.0  0.3  90488  7380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   175  1.0  0.3  90488  7380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   178  1.0  0.3  90488  7380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   179  0.0  0.2  90452  5380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   180  0.0  0.2  90452  5380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   181  0.0  0.2  90452  5380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start 

Nous voyons le nombre de processus Apache monté en flèche , une fois la monté en charge terminé le nombre de processus va réduire tout seule. Ce nombre correspond à la directive __MaxSpareServers__ :

        [server] $ ps aux | grep apache
        root        51  0.0  0.9  90420 19460 ?        Ss   17:04   0:00 /usr/sbin/apache2 -k start
        www-data    56  0.1  0.4  90512  8436 ?        S    17:04   0:01 /usr/sbin/apache2 -k start
        www-data    57  0.1  0.4  90512  8436 ?        S    17:04   0:01 /usr/sbin/apache2 -k start
        www-data    70  0.3  0.4  90512  8436 ?        S    17:10   0:01 /usr/sbin/apache2 -k start
        www-data    72  0.2  0.4  90512  8436 ?        S    17:10   0:00 /usr/sbin/apache2 -k start
        www-data   130  0.3  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   161  0.1  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   164  0.1  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   174  0.0  0.3  90488  7380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   175  0.0  0.3  90488  7380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   181  0.0  0.2  90452  5380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start

En théorie le nombre de processus qu'apache pourrait démarrer correspond  à la directive __MaxRequestWorkers__ , cependant dans mon cas mon portable ne sera plus en mesure de répondre à la charge avant :P. Pourquoi limité le nombre de processus me direz vous ? Si vous êtes __slashdoté__ par exemple donc une augmentation significative de l'accès à votre site web , si le nombre de processus était illimité, dans le cas où votre site web est en mesure de fournir 1000 utilisateurs lors que le 1001 arrive votre serveur ne serait plus en mesure de répondre TOTALEMENT à AUCUN utilisateur. Si vous avez configurer adéquatement votre serveur apache le 1001 utilisateur ne sera pas en mesure d'accéder à la page cependant les 1000 autres n'y verront rien.

### <a name="perf_view_apache_process_status" /> Visualisation des pages traité par le processus

Bon voir les processus apache c'est très bien, ça nous permet de visualiser l'utilisation du serveur mais si nous voyons un processus apache qui prend 100% du __CPU__ ou un nombre énorme de processus comment puis je savoir la source et ou la destination des requêtes ?!?! Certain me dirons de consulter les logs, c'est une TRÈS bonne idée malheureusement si vous avez mutualiser 200 sites sur votre serveur ce sera complètement illisible :-/. Vous pouvez utiliser des systèmes de google analytique ou __piwik__  par contre vous risquez d'avoir quelques problème à faire la corrélation avec les __PID__ du processus sur votre machine :-(. Bon vous vous doutez bien que si je prends autant de temps pour vous dire tous ceci c'est que j'ai une solution :P.

Il existe un module qui permet d'avoir l'information en temps réelle des accès sur le serveur ce dernier est **mod_status**, le module est activé par défaut sur **Ubuntu** mais accessible uniquement localement sur le serveur. Nous allons donc réaliser une petite configuration afin de permettre l'accès depuis notre machine.

        $ sudo vim /etc/apache2/mods-enabled/status.conf
        [... OUTPUT COUPÉ ...]
                <Location /server-status>
                    SetHandler server-status
                    #Require local
                    Require ip 172.17.42.1
                </Location>
        [... OUTPUT COUPÉ ...]

Dans la situation j'ai permis uniquement l'IP 172.17.42.1, faut __reloader__ la configuration apache pour que ce soit actif.

Voici le résultat à froid :

![server-status_empty.png](./imgs/server-status_empty.png)

Nous pouvons déjà voir que la requêtes à cette page fut traité par le **PID** 383. Effectivement si je liste les processus en cours sur la machine : 

        $ ps aux | grep apache
        root       380  0.0  0.9  90420 19552 ?        Ss   17:42   0:00 /usr/sbin/apache2 -k start
        www-data   383  0.0  0.4  90684  8836 ?        S    17:42   0:00 /usr/sbin/apache2 -k start
        www-data   384  0.0  0.2  90452  5424 ?        S    17:42   0:00 /usr/sbin/apache2 -k start

Nous allons voir à présent le comportement lors de l'accès a plusieurs page à l'aide de __siege__ :

        $ cat sitea_urls.txt 
        https://www.linux202-sitea.com/
        https://www.linux202-sitea.com/info.php
        https://www.linux202-sitea.com/articles/2016/super_validation
        https://www.linux202-sitea.com/app.php
        $ siege  -r 20 -c 20  -f sitea_urls.txt


![server-status_siege-20-20.png](./imgs/server-status_siege-20-20.png)

Donc le gros avantage est de pouvoir avoir le détail de ce que réalise un processus, vous avez le __pid__ ainsi que le __VirtualHost__ qui est demandé ainsi que la page demandée. Le tous avec l'adresse __ip__ de provenance , si vous êtes donc victime d'un **DOS** vous êtes en mesure de savoir d'où et surtout vers quelle page.

Nous pouvons voir l'état des demandes de page web à l'aide du système d'identifiant :

        Scoreboard Key:
        "_" Waiting for Connection
        "S" Starting up
        "R" Reading Request,
        "W" Sending Reply
        "K" Keepalive (read)
        "D" DNS Lookup,
        "C" Closing connection
        "L" Logging
        "G" Gracefully finishing
        "I" Idle cleanup of worker
        "." Open slot with no current process

__Anecdote__ : Dans le passé, un client avait un problème de disponibilité de page web, une page dynamique qui été plus que sollicité. Le problème été que le serveur web ne pouvait plus traité les demandes, grâce à la visualisation de la page demandé nous avons pu mettre une page web statique __html__, donc moins lourde à traité mentionnant un problème de disponibilité du service.


### <a name="perf_view_cpu_prob" /> Analyse problème de charge CPU

Pour réaliser l'analyse nous allons installer le pacquage **sysstat** si ceci n'est pas déjà présent .

        $ apt-cache search iostat
        sysstat - system performance tools for Linux
        $ sudo apt-get install sysstat

Pour continuer nous allons mettre une page __php__ non performante , et c'est moi qui l'ai fait :D ... Je voulais une page qui prenne beaucoup de __CPU__. J'ai donc créer une page qui affiche 100 fois un nombre aléatoire de 10000 caractère. On repassera pour la beauté de l'opération, mais le résultat est au rendez-vous le CPU augmente :D.

        $ sudo vim /data/vhosts/siteA/docroot/perf/random.php
        <?php
            function generateRandomString($length = 100000 ) {
                $characters = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';
                $charactersLength = strlen($characters);
                $randomString = '';

                for ($i = 0; $i < $length; $i++) {
                    $randomString .= $characters[rand(0, $charactersLength - 1)];
                }
                return $randomString;
            }

            for ($x = 0 ; $x < 100000 ; $x++ ) {
                if ( $x == 1 ) {
                    echo generateRandomString();
                }
                echo "<br>";
            }

        ?>


Si vous allons sur l'URL : https://www.linux202-sitea.com/perf/random.php , vous aurez une liste de caractère, si vous cliquez pour rafraichir la page d'autre nombre seront présenter.

Nous allons à présent monter en charge le serveur, nous visualiserons le comportement avec la commande __vmstat__ :

        [client]$ ab  -n 200 -c 10 -l https://www.linux202-siteA.com/perf/random.php
        Concurrency Level:      10
        Time taken for tests:   20.719 seconds
        Complete requests:      200
        Failed requests:        0
        Total transferred:      100047400 bytes
        HTML transferred:       100000000 bytes
        Requests per second:    9.65 [#/sec] (mean)
        Time per request:       1035.974 [ms] (mean)
        Time per request:       103.597 [ms] (mean, across all concurrent requests)
        Transfer rate:          4715.49 [Kbytes/sec] received

        Connection Times (ms)
         min  mean[+/-sd] median   max
         Connect:       64  143  36.9    139     293
         Processing:   400  883 129.8    897    1265
         Waiting:      141  545  96.4    551     889
         Total:        540 1026 141.6   1038    1430

        Percentage of the requests served within a certain time (ms)
        50%   1038
        66%   1088
        75%   1116
        80%   1141
        90%   1183
        95%   1224
        98%   1334
        99%   1398
        100%   1430 (longest request)

        $ vmstat 5 20
        procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
        r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
        13  0    940 951656  74600 503100    0    0   266    37  322  525 26  3 70  1  0
        11  0    940 947320  74600 503140    0    0     0     0 1228 3242 94  6  0  0  0
        10  0    940 946772  74624 503164    0    0     0    13 1271 3252 94  6  0  0  0
        11  0    940 955588  74648 503192    0    0     0    12 1172 3224 94  6  0  0  0
         5  0    940 955292  74672 503208    0    0     0    11 1286 3170 94  6  0  0  0
         0  0    940 959788  74696 503236    0    0     0    14  812 1145  8  3 89  0  0
         1  0    940 961992  74720 503248    0    0     0    13  727  899  3  1 96  0  0


Bien entendu vous pouvez aussi utiliser la commande __top__ pour visualiser le comportement , je voulais vous présenter une autre méthode possible qui se script bien et fournit l'ensemble de l'information du système ( Mémoire, __Input/Ouput__ , __cpu__ ...). Si vous désirez utilisé top en script c'est aussi possible avec l'option **-b** pour __batch__  qui est bien pratique.

        # Avant test de charge
        $ uptime
         17:11:59 up 22 min,  1 user,  load average: 0.96, 1.62, 1.42

        # Après test de charge
        $ uptime
         17:13:02 up 23 min,  1 user,  load average: 2.81, 1.96, 1.55

Dans la situation suivant , quelle est la solution ? 

* Corriger le code **php**, ce serait LA solution à mettre en place car clairement il y a un problème, cependant ceci n'est pas toujours possible à notre niveau 

Donc quelle est la solution **de contournement** que l'on peut mettre en place ? 

* Bien entendu ceci dépend de votre application , dans le cas présent la question que je peux me poser : est est-ce que les chiffres aléatoire doivent changé à chaque rafraichissement ? Puis je mettre en place un système de cache afin que cette dernier soit générer uniquement selon un intervalle définie ?

Nous pourrions modifier le code __php__ afin qu'il ajoute un __header__ (en tête) __html__ afin que le client __cache__ le contenu de la page. Ceci est une très bonne solution malheureusement comme le système de __cache__ sera réalisé au niveau du client si j'ai énormément de requête provenant de source multiple , l'opération de __caching__ de la page ne s'effectuera PAS. Du moins pas comme nous l'entendu , la charge sur le serveur sera identique , ça ne solutionnera le problème que si le même client / fureteur accède à la page.

Nous allons donc introduire le système de __cache__ au niveau du serveur , le résultat sera le suivant :

* Le serveur va générer le résultat de la page dynamique __php__ une fois
* Par la suite le serveur apache va cacher le contenu dans ça mémoire 
* Lors des prochaines requêtes peut importe le client le même contenu sera transmis au demandeur
* Un fois le cache expirer la page sera régénéré et caché , ainsi de suite.

Bien entendu le coté négatif de cette opération est que le contenu dynamique ne sera pas généré à chaque requête , mais si l'on y pense un peu si nous prenons un site de nouvelle telle que lemonde.fr , lapresse.ca , ... Si nous utilisons un système de cache de 5 minutes permettant de répondre à des milliers voir millions de requêtes est-ce vraiment critique ?!?! 

#### <a name="perf_mod_cache" /> Utilisation de mod_cache

Le module que nous utiliserons pour nos besoin sera [mod_cache](https://httpd.apache.org/docs/current/fr/mod/mod_cache.html) , nous verrons uniquement un survole, cependant ceci vous offrira la possibilité d'aller plus loin par vous même.

Le système __mod\_cache__ fonction avec 2 mode :


* [mod\_cache\_disk](https://httpd.apache.org/docs/current/fr/mod/mod_cache_disk.html)
implémente un gestionnaire de stockage sur disque. Les en-têtes et corps sont stockés séparément sur le disque dans une structure de répertoires basée sur le condensé md5 de l'URL mise en cache. Plusieurs réponses à contenu négocié peuvent être stockées en même temps, mais la mise en cache de contenus partiels n'est pas supportée par ce module. L'utilitaire htcacheclean permet de lister et de supprimer les URLs mises en cache, et de maintenir le cache en deçà de certaines limites de taille et de nombre d'inodes.
* [mod\_cache\_socache](https://httpd.apache.org/docs/current/fr/mod/mod_cache_socache.html)
Implémente un gestionnaire de stockage basé sur un cache d'objets partagés. Les en-têtes et corps sont stockés ensemble sous une seule clé basée sur l'URL de la réponse mise en cache. Des réponses à contenus multiples négociés peuvent être stockées simultanément, mais ce module ne supporte pas la mise en cache de contenus partiels. 

Nous allons débuter avec le premier c'est très équivalant avec le deuxième donc pas de stresse :D. Attention le nom du module pour caché en mémoire n'est pas le même avec la version apache 2.2.

Nous allons activer les modules qui est déjà disponible sous Ubuntu. 

        $ ls /etc/apache2/mods-available/*cache*
        /etc/apache2/mods-available/authn_socache.load  /etc/apache2/mods-available/file_cache.load
        /etc/apache2/mods-available/cache.load          /etc/apache2/mods-available/socache_dbm.load
        /etc/apache2/mods-available/cache_disk.conf     /etc/apache2/mods-available/socache_memcache.load
        /etc/apache2/mods-available/cache_disk.load     /etc/apache2/mods-available/socache_shmcb.load
        /etc/apache2/mods-available/cache_socache.load
        $ sudo a2enmod cache 
        Enabling module cache.
        To activate the new configuration, you need to run:
          service apache2 restart
        $ sudo a2enmod cache_disk
        Considering dependency cache for cache_disk:
        Module cache already enabled
        Enabling module cache_disk.
        To activate the new configuration, you need to run:
          service apache2 restart
        $ ls /etc/apache2/mods-enabled/*cache*
        cache.load  cache_disk.conf  cache_disk.load  socache_shmcb.load

Regardons le fichier de configuration de cache pour le disque dur qui est définie par défaut sans les commentaires :

        $ cat /etc/apache2/mods-enabled/cache_disk.conf  | grep -v "#" | grep -v "^$"
        <IfModule mod_cache_disk.c>
                CacheRoot /var/cache/apache2/mod_cache_disk
                CacheDirLevels 2
                CacheDirLength 1
        </IfModule>

Nous avons la configuration du répertoire qui sera utilisé pour stocké le contenu mis en cache ceci via la directive [CacheRoot](https://httpd.apache.org/docs/current/fr/mod/mod_cache_disk.html#cacheroot). La directive [CacheDirLevels](https://httpd.apache.org/docs/current/fr/mod/mod_cache_disk.html#cachedirlevels) permet de définir le nombre de niveaux de sous-répertoires que comportera le cache. La directive [CacheDirLength](https://httpd.apache.org/docs/current/fr/mod/mod_cache_disk.html#cachedirlength) permet de définir le nombre de caractères que comportera chaque nom de sous-répertoire de la hiérarchie du cache. 
 
Si nous regardons le répertoire définie par __CacheRoot__ nous constaterons que les permissions sont définie pour l'utilisateur qui exécute le serveur __web__ :

        $ ls -ld /var/cache/apache2/mod_cache_disk
        drwxr-xr-x 2 www-data www-data 4096 Jan 14 12:46 /var/cache/apache2/mod_cache_disk

Si vous optez pour changer cette configuration n'oubliez pas d'ajuster les configurations en conséquences. 

À ce stade même si je refait un teste de charge j'aurais exactement le même comportement qu'avant car bien que les modules sont chargé et configurer "globalement" aucun serveur virtuel ne l'a d'activer !! 
Nous allons donc l'activer pour le serveur virtuel __siteA__.

        $  sudo vim /etc/apache2/sites-enabled/siteA-ssl.conf 
        [... OUTPUT COUPE ...]
                Alias "/cm-images" "/data/vhosts/common/images"

                # Mise en cache de tous les contenus
                CacheEnable  disk  /

                <Directory /data/vhosts/siteA/docroot/>
                    Options none
                    AllowOverride ALL
                    Require all granted
                </Directory>
                                                                                                
        [... OUTPUT COUPE ...]

On valide la configuration et on redémarre, je dois faire un __restart__ , car il y a des modules à charger.

        $ sudo apachectl configtest && sudo /etc/init.d/apache2 restart
        Syntax OK
         * Restarting web server apache2
         ...done.

Nous avons activé le cache et réalisé le redémarrage d'apache , allons sur les pages du site . 

* https://www.linux202-sitea.com/perf/random.php
* https://www.linux202-sitea.com/

Avec la commande **htcacheclean** vous pouvez voir le contenu qui est mis en cache :

        $ sudo htcacheclean -A -p /var/cache/apache2/mod_cache_disk/
        https://www.linux202-sitea.com:443/Free_Software_Foundation_logo.png? 620 37866 200 0 1466682926812864 1466769326812864 1466682926812463 1466682926812864 1 0
        https://www.linux202-sitea.com:443/index.html? 612 109 200 0 1466682926780187 1466769326780187 1466682926779031 1466682926780187 1 0
        $ sudo htcacheclean -a -p /var/cache/apache2/mod_cache_disk/
        https://www.linux202-sitea.com:443/Free_Software_Foundation_logo.png?
        https://www.linux202-sitea.com:443/index.html?

**ATTENTION** : N'oubliez pas d'utiliser la commande avec __sudo__ sinon votre utilisateur n'ayant pas la permissions d'accéder au contenu vous aurez un résultat VIDE. 

**heuu**  pourquoi on ne voit pas la page __PHP__ dans le système la liste des page qui caché ?!?! 
Nous allons devoir mettre une petite modification dans la page __php__, nous allons devoir définir des en-tête (__header__) __HTML__ . Voici ce que nous allons rajouter :

        $ sudo vim /data/vhosts/siteA/docroot/perf/random.php
        <?php
        header("Cache-Control: must-revalidate, max-age=3600");
        header("Vary: Accept-Encoding");
        ?>
        <?php
        function generateRandomString($length = 100000) {
        [... OUTPUT COUPÉ ...]

Nous avons 2 en-tête :
TODO : a completer

* *Cache-Control: must-revalidate, max-age=3600** : 
* __Vary: Accept-Encoding__ :

On valide :D, on retourne sur la page et on réutilise la commande  :

        $ sudo htcacheclean  -a -p /var/cache/apache2/mod_cache_disk/
        https://www.linux202-sitea.com:443/perf/random.php
        [... OUTPUT COUPÉ ...]


C'est le temps de refaire un test de performance :D.

        [client]$ ab  -n 200 -c 10 -l https://www.linux202-siteA.com/perf/random.php
        Concurrency Level:      10
        Time taken for tests:   4.369 seconds
        Complete requests:      200
        Failed requests:        0
        Total transferred:      2134200 bytes
        HTML transferred:       2080000 bytes
        Requests per second:    45.78 [#/sec] (mean)
        Time per request:       218.458 [ms] (mean)
        Time per request:       21.846 [ms] (mean, across all concurrent requests)
        Transfer rate:          477.02 [Kbytes/sec] received

        Connection Times (ms)
         min  mean[+/-sd] median   max
         Connect:       34  190  86.2    209     328
         Processing:     1   20  18.1     14      93
         Waiting:        1   13  14.2      9      79
         Total:         35  210  94.7    239     341

        Percentage of the requests served within a certain time (ms)
         50%    239
         66%    283
         75%    297
         80%    302
         90%    313
         95%    320
         98%    325
         99%    330
        100%    341 (longest request)

        $ uptime
        # avant 
         17:25:22 up 35 min,  1 user,  load average: 0.70, 0.85, 1.06
        $ vmstat 5 20
         procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
          r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
          1  0    940 877884  75524 520964    0    0   174    28  365  604 25  3 71  1  0
         10  0    940 875124  75524 520992    0    0     0     1  844 1999 64  4 31  0  0
          0  0    940 876540  75548 521004    0    0     0    30  855 1650 33  4 64  0  0 

        # Apres 
        $ uptime
         17:26:16 up 36 min,  1 user,  load average: 1.06, 0.96, 1.09

On peut dire que ça MARCHE :D , woot !! Bon c'est pas une raison pour programmer comme un porc ;-).

Je vous ai dit ce n'est qu'une introduction au système nous allons tous de même prendre le temps d'exploirer un peu les options disponible on est dedans faut en profiter :D.

Quand nous activons un système de **cache** la première question que l'on se pose souvent est combien de temps le système va caché l'information ?!?! Ceci est définie par la directive [CacheDefaultExpire](https://httpd.apache.org/docs/current/fr/mod/mod_cache.html#cachedefaultexpire)

![CacheDefaultExpire-screenshot.png](./imgs/CacheDefaultExpire-screenshot.png)

Comme vous pouvez le voir la valeur par défaut est 3600 secondes , mais j'aimerai surtout porter votre attention sur le lieu où peut être définie cette directive , le context :    configuration du serveur, serveur virtuel, répertoire, .htaccess.

Comme vous pouvez le constater ceci peut être sur-définie à plusieurs lieux selon le besoin !!

L'autre intérogation qui peut être soulever est , ouin mais moi je veux pas que TOUS mon site web soit caché , c'est juste une section qui me pose problème ... 

Effectivement pour la démonstration j'ai activé le cache pour l'ensemble du site mais regardons la directive [CacheEnable](https://httpd.apache.org/docs/current/fr/mod/mod_cache.html#cacheenable). 

![CacheEnable-screenshot.png](./imgs/CacheEnable-screenshot.png)

Encore une fois je vous pointe la ligne **contexte** qui indique une liste non négligeable où nous pouvons activer le mode de caching. 

Bon pour les personnes qui veulent l'activer pour un répertoire mais pas un fichier , oui il y a des besoins parfois comme ça :P . La directive [CacheDisable](https://httpd.apache.org/docs/current/fr/mod/mod_cache.html#cachedisable) est la pour ça encore une fois la liste des lieux où ceci peut être définie est conséquente au besoin ...

![CacheDisable-screenshot.png](./imgs/CacheDisable-screenshot.png)

Conformément à la définition de la directive vous pouvez l'utiliser comme suit :

        <Location "/foo">
            CacheDisable on
        </Location>
        
        # Ou
        CacheDisable "/path/url/fichier/toto.html"

Je ne couvrirai pas ici le module pour caché en mémoire le concept étant similaire je vais continuer pour couvrir plus de matière dans le cas où vous désiriez que je rajoute cette section SVP le dire :D.


#### <a name="perf_wait_access" /> Augmentation de la charge du à un problème d'Input/Output (tmpfs)

Bon nous avons corrigé le problème de charge du CPU , comme nous avons pu le constater lors de l'exemple précédent la charge du CPU été principalement du à une augmentation du pourcentage CPU utilisateur. Nous générions un processus qui générais un nombre aléatoire (poche :P) ce qui avait comme conséquence d'augmenter la charge .

         procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
        r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
        13  0    940 951656  74600 503100    0    0   266    37  322  525 26  3 70  1  0
        11  0    940 947320  74600 503140    0    0     0     0 1228 3242 94  6  0  0  0
        10  0    940 946772  74624 503164    0    0     0    13 1271 3252 94  6  0  0  0

Comme  nous pouvons le voir ci-dessus l'augmentation est sous la colonne **US** pour la section CPU.
Voyons un autre cas de figure l'augmentation de la charge mais cette fois dû à un problème de **wait-access** (**WA**), généralement causé par un accès intensif d'écriture ou de lecture du disque dur. 

Je vais créer un fichier texte de 27 __Megs__ nommé __data.dtd__ :

        $ pwd
        /data/vhosts/siteA/docroot/perf
        $ tail data.dtd 
        2016-06-13 08:42:31 status unpacked sysstat:i386 10.2.0-1
        2016-06-13 08:42:31 status unpacked sysstat:i386 10.2.0-1
        2016-06-13 08:42:31 status unpacked sysstat:i386 10.2.0-1
        2016-06-13 08:42:31 status unpacked sysstat:i386 10.2.0-1
        2016-06-13 08:42:31 status unpacked sysstat:i386 10.2.0-1
        2016-06-13 08:42:31 status half-configured sysstat:i386 10.2.0-1
        2016-06-13 08:42:32 status installed sysstat:i386 10.2.0-1
        2016-06-13 08:42:32 trigproc libc-bin:i386 2.19-0ubuntu6 <none>
        2016-06-13 08:42:32 status half-configured libc-bin:i386 2.19-0ubuntu6
        2016-06-13 08:42:32 status installed libc-bin:i386 2.19-0ubuntu6
        $ du -hs data.dtd
        27M     data.dtd

Je vais créer un fichier __php__ qui va lire et écrire ce fichier sous un autre nom  puis le supprimer :

        $ sudo vim /data/vhosts/siteA/docroot/perf/io-file.php
        <?php

        function gen_io($id=0,$data="") {
            
            $file_name="./tmp/test".$id.".txt";
            $file = fopen($file_name,"w");
            echo fwrite($file,$data);
            fclose($file);
            unlink($file_name);
        }
        
        $file_data = fopen("data.dtd","r");
        $data = fread($file_data,filesize("data.dtd"));

        for ($x = 0 ; $x < 100000; $x++ ) {
            if ($x == 1 ) {
                echo gen_io($x,$data);
            }
            echo "<br>";
            }

        fclose($file_data);

        ?> 

        $ sudo mkdir /data/vhosts/siteA/docroot/perf/tmp
        $ sudo chown www-data  /data/vhosts/siteA/docroot/perf/tmp

Comme il y a écriture sur le disque dur , je ne veux pas que ma page soit caché sinon le système ne réalisera pas l'opération à chaque accès au site :-/ . Donc l'option de mise en cache avec __mod\_cache__ n'est pas une option dans le cas présent je désactive donc l'option . 

        $ head -30  /etc/apache2/sites-enabled/siteA-ssl.conf

        <VirtualHost 172.17.0.1:443>
                ServerAdmin webmaster@localhost
                ServerName www.linux202-siteA.com
                ServerAlias linux202-siteA.com
                ServerAlias toto.linux202-siteA.com

                DocumentRoot /data/vhosts/siteA/docroot/

                Alias "/cm-images" "/data/vhosts/common/images"

                # Mise en cache de tous les contenus
                #CacheEnable  disk  /
                #CacheIgnoreCacheControl On
                #CacheDefaultExpire 3600

        [... OUTPUT COUPÉ ...]

On redémarre le service apache et on va faire un test

        $ sudo apachectl configtest && sudo /etc/init.d/apache2 restart

Je vais réutiliser la commande __ab__ pour charger le serveur et nous allons visualiser le comportement avec __vmstat__ sur le serveur.

        [client]$ ab  -n 200 -c 10 -l https://www.linux202-siteA.com/perf/io-file.php
        Document Path:          /perf/io-file.php
        Document Length:        Variable

        Concurrency Level:      10
        Time taken for tests:   66.105 seconds
        Complete requests:      200
        Failed requests:        0
        Total transferred:      80040200 bytes
        HTML transferred:       80002000 bytes
        Requests per second:    3.03 [#/sec] (mean)
        Time per request:       3305.268 [ms] (mean)
        Time per request:       330.527 [ms] (mean, across all concurrent requests)
        Transfer rate:          1182.42 [Kbytes/sec] received

        Connection Times (ms)
                      min  mean[+/-sd] median   max
        Connect:       34  130  64.4    128     338
        Processing:   260 3153 1847.1   2666    8556
        Waiting:      205 2879 1841.3   2405    8336
        Total:        295 3283 1841.0   2767    8675

        Percentage of the requests served within a certain time (ms)
         50%   2767
         66%   3643
         75%   4174
         80%   4630
         90%   5822
         95%   7789
         98%   8035
         99%   8477
        100%   8675 (longest request)

        [server]$ vmstat 2 30 
        procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
        r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
         1  0   3280 369692  72788 1029732    0    1   186  1194  337  594 10  5 82  3  0
        10  0   3280 238252  72796 1050980    0    0    50    60  533  765 18 12 70  0  0
         7  0   3280 224696  72800 1056976    0    0    22 26014 5236 11333 35 62  4  0  0
         0 12   3784  52768  72800 1071464   16  252    62 47898 4806 10102 33 61  0  6  0
         3 13   4652  52848  72816 1065776   12  434    60 36304 6132 13241 11 27  0 62  0
         2  9   4888  55556  72148 1062744    0  118    20 34436 1815 3370 22 22  0 56  0
         0 10   5088  53288  69948 1068768    8  100    16 17190 4251 8884  9 14  0 77  0
         2 12   5092 108800  69980 1051752    0    2    20 45946 1419 3885  7 18  1 73  0
         9  1   9412  95056  70020 1059816    0 2160     0 20222 1549 5115  8 13  4 75  0
         0  3   9412  72108  70044 1056564    0    0     4 36604 1299 5678 28 32  0 40  0
         6  0   9512  50720  70060 1078776    0   50     0 41082 4313 10174  6 32  2 60  0
        11  0   9792  69936  70060 1058804    0  140     0 63094 4520 10074 38 60  1  1  0
         0  4   9792  58196  70072 1064724    0    0     0 59588 5369 12786 33 54  1 13  0
        11  0   9792 154456  70088 1055740    0    0     4 29520 2257 8491 12 19  0 68  0
        10  1  10324 147376  67184 1047248    0  266     8 68910 4080 8758 37 57  2  4  0
         0  6  10324  77544  67192 1054612    0    0     6 15918 4640 10404 27 46  0 27  0
         8  2  11644  54444  62904 1084604    0  660    10 41374  955 7323 10 25 14 52  0
         0  5  11968  68560  62232 1067420    0  162     4 20014 3465 8940 30 37  0 33  0
         0  2  12224  95116  62244 1047644    0  128     8 67342 2957 6338 34 57  1  8  0
         2  5  13148  51240  62248 1091084    0  462     2 59418 2167 5202 16 27  1 56  0
         0  3  13256  51636  62256 1090584    0   54     0 11078  484  442  2  1  0 97  0
         6  0  13616 157088  58512 1040012    0  180    12 37504 4452 9477 30 43  0 27  0
         0  7  13620  48864  58148 1100000    0    2    14 59066 3285 7892 26 55  0 19  0
         7  9  14476 160316  57192 1059464    0  428    98 52044 4935 30204 24 33  0 43  0
         0 10  14476  58264  57192 1088112    0    0    18  3938 2510 4311  5 18  0 77  0
         0  7  19244  67108  49160 1087016    0 2384     4 60674 3020 8848 26 45  0 29  0
         0  4  19244  62888  49164 1097100    0    0     0 18604  800 1125  3  2  0 95  0
         8  3  19244 120060  49208 1074256    0    0   140 31384 1019 5032 26 29  0 44  0
         1  6  19244  64604  49224 1107128    0    0     0 71612 2090 12644 36 57  1  6  0
         2  3  20540  53464  39044 1121280    0  648     0 21408 5930 12650  3 14  0 83  0
         $ uptime
         17:22:34 up 27 min,  1 user,  load average: 9.56, 3.39, 1.67


La question est comment puis je corriger ce problème, la mise en cache n'est pas une option car il faut que l'écriture soit réaliser à chaque appel. Je ne peux pas fournir une page pré généré au client, encore une fois il est possible probablement de corriger le problème au niveau du code (yeahhh I'm a sysadmin , so the problem is the code :P ) . Bon quelle solution de contournement s'offre à moi ?!?!
Dans le cas présent ce pourrait être aussi un accès réseaux sur un disque partagé ou autre ... Soyons imaginatif :D.

La première idée que l'on se dit faut un __SSD__ , c'est une très bonne idée quelle est la taille requis ?!?! Et vous avez combien de serveur qui doivent avoir se __SSD__ de présent ? Imaginons que ces fichiers soit des fichiers "temporaire" de traitement donc vous auriez besoin de 2 ou 3 __Gig__ sur chaque serveur , avec un __cluster__ de 30 machines. 
Le prix des __SSD__ pour les serveurs sont très chères et malheureusement le __SSD__ n'est pas optimal pour l'écriture la longévité des __HD__ sont considérablement impacté.

La deuxième idée pourquoi on l'écrit pas dans la mémoire ... Le script __php__ va conservé l'information en mémoire et faire tous de suite le traitement ... Super idée mais est-ce que le processus suivant est réalisé par la page __php__ ?? Est-ce un processus qui fait le traitement et combien de temps ce dernier prends ? Est-ce vraiment envisageable de gardé l'utilisateur le temps des 2 traitements ?!? Probablement pas .

Voici ma proposition, mettre en place un faux répertoire qui sera en fait dans la mémoire du système , résultat le temps d'écriture est SUPER performant car effectué en mémoire. Le fichier sera disponible sur le système de fichier comme un fichier normale et pourra donc être traité par une autre application le temps venu. 
**Le point négatif**: Si le serveur **crash** les données sont perdu , yep rien n'est parfait :P .

Voyons le résultat , mis en place de la solution : 

        $ sudo vim /etc/fstab 
        [... OUTPUT COUPÉ ...]
        tmpfs /data/vhosts/siteA/docroot/perf/tmp tmpfs   nodev,nosuid,size=1G          0  0

Je configure le service **tmpfs** afin qu'il soit définie pour le répertoire __/data/vhosts/siteA/docroot/perf/tmp__ je lui alloué __1 Gig__ de mémoire maximum. __Mountons__ ce dernier.

        $ sudo mount /data/vhosts/siteA/docroot/perf/tmp
        $ sudo mount | grep perf
        tmpfs on /data/vhosts/siteA/docroot/perf/tmp type tmpfs (rw,nosuid,nodev,relatime,size=1048576k)

On refait un test ?? 


        [client] $ ab  -n 200 -c 10 -l https://www.linux202-siteA.com/perf/io-file.php
        Document Path:          /perf/io-file.php
        Document Length:        Variable

        Concurrency Level:      10
        Time taken for tests:   28.298 seconds
        Complete requests:      200
        Failed requests:        0
        Total transferred:      80040200 bytes
        HTML transferred:       80002000 bytes
        Requests per second:    7.07 [#/sec] (mean)
        Time per request:       1414.915 [ms] (mean)
        Time per request:       141.492 [ms] (mean, across all concurrent requests)
        Transfer rate:          2762.15 [Kbytes/sec] received

        Connection Times (ms)
                      min  mean[+/-sd] median   max
        Connect:       38  145  41.2    140     255
        Processing:   584 1258 196.2   1267    1685
        Waiting:      399  946 166.2    955    1299
        Total:        693 1402 211.1   1403    1885

        Percentage of the requests served within a certain time (ms)
        50%   1403
        66%   1491
        75%   1557
        80%   1592
        90%   1660
        95%   1741
        98%   1834
        99%   1840
        100%   1885 (longest request)


        [server] $ $ vmstat 2 40
        procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
        r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
        1  0  21452 331592  35516 1115720    0    4   117  1266  329  583 13  4 79  3  0
        10  0  21532 100284  32940 1121244    0   40    12    40 3836 7251 27 49 24  0  0
        10  0  21768 216136  32940 1086536    0  118     0   118 2377 3998 47 54  0  0  0
        10  0  21768  90072  32948 1111180    0    0     0     6 1966 4121 43 57  0  0  0
        9  0  21768  67004  32972 1128720    0    0     0    30 3253 6686 45 55  0  0  0
        13  0  22488 173208  32972 1080800    0  360     0   360 3488 6753 47 53  0  0  0
        11  0  22488 237528  32996 1090832    0    0     0    30 4113 8468 49 50  1  0  0
        7  0  22488  96588  32996 1094072    0    0     0     8 1474 3155 43 57  0  0  0
        10  0  22664 155992  32448 1074988    0   88     0    88 1934 4156 47 53  0  0  0
        6  0  22664 183056  32472 1059836    0    0     0    28 1299 2791 47 53  0  0  0
        9  0  22664 130136  32472 1076684    0    0     0     0 4219 8722 41 59  0  0  0
        9  0  22664 222444  32496 1063548    0    0     0    30 2267 4985 50 50  0  0  0
        8  0  22664 111852  32496 1081300    0    0     0     0 3195 6426 41 59  0  0  0
        10  0  22664 160976  32496 1061252    0    0     0     0 3926 8204 44 56  0  0  0
        10  0  22664 225652  32520 1088308    0    0     0    28 3439 7062 49 51  0  0  0  
        $ uptime
         17:39:35 up 44 min,  1 user,  load average: 2.86, 1.25, 1.10


Nous le voyons clairement, l'accès au disque est resté à 0 tous le long du processus , la charge sur le CPU est monté mais uniquement à cause des processus utilisateur, mais beaucoup moins. Le résultat du testes de charge est beaucoup mieux.

Mais je le répète, si vous utilisez cette technique vous devez faire une copie ou un traitement des fichiers qui sont TEMPORAIRE . S'il y a crash il y a perte de donnée , bien entendu vous pourriez mettre tous votre site web en mémoire ceci augmentera la performance du serveur :D.

### <a name="perf_conf_worker_prefork" /> Configuration de l'exécution d'apache (Worker vs Prefork)

Lors de la présentation des processus apache j'ai fait mention de 2 modes disponibles avec le système de __prefork__ et avec le système de __Thread__. Ceci était une présentation simple afin d'informer de la situation nous allons maintenant voir plus en détail les 2 modes , nous avons débuter avec la configuration par défaut pour la présentation, nous allons la manipulé à présent.


#### <a name="perf_prefork" /> MPM prefork

Telle que mentionné lors de la présentation précédent le système de __prefork__ , __fork__ un nouveau processus apache pour faire la gestion des nouvelles requêtes. Lors du __Fork__ une copie du processus parent est réalisé avec sont pile mémoire, ceci est le système originale mis en place avec apache, donc l'ensemble des modules fonctionne avec ce mode , ce qui n'est pas vrai avec l'autre système.

Un processus de contrôle unique a pour tâche de lancer les processus enfants qui attendent les connexions et les traitent au fur et à mesure qu'elles arrivent. Apache __httpd__ essaie toujours de maintenir plusieurs processus serveurs inactifs ou en réserve, afin de pouvoir traiter les requêtes entrantes. De cette façon, les clients n'ont pas besoin d'attendre le démarrage d'un nouveau processus enfant pour que leurs requêtes puissent être traitées.

Le processus parent est en général démarré en tant que __root__ sous Unix afin de pouvoir se mettre à l'écoute sur le port 80, les processus enfants sont lancés par Apache __httpd__ sous un utilisateur avec privilèges restreints. On peut contrôler les privilèges accordés aux processus enfants d'Apache __httpd__ à l'aide des directives **User** et **Group**. Les processus enfants doivent être en mesure de lire tous les contenus destinés à être servis, mais leurs privilèges doivent être aussi bas que possible.

Les directives [StartServers](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#startservers), [MinSpareServers](https://httpd.apache.org/docs/2.4/fr/mod/prefork.html#minspareservers), [MaxSpareServers](https://httpd.apache.org/docs/2.4/fr/mod/prefork.html#maxspareservers) et [MaxRequestWorkers](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#maxrequestworkers) permettent de contrôler la manière dont le processus parent crée les processus enfants pour traiter les requêtes. Les sites qui doivent traiter plus de 256 requêtes simultanées doivent augmenter la valeur de [MaxRequestWorkers](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#maxrequestworkers), alors que les sites dont la ressource mémoire est limitée doivent la diminuer afin d'éviter une __hyperactivité__ du serveur (utilisation excessive de la mémoire virtuelle sur disque). 

Nous allons analyser la configuration actuelle : 

        $ cat /etc/apache2/mods-enabled/mpm_prefork.conf
        [ ... OUTPUT COUPÉ ... ]
        <IfModule mpm_prefork_module>
                StartServers              5
                MinSpareServers           5
                MaxSpareServers          10
                MaxRequestWorkers       150
                MaxConnectionsPerChild    0
        </IfModule>
        [ ... OUTPUT COUPÉ ... ]


* **StartServers**

    ![StartServers-screenshot.png](./imgs/StartServers-screenshot.png)

    Définie le nombre de processus qui seront démarrer lors de l'initialisation du service , avec le module __preforf__ la valeur par défaut est **5**. Cette valeur est généralement assez basse , l'objectif est d'être en mesure de répondre au première requêtes rapidement, par la suite lors de la monté en charge ce sera les directive **\*SparesServers** qui prendront le relais.

* **MinSpareServers**

    ![MinSpareServers-screenshot.png](./imgs/MinSpareServers-screenshot.png)

    La directive MinSpareServers permet de définir le nombre minimum désiré de processus serveurs enfants inactifs. Un processus inactif est un processus qui ne traite pas de requête. S'il y a moins de MinSpareServers processus inactifs, le processus parent va créer de nouveaux enfants de la manière suivante : il en crée un, attend une seconde, il en crée deux, attend une seconde, il en crée quatre, puis continue ainsi exponentiellement jusu'à ce que son taux de création de processus enfants soit de 32 par seconde. Il ne s'arrête que lorsque le nombre de processus enfants correspond à la définition de la directive MinSpareServers.
    Je vais insister sur l'aspect de processus inactif ! Si vous démarrez votre service apache, vous aurez 5 processus apache (en dehors du parent présent pour écouter sur le port ) 
        
            $ ps aux | grep ^www-data
            www-data    59  0.0  0.2  90588  5568 ?        S    08:42   0:00 /usr/sbin/apache2 -k start
            www-data    60  0.0  0.2  90588  5572 ?        S    08:42   0:00 /usr/sbin/apache2 -k start
            www-data    61  0.0  0.2  90588  5572 ?        S    08:42   0:00 /usr/sbin/apache2 -k start
            www-data    62  0.0  0.2  90588  5572 ?        S    08:42   0:00 /usr/sbin/apache2 -k start
            www-data    63  0.0  0.2  90588  5572 ?        S    08:42   0:00 /usr/sbin/apache2 -k start

    Si vous accéder à l'URL **Server-status** (https://www.linux202-sitea.com/server-status), vous pourrez voir l'état actuelle des processus 

            CPU Usage: u0 s0 cu0 cs0
            0 requests/sec - 0 B/second -
            1 requests currently being processed, 4 idle workers

   1 Requête en cours 4 en attentes , mais l'instruction **MinSpareServers** indique que nous devons avoir 5 processus en attente , effectivement si vous réalisé la commande **ps** vous aurez bien 6 processus apache en execution , l'URL **server-status** vous donnera la même information. 

* **MaxSpareServers** 

    ![MaxSpareServers-screenshot.png](./imgs/MaxSpareServers-screenshot.png)

    La directive MaxSpareServers permet de définir le nombre maximum souhaité de processus serveurs enfants inactifs. Un processus inactif est un processus qui ne traite pas de requête. S'il y a plus de MaxSpareServers processus inactifs, le processus parent arrêtera les processus excédentaires.

    La modification de ce paramètre n'est nécessaire que dans le cas de sites très sollicités. Définir ce paramètre à une valeur très grande est cependant dans la plupart des cas une mauvaise idée.
    Dans notre cas le nombre minimum est de 5 , s'il y a un nombre de requête excessif le système va démarrer plus de processus pour traiter les demandes . Une fois la charge terminé le apache va tuer les processus inactifs excédent ce nombre, cependant quand le nombre de processus apache sera égale à **MaxSpareServers** le système les laissera ceci causera une utilisation de mémoire pour conserver ces processus.

* **MaxRequestWorkers** (__MaxClients__ avant la version 2.3.13)

    ![MaxRequestWorkers-screenshot.png](./imgs/MaxRequestWorkers-screenshot.png)

    La directive [MaxRequestWorkers](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#maxrequestworkers) permet de fixer le nombre maximum de requêtes pouvant être traitées simultanément. Si la limite __MaxRequestWorkers__ est atteinte, toute tentative de connexion sera normalement mise dans une file d'attente, et ceci jusqu'à un certain nombre dépendant de la directive [ListenBacklog](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#listenbacklog). Lorsqu'un processus enfant se libèrera suite à la fin du traitement d'une requête, la connexion en attente pourra être traitée à son tour.

    Pour les serveurs non __threadés__ (c'est à dire utilisant **prefork**), la directive __MaxRequestWorkers__ définit alors le nombre maximum de processus enfants qui pourront être lancés simultanément pour traiter les requêtes. La valeur par défaut est 256 ; si vous l'augmentez, vous devez aussi augmenter la valeur de la directive [ServerLimit](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#serverlimit).

* **MaxConnectionsPerChild**

    ![MaxConnectionsPerChild-screenshot.png](./imgs/MaxConnectionsPerChild-screenshot.png)

    La directive [MaxConnectionsPerChild](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#maxconnectionsperchild) permet de définir le nombre maximum de connexions qu'un processus enfant va pouvoir traiter au cours de son fonctionnement. Lorsqu'il a traité __MaxConnectionsPerChild__ connexions, le processus enfant est arrêté. Si __MaxConnectionsPerChild__ est définie à 0, il n'y a plus aucune limite sur le nombre de connexions que le processus pourra traiter.

    Définir __MaxConnectionsPerChild__ à une valeur non nulle limite la quantité de mémoire qu'un processus peut consommer à cause de fuites (accidentelles) de mémoire. Il est donc fortement recommandé de définir une valeur afin d'avoir un recyclage des processus.

##### <a name="perf_prefork_optimisation" /> MPM prefork Optimisation

Maintenant que l'on comprend un peu mieux la configuration du système de démarrage des processus apache nous allons pouvoir discuter de modification de configuration afin d'améliorer les performances. Je vous préviens tous de suite à moins d'avoir un site web ultra chargé les gains de performances ne seront pas si significatif, de plus vous devrez faire des testes de validation et prendre des " risques " jusqu'à un certain point lors des modifications. 
Le plus gros gains que vous allez avoir est si vous avez un __VPS__ avec peu de __RAM__ ou si vous prenez une instance __Amazon EC2__ avec peu de mémoire et de __cpu__.

Voyons un exemple de configuration "classique" par défaut pour le système __préfork__

        $ cat /etc/apache2/mods-enabled/mpm_prefork.conf
        [ ... OUTPUT COUPÉ ... ]
        <IfModule mpm_prefork_module>
                StartServers                     5
                MinSpareServers           5
                MaxSpareServers          10
                MaxRequestWorkers         150
                MaxConnectionsPerChild   0
        </IfModule>

Afin de ne pas interférer avec les configurations préalablement réalisé nous allons désactiver le système de cache activé lors de la démonstration de l'utilisation du __CPU__ .

        $ cat /etc/apache2/sites-enabled/siteA-ssl.conf
        [ ... OUTPUT COUPÉ ... ]
                # Mise en cache de tous les contenus
                #CacheEnable  disk  /
                #CacheIgnoreCacheControl On
                #CacheDefaultExpire 3600
        [ ... OUTPUT COUPÉ ... ]
        $ sudo apachectl configtest && sudo /etc/init.d/apache2 restart

Je vais principalement manipuler la directive [MaxRequestWorkers](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#maxrequestworkers). Pour rappel cette directive définie le nombre de processus qu'apache va démarrer afin d'être en mesure de supporter la charge , en d'autre mot dans cette situation le site sera en mesure de fournir 150 clients concurrentiels. Nous allons faire un teste de charge avec 250 requêtes dont 250 concurrent :

        [client]$ ab  -n 250 -c 250 -l https://www.linux202-siteA.com/
        Percentage of the requests served within a certain time (ms)
          50%   2416
          66%   2622
          75%   2753
          80%   2801
          90%   3089
          95%   3352
          98%   3735
          99%   4689
          100%   4805 (longest request)


        [server]$ $ ps aux  | egrep 'apache|RSS' | head   
        USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
        root        58  0.1  0.9  90556 19536 ?        Ss   08:33   0:00 /usr/sbin/apache2 -k start
        www-data    63  0.0  0.2  90588  5468 ?        S    08:33   0:00 /usr/sbin/apache2 -k start
        [ ... OUTPUT COUPÉ ... ]

        [server]$ ps aux  | tr -s " " | cut -d " " -f 6,11- | grep apache | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum}'
        799480
        [server]$ bc -l
        bc 1.06.95
        Copyright 1991-1994, 1997, 1998, 2000, 2004, 2006 Free Software Foundation, Inc.
        This is free software with ABSOLUTELY NO WARRANTY.
        For details type warranty.
        799480 / 1024
        780.74218750000000000000

Dans l'exemple ci-dessus lors de la monté en charge j'ai fait la calcule de la mémoire utilisé par apache , en additionnant la colonne __RSS__ . Comme vous pouvez le constater nous monté a 780 __Megs__ de __RAM__ , pour uniquement la page d'accueil avec 250 client concurrent, cette monté en charge n'est que temporaire le temps de faire le traitement des connexions. Est-ce vraiment requis ?!?! Nous communiquons uniquement avec la page d'accueil qui ne contient pas beaucoup d'information ... Nous pouvons voir aussi que le temps maximal de réponde pour la page est de 4805 ms.

Réalisons une petite modification réalisons la même opération mais en réduisant le nombre de processus apache qui peut être démarré. Comme nous sommes en __prefork__ et qu'il y a copie du __stack__ mémoire pour chaque processus s'il y a moins de processus il y aura donc moins de mémoire. Je présume que votre premier réflexe est de vous dire : " oui c'est vraie, mais moins de processus pour prendre les requêtes vont exploser le temps de réponse ..." . Votre idée est juste mais présumé ce n'est pas confirmer :P , faisons le teste et regardons le résultat :


        $ cat /etc/apache2/mods-enabled/mpm_prefork.conf
        [ ... OUTPUT COUPÉ ... ]
        <IfModule mpm_prefork_module>
                StartServers                     5
                MinSpareServers           5
                MaxSpareServers          10
                MaxRequestWorkers         50
                MaxConnectionsPerChild   0
        </IfModule>
        $ sudo apachectl configtest && sudo /etc/init.d/apache2 restart

Donc nous réduisons le nombre de processus utilisable par apache , nous le passons de 150 à 50

        [client]$ ab  -n 250 -c 250 -l https://www.linux202-siteA.com/
        Percentage of the requests served within a certain time (ms)
          50%   2467
          66%   2746
          75%   2857
          80%   2954
          90%   3488
          95%   3894
          98%   4298
          99%   4748
         100%   4806 (longest request)


        [server]$ ps aux  | tr -s " " | cut -d " " -f 6,11- | grep apache | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum}'
        441432
        [server]$  bc -l
        bc 1.06.95
        Copyright 1991-1994, 1997, 1998, 2000, 2004, 2006 Free Software Foundation, Inc.
        This is free software with ABSOLUTELY NO WARRANTY.
        For details type warranty.
        441432/ 1024
        431.08593750000000000000

Donc nous utilisons maintenant 431 __megs__ de RAM et comparons le résultat du temps de réponses du serveur :

          150 Workers                               50 Workrs
          % of the requests served (ms)             % of the requests served (ms)
          50%   2416                                50%   2467
          66%   2622                                66%   2746
          75%   2753                                75%   2857
          80%   2801                                80%   2954
          90%   3089                                90%   3488
          95%   3352                                95%   3894
          98%   3735                                98%   4298
          99%   4689                                99%   4748
          100%  4805 (longest request)             100%   4806 (longest request)


Nous avons presque réduit de 50% la mémoire utilisé par le système pour un impacte minime sur les temps de réponses, nous pouvons donc y voir comme un succès . Nous pourrions même essayer de réduire ce nombre encore à 25 par exemple :

        [client]$ ab  -n 250 -c 250 -l https://www.linux202-siteA.com/
        Percentage of the requests served within a certain time (ms)
          50%   2443
          66%   2690
          75%   2825
          80%   2893
          90%   3316
          95%   3704
          98%   4024
          99%   4488
         100%   4660 (longest request)

        [server]$ ps aux  | tr -s " " | cut -d " " -f 6,11- | grep apache | egrep -v "grep|htcache" | awk '{ sum+=$1} END      {print sum}'
        235584

        [server]$ bc -l
        bc 1.06.95
        Copyright 1991-1994, 1997, 1998, 2000, 2004, 2006 Free Software Foundation, Inc.
        This is free software with ABSOLUTELY NO WARRANTY.
        For details type `warranty'. 
        235584 / 1024
        230.06250000000000000000

Donc 250 __megs__ pour un impacte sur les temps de réponses encore franchement très très confortable. 

**Woww** , bon je comprend l'économie de mémoire ... Mais si j'accepte que 50 connections et qu'il y en arrive 250 comment le serveur fait pour répondre ?!?! Où est la limite du serveur ?!?! Ceci n'est pas claire ! Vous avez raisons, ça demande un peu plus d'explication sur ce qui se passe sous le tapi :P.


La définition de la limite des connexions concurrent est définie par l'instruction [ServerLimit](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#serverlimit), cette dernière permet de définir le nombre de concurrence . Cette dernière est aussi utilisé pour limité le nombre de processus conjointement à l'instruction [MaxRequestWorkers](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#maxrequestworkers). La valeur par défaut est 256, vous ne devriez normalement pas la modifier , à moins d'avoir un serveur en conséquence :P. 

![ServerLimit-screenshot.png](./imgs/ServerLimit-screenshot.png)

Lors d'une augmentation de charge le système va utiliser l'instruction [ListenBackLog](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#listenbacklog) pour prendre en charge la connexion __TCP__ ( 3 __handshakes__ ). Le résultat est que le client aura bien établie la connexion avec le serveur et ce dernier recevra l'information de la page web lors qu'un processus se sera libéré. Par défaut le nombre de connexion dans la queue est de 511. Il faut faire attention lorsque nous jouons avec cette valeur car nous nous mettons à risque d'une attaque pas __TCP__ flood si cette dernière est trop haute.

Référence : http://www.ryanfrantz.com/posts/apache-tcp-backlog/

Donc tous le mystère de la gestion des connexions est dans ces 2 paramètres :D.

* Référence :
    * https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html
    * https://httpd.apache.org/docs/2.4/fr/mod/prefork.html

#### <a name="perf_worker" /> MPM worker

Nous venons de couvrir le mode __prefork__ passons au mode __worker__ au risque de me répété, __prefork__ __fork__ les processus donc réalise une copie du processus pour faire le traitement alors que __worker__ fonctionne en mode __thread__ et utilise la mémoire partagé des __thread__ pour faire le traitement. 

![prefork-vs-worker.png](./imgs/prefork-vs-worker.png)

Je vais modifier le mode par défaut __préfork__ pour passer en mode __worker__.

        $ sudo a2enmod mpm_worker
        Considering conflict mpm_event for mpm_worker:
        Considering conflict mpm_prefork for mpm_worker:
        ERROR: Module mpm_prefork is enabled - cannot proceed due to conflicts. It needs to be disabled first!
        Considering conflict mpm_itk for mpm_worker:


Comme vous pouvez le constater les 2 modules ne peuvent pas cohabité, nous nous y attendions je vais donc désactiver le mode __prefork__ pour passer au mode __worker__.

        $  sudo a2dismod mpm_prefork
        Module mpm_prefork disabled.
        To activate the new configuration, you need to run:
          service apache2 restart
        $ sudo a2enmod mpm_worker
        Considering conflict mpm_event for mpm_worker:
        Considering conflict mpm_prefork for mpm_worker:
        Considering conflict mpm_itk for mpm_worker:
        Enabling module mpm_worker.
        To activate the new configuration, you need to run:
            service apache2 restart

On valide la configuration + le redémarrage et on valide le tous ! Telle que mentionné dans le passé , le module __php__ avec Ubuntu n'est pas compatible avec le mode __worker__ nous y reviendrons donc pour le moment je vais le désactiver.

        $ sudo apachectl configtest && sudo /etc/init.d/apache2 restart
        [Mon Jul 04 17:28:01.104973 2016] [:crit] [pid 144:tid 3074546304] Apache is running a threaded MPM, but your PHP Module is not compiled to be threadsafe.  You need to recompile PHP.
        AH00013: Pre-configuration failed
        Action 'configtest' failed.
        The Apache error log may have more information.

        $ sudo a2dismod php5
        Module php5 disabled.
        To activate the new configuration, you need to run:
          service apache2 restart

        $ sudo apachectl configtest && sudo /etc/init.d/apache2 restart
        Syntax OK
        * Restarting web server apache2
            ...done.

Si nous accédons à la page du site nous devrions avoir le site comme avant : https://www.linux202-sitea.com/

Cool ! Maintenant que ça marche un peu d'explication avant de l'analyser

Un processus de contrôle unique (le parent) a pour tâche de lancer les processus enfants. Chaque processus enfant crée un nombre fixe de __threads__ serveurs selon la valeur de la directive __ThreadsPerChild__, ainsi qu'un __thread__ chargé d'attendre les connexions et de les passer à un __thread__ serveur pour traitement au fur et à mesure de leur arrivée.

Le serveur HTTP Apache essaie toujours de maintenir un jeu de __threads__ serveurs inactifs ou en réserve, qui se tiennent prêts à traiter les requêtes entrantes. De cette façon, les clients n'ont pas besoin d'attendre la création d'un nouveau __thread__ ou d'un nouveau processus pour que leurs requêtes puissent être traitées. Le nombre de processus lancés initialement est défini par la directive __StartServers__. En cours de fonctionnement, le serveur évalue le nombre total de __threads__ inactifs dans tous les processus, et en crée ou en arrête de façon à maintenir ce nombre à l'intérieur des limites définies par les directives __MinSpareThreads__ et __MaxSpareThreads__. Comme ce module s'auto-contrôle de manière efficace, on peut en général conserver les valeurs par défaut. Le nombre maximum de clients pouvant être servis simultanément (c'est à dire le nombre global maximum de __threads__ pour tous les processus) est défini par la directive __MaxRequestWorkers__. Le nombre maximum de processus enfants actifs est défini par la valeur de la directive __MaxRequestWorkers__ divisée par la valeur de la directive __ThreadsPerChild__.

Référence : https://httpd.apache.org/docs/2.4/fr/mod/worker.html

Visualisons la configuration :

        $ cat /etc/apache2/mods-enabled/mpm_worker.conf
        [ ... OUTPUT COUPÉ ... ]
        <IfModule mpm_worker_module>
                StartServers             2
                MinSpareThreads          25
                MaxSpareThreads          75
                ThreadLimit              64
                ThreadsPerChild          25
                MaxRequestWorkers        150
                MaxConnectionsPerChild   0
        </IfModule>

Analysons les directives disponible

* **StartServers**

    ![StartServers-screenshot.png](./imgs/StartServers-screenshot.png)

    Définie le nombre de processus qui seront démarrer lors de l'initialisation du service , avec le module __worker__ la valeur par défaut est **2**. Cette valeur est généralement assez basse , l'objectif est d'être en mesure de répondre au première requêtes rapidement. Comme vous pouvez le constater la valeur est plus basse que pour le module __prefork__ comme le système utilise 1 processus pour traiter plusieurs demande à l'aide des __thread__ il a moins besoin de démarrer de processus pour prendre en charge la demande.

* **MinSpareThreads**

    ![MinSpareThreads-screenshot.png](./imgs/MinSpareThreads-screenshot.png)

    C'est le nombre minimum de __threads__ inactifs pour être en mesure de traiter les pics de requêtes.
    Sous le mode __worker__ , la définition par défaut est __MinSpareThreads 75__, et le nombre de __threads__ inactifs est surveillé au niveau du serveur. Si le serveur ne possède pas assez de __threads__ inactifs, des processus enfants sont créés jusqu'à ce que le nombre de __threads__ inactifs repasse au dessus de nombre.

* **MaxSpareThreads**

    ![MaxSpareThreads-screenshot.png](./imgs/MaxSpareThreads-screenshot.png)

    C'est le nombre maximum de __threads__ inactifs.
    Sous le mode __worker__ , la définition par défaut est __MaxSpareThreads 250__. Ce __MPM__ gère les __threads__ inactifs au niveau du serveur. Si le serveur possède trop de __threads__ inactifs, des processus enfants seront arrêtés jusqu'à ce que le nombre de __threads__ inactifs repasse en dessous de cette limite.

* **ThreadLimit**

    ![ThreadLimit-screenshot.png](./imgs/ThreadLimit-screenshot.png)

    Cette directive permet de définir le nombre maximum que l'on peut affecter à la directive __ThreadsPerChild__ pour la durée de vie du processus Apache __httpd__. La directive __ThreadsPerChild__peut être modifiée au cours d'un redémarrage jusqu'à la valeur de la directive __ThreadLimit__, mais toute tentative de modification de la directive __ThreadLimit__ au cours d'un redémarrage sera ignorée.

    L'utilisation de cette directive doit faire l'objet de précautions particulières. Si __ThreadLimit__ est définie à une valeur très supérieure à la directive __ThreadsPerChild__, de la mémoire partagée supplémentaire sera inutilement allouée. Si les directives __ThreadLimit__ et __ThreadsPerChild__ sont définies à des valeurs supérieures à ce que le système peut supporter, ce dernier peut devenir instable, ou Apache __httpd__ peut tout simplement refuser de démarrer. Ne définissez pas cette directive à une valeur supérieure à la valeur maximale que vous pensez affecter à la directive __ThreadsPerChild__ pour le processus Apache __httpd__ en cours d'exécution.

* **ThreadsPerChild**

    ![ThreadsPerChild-screenshot.png](./imgs/ThreadsPerChild-screenshot.png)

    Cette directive permet de définir le nombre de __threads__ que va créer chaque processus enfant. Un processus enfant crée ces __threads__ au démarrage et n'en crée plus d'autres par la suite. Avec un __MPM__ comme __worker__ qui lance plusieurs processus enfants, c'est le nombre total de __threads__ qui doit être suffisamment grand pour supporter la charge du serveur


* **MaxRequestWorkers**

    ![MaxRequestWorkers-screenshot.png](./imgs/MaxRequestWorkers-screenshot.png)

    La directive __MaxRequestWorkers__ permet de fixer le nombre maximum de requêtes pouvant être traitées simultanément. Si la limite __MaxRequestWorkers__ est atteinte, toute tentative de connexion sera normalement mise dans une file d'attente, et ceci jusqu'à un certain nombre dépendant de la directive __ListenBacklog__. Lorsqu'un processus enfant se libèrera suite à la fin du traitement d'une requête, la connexion en attente pourra être traitée à son tour.
    Pour les serveur __threadés__ et hybrides (utilisant par exemple __event__ ou __worker__), __MaxRequestWorkers__ définit alors le nombre total de __threads__ qui seront disponibles pour servir les clients. Dans le cas des __MPMs__ hybrides, la valeur par défaut est 16 (directive __ServerLimit__) multiplié par la valeur 25 (directive __ThreadsPerChild__). Par conséquent, pour affecter à la directive __MaxRequestWorkers__ une valeur qui requiert plus de 16 processus, vous devez aussi augmenter la valeur de la directive __ServerLimit__.


* **MaxConnectionsPerChild**

    ![MaxConnectionsPerChild-screenshot.png](./imgs/MaxConnectionsPerChild-screenshot.png)

    La directive __MaxConnectionsPerChild__ permet de définir le nombre maximum de connexions qu'un processus enfant va pouvoir traiter au cours de son fonctionnement. Lorsqu'il a traité __MaxConnectionsPerChild__ connexions, le processus enfant est arrêté. Si __MaxConnectionsPerChild__ est définie à 0, il n'y a plus aucune limite sur le nombre de connexions que le processus pourra traiter. Définir __MaxConnectionsPerChild__ à une valeur non nulle limite la quantité de mémoire qu'un processus peut consommer à cause de fuites (accidentelles) de mémoire.

##### <a name="perf_worker_optimisation" /> MPM Worker Optimisation

Maintenant que l'on comprend un peu mieux la configuration du système de démarrage des processus apache nous allons pouvoir discuter de modification de configuration afin d'améliorer les performances. Je vous préviens tous de suite à moins d'avoir un site web ultra chargé les gains de performances ne seront pas si significatif, de plus vous devrez faire des testes de validation et prendre des " risques " jusqu'à un certain point lors des modifications. 
Le plus gros gains que vous allez avoir est si vous avez un __VPS__ avec peu de __RAM__ ou si vous prenez une instance __Amazon EC2__ avec peu de mémoire et de __cpu__.

Nous allons commencer par voir le comportement du système __worker__ pour réaliser les manipulations par la suite . Premièrement conformément à la directive [StartServers](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#startservers) lors du démarrage du service nous avons bien uniquement 2 processus en plus de celui qui écoute sur le(s) port(s).

        $ ps aux |grep apache2
        root        54  0.0  0.3   8952  6580 ?        Ss   08:41   0:00 /usr/sbin/apache2 -k start
        www-data    59  0.0  0.2 231584  4656 ?        Sl   08:41   0:00 /usr/sbin/apache2 -k start
        www-data    60  0.0  0.2 231584  4656 ?        Sl   08:41   0:00 /usr/sbin/apache2 -k start

Nous allons monté en charge tranquillement avec un premier teste afin de voir le comportement des processus. Nous allons y allé gentiment avec un 200 requêtes dont 10 concurrentes.

        [client]$ ab  -n 100 -c 10 -l https://www.linux202-siteA.com/
        [ ... OUTPUT COUPÉ ... ]
        Concurrency Level:      10
        Time taken for tests:   2.056 seconds
        Complete requests:      100
        Failed requests:        0
        Total transferred:      36900 bytes
        HTML transferred:       10000 bytes
        Requests per second:    48.63 [#/sec] (mean)
        Time per request:       205.628 [ms] (mean)
        Time per request:       20.563 [ms] (mean, across all concurrent requests)
        Transfer rate:          17.52 [Kbytes/sec] received

        Connection Times (ms)
                      min  mean[+/-sd] median   max
                      Connect:       33  184  92.6    213     291
                      Processing:     1   12  17.1      5      77
                      Waiting:        0    9  14.4      3      64
                      Total:         34  196  95.1    240     303

        Percentage of the requests served within a certain time (ms)
           50%    240
           66%    263
           75%    284
           80%    285
           90%    287
           95%    292 
           98%    300 
           99%    303 
          100%    303 (longest request)

        [server]$ ps aux | grep apache2
        root        54  0.0  0.3   8952  6580 ?        Ss   08:41   0:00 /usr/sbin/apache2 -k start
        www-data    59  0.4  0.3 234884  8084 ?        Sl   08:41   0:01 /usr/sbin/apache2 -k start
        www-data    60  0.3  0.3 234744  8020 ?        Sl   08:41   0:01 /usr/sbin/apache2 -k start

Comme l'ensemble des requêtes furent traité par des __threads__ exécuter par les processus il n'y a pas d'augmentation de ces derniers.

J'aimerai porter votre attention sur le premier teste de **AB** que nous avions réalisé [présentation de ab](#perf_bench_ab), nous avions utilisé le même nombre de requête mais avec le système __prefork__ , voici les résultats que nous avions eu :

        Concurrency Level:      10
        Time taken for tests:   2.263 seconds
        Complete requests:      100
        Failed requests:        0
        Total transferred:      36900 bytes
        HTML transferred:       10000 bytes
        Requests per second:    44.19 [#/sec] (mean)
        Time per request:       226.313 [ms] (mean)
        Time per request:       22.631 [ms] (mean, across all concurrent requests)
        Transfer rate:          15.92 [Kbytes/sec] received

        Connection Times (ms)
                      min  mean[+/-sd] median   max
        Connect:       33  189  77.2    201     456
        Processing:     1   22  19.3     19      86
        Waiting:        0   16  16.5      9      76
        Total:         34  210  82.5    215     457

        Percentage of the requests served within a certain time (ms)
        50%    215
        66%    237
        75%    253
        80%    258
        90%    288
        95%    363
        98%    403
        99%    457
        100%   457 (longest request)

Il n'y a pas beaucoup de différence cependant on voit que sur la duré le système de __thread__ répond mieux, ceci est principalement au fait que le système n'a pas besoin d'attendre que le système d'exploitation démarre des processus pour faire la gestion des requêtes.

Montons en charge pour voir un peu :D 

        [client]$ ab  -n 200 -c 50 -l https://www.linux202-siteA.com/
        [... OUTPUT COUPÉ ..]
        Percentage of the requests served within a certain time (ms)
          50%    992
          66%   1007
          75%   1014
          80%   1026
          90%   1066
          95%   1073
          98%   1077
          99%   1135
         100%   1266 (longest request)


        [server]$ ps aux | grep apache
        root        54  0.0  0.3   8952  6580 ?        Ss   08:41   0:00 /usr/sbin/apache2 -k start
        www-data    59  0.4  0.4 236072  9396 ?        Sl   08:41   0:03 /usr/sbin/apache2 -k start
        www-data    60  0.3  0.4 235944  9556 ?        Sl   08:41   0:03 /usr/sbin/apache2 -k start
        www-data   129 26.8  0.4 235796  9264 ?        Sl   08:54   0:01 /usr/sbin/apache2 -k start
        www-data   159  0.0  0.2 231584  4660 ?        Sl   08:54   0:00 /usr/sbin/apache2 -k start

        [server]$ ps aux | grep apache
        root        54  0.0  0.3   8952  6580 ?        Ss   08:41   0:00 /usr/sbin/apache2 -k start
        www-data   191  0.0  0.2 231584  4660 ?        Sl   08:54   0:00 /usr/sbin/apache2 -k start


Je vais remettre le système de __prefork__ et faire une vraie monté en charge afin de démontré la différence de comportement nous allons toujours utiliser la page d'accueil afin d'avoir un teste équivalent . 

Pour rappel la configuration __prefork__ 

        $ cat /etc/apache2/mods-available/mpm_prefork.conf
        <IfModule mpm_prefork_module>
                StartServers                     5
                MinSpareServers           5
                MaxSpareServers          10
                MaxRequestWorkers        150
                MaxConnectionsPerChild   0
        </IfModule>

        [server]$ uptime
         08:17:32 up 7 min,  1 user,  load average: 0.50, 0.48, 0.28

        [client]$ ab  -n 500 -c 100 -l https://www.linux202-siteA.com/
        Percentage of the requests served within a certain time (ms)
          50%   1953
          66%   2038
          75%   2083
          80%   2114
          90%   2195
          95%   2227
          98%   2348
          99%   2392
         100%   2434 (longest request)

        # apres le teste de charge 
        [server]$ uptime
         08:18:39 up 8 min,  1 user,  load average: 3.16, 1.04, 0.47


J'active le mode __prefork__ et refait le teste ...

        $ cat /etc/apache2/mods-enabled/mpm_worker.conf
        <IfModule mpm_worker_module>
               StartServers                     2
               MinSpareThreads          25
               MaxSpareThreads          75
               ThreadLimit                      64
               ThreadsPerChild          25
               MaxRequestWorkers         150
               MaxConnectionsPerChild   0
        </IfModule>
        
        [server]$ uptime
        08:21:42 up 11 min,  1 user,  load average: 0.36, 0.68, 0.44

        [client]$ ab  -n 500 -c 100 -l https://www.linux202-siteA.com/
        Percentage of the requests served within a certain time (ms)
          50%   1964
          66%   2103
          75%   2189
          80%   2267
          90%   2501
          95%   2622
          98%   2848
          99%   3071
         100%   3454 (longest request)


        # apres le teste de charge 
        [server]$ uptime
        08:23:43 up 13 min,  1 user,  load average: 14.77, 4.49, 1.75

Clairement c'est plus performant ... Heu __oupss__ le __load__ de la machine est monté a 14.77, il y a un problème nous ne serons pas en mesure de monté en charge si la machine est autant sollicité.

La question est pourquoi cette monté en charge, ce qui n'est pas affiché dans la démonstration ci-dessus c'est le nombre de processus qui furent démarrer même si le système de __thread__ est plus performant mon système n'est pas en mesure de supporter cette monté en charge.

Je vais réduire  le nombre de **MaxRequestWorkers** de 150 à 25

        
        [server]$ uptime
         08:31:31 up 21 min,  1 user,  load average: 0.58, 2.61, 1.95

        [client]$ ab  -n 500 -c 100 -l https://www.linux202-siteA.com/
        Percentage of the requests served within a certain time (ms)
          50%   2149 
          66%   2557 
          75%   2602 
          80%   2634 
          90%   2693 
          95%   2708 
          98%   2751 
          99%   2755 
         100%   2802 (longest request)

        # apres le teste de charge 
        [server]$ uptime
         08:31:45 up 21 min,  1 user,  load average: 2.30, 2.89, 2.06

Une nouvelle fois en réduisant le nombre de traitement concurrent que j'accepte , je réduit la charge sur le serveur et permet un meilleur traitement de ces derniers.

Mais , mais , mais on avait pas dit que __worker__ est plus performant ... Oui car il ne réalise pas une copie des processus mais gère les requêtes par __thread__ 

**Worker**

        # Utilisation de la RAM au démarrage 
        [server]$ ps aux  | tr -s " " | cut -d " " -f 6,11- | grep apache | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum/1024 " Megs"}'
         11.3555 Megs
        [server]$ uptime
         08:45:11 up 24 min,  1 user,  load average: 0.20, 0.28, 0.33

        [client]$ ab  -n 500 -c 100 -l https://www.linux202-siteA.com/
        [... OUTPUT COUPÉ ...]
        Percentage of the requests served within a certain time (ms)
          50%   1933
          66%   2052
          75%   2126
          80%   2157
          90%   2224
          95%   2250
          98%   2279
          99%   2316
         100%   2326 (longest request)

        [server]$ ps aux  | tr -s " " | cut -d " " -f 6,11- | grep apache | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum/1024 " Megs"}'
        16.0039 Megs

        [server]$ $ uptime
         08:48:57 up 28 min,  1 user,  load average: 2.02, 0.65, 0.44

Donc avec le mode __worker__ pendant le temps du traitement nous sommes monté à un gros 16 Megs de RAM pour traiter les requêtes.

**PreFork**

        # Switch de la configuration
        [server]$ sudo a2dismod mpm_worker
        [server]$ sudo a2enmod mpm_prefork
        [server]$ sudo apachectl configtest && sudo /etc/init.d/apache2 restart

        # Utilisation de la RAM au démarrage 
        [server]$ ps aux  | tr -s " " | cut -d " " -f 6,11- | grep apache | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum/1024 " Megs"}'
        23.0352 Megs

        [server]$ uptime
         08:53:48 up 33 min,  1 user,  load average: 0.29, 0.47, 0.41

        [client]$ ab  -n 500 -c 100 -l https://www.linux202-siteA.com/
        [... OUTPUT COUPÉ ...]

        [server]$ ps aux  | tr -s " " | cut -d " " -f 6,11- | grep apache | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum/1024 " Megs"}'
        157.547 Megs

        [server]$ uptime
         08:54:40 up 34 min,  1 user,  load average: 2.39, 0.90, 0.56

**Conclusion**

Bien que la charge sur le serveur est sensiblement équivalent au niveau du __load average__ nous voyons clairement un gain au niveau de la gestion de la mémoire . Pour le même teste nous passons de 157 __Megs__ (__prefork__) à 16 __Megs__ (__worker__) un petit 141 __Megs__ d économisé. 

Vous me direz peut-être la RAM n'est pas très chère , cependant si vous voyez l'utilisation de plusieurs instance Amazon EC2, ou la location de petite machine à moindre coût telle que des __VPS__ vous aurez tous avantage à mieux utiliser la mémoire disponible. Nous aurons le même requis si nous mettons en place des dockers sur une même machine pour faire la gestion de micro services..

Super me direz vous mais j'ai besoin d'avoir __php__ moi, vous avez probablement une application développé avec ce langage qui est difficile a vous départir. Vous n'avez pas envie d'avoir un autre serveur apache uniquement pour fournir le service __php__ qui fonctionne en __préfork__. Nous allons donc maintenant voir comment nous pouvons faire fonctionner __php__avec le mode __worker__. 

### <a name="perf_php" /> Amélioration des performances de php


Personnellement je ne suis pas un grand fan de __PHP__ pas que ce soit un mauvais langage de programmation, cependant ça simplicité de développement a amené  sont lot de page mal programmé. Résultat j'ai un préjugé négatif de ce langage , je suis honnête dans mon propos, cependant c'est une réalité que les pages __php__ sont très présent dans notre quotidien.

Nous allons donc voir comment nous pouvons améliorer les performances de notre système apache lorsque nous devons exécuter du __php__. Nous avons vu comment géré le problème de __CPU__ à l'aide d'un système de cache , nous avons vu comment traiter le problème d'__IO__ lors de l'écriture de fichier à l'aide d'un système de fichier en mémoire. Par contre la solution idéal pour le problème de mémoire reste l'utilisation du module de gestion de processus __worker__ malheureusement __mod\_php__ ne peut pas fonctionner avec ce dernier. Voyons une solution à ce problème , nous allons utiliser __php5-fpm__.

#### <a name="perf_php_php5-fpm" /> Utilisation en mode cgi (php5-fpm)

__PHP-FPM__ (__FastCGI Process Manager__) est une interface [SAPI](https://fr.wikipedia.org/wiki/Server_Application_Programming_Interface) permettant la communication entre un serveur Web et __PHP__, basée sur le protocole __FastCGI__ et écrite par __Andrei Nigmatulin__.

#### <a name="perf_php_php5-fpm_installation" /> Installation & configuration de php5-fpm

Merci Debian nous avons un pacquage pour ça :P.

        $ sudo apt-get install php5-fpm libapache2-mod-fastcgi

Ceci va nous permettre d'avoir un service __Fastcgi__ disponible pour apache, mais c'est quoi ça __Fastcgi__ en d'autre mot au lieu qu'apache soit en mesure d'interpréter lui même à l'interne les fichiers de type __php__ il va exécuter la la commande __/usr/bin/php__ pour générer la page . Le point négatif si vous utilisez cette méthode est que j'ai déjà vu dans le passer un petit changement de comportement dans les pages __php__ lorsque ce dernier s'attend à "vivre" dans apache. Nous avions rencontré un problème principalement dans des variables d'environnement qui ne sont pas présente, car non exécuter sous apache.

Suite à l'opération vous pouvez constater que le module __FastCGI__ est déjà actif :

        $  ls -l /etc/apache2/mods-enabled/*fast*
        lrwxrwxrwx 1 root root 30 Jul  8 17:05 /etc/apache2/mods-enabled/fastcgi.conf -> ../mods-available/fastcgi.conf
        lrwxrwxrwx 1 root root 30 Jul  8 17:05 /etc/apache2/mods-enabled/fastcgi.load -> ../mods-available/fastcgi.load


Nous allons désactiver le __mod\_php__ et mettre le système en mode __worker__ :

        $ sudo a2dismod php5
        $ sudo a2dismod mpm_prefork
        $ sudo a2enmod  mpm_worker

Nous pourrions redémarrer apache à ce stade mais nous allons mettre en place la configuration pour __php-fpm__. Nous allons donc créer le fichier de configuration **/etc/apache2/conf-available/php5-fpm.conf**

        <IfModule mod_fastcgi.c>
            AddHandler php5-fcgi .php
            Action php5-fcgi /php5-fcgi
            Alias /php5-fcgi /usr/lib/cgi-bin/php5-fcgi
            FastCgiExternalServer /usr/lib/cgi-bin/php5-fcgi -socket /var/run/php5-fpm.sock -pass-header Authorization
        </IfModule>

Analysons le fichier de configuration :

* **AddHandler** : nous ajoutons un interpréter pour les fichiers dont l'extension se termine par __.php__ lors que ce type de fichier sera traiter nous appellerons l'__handler__  (l'interpréteur) __php-fcgi__
* **Action** : Suite à l'identification de l'extension du fichier nous définissons l'action a prendre nous lui indiquons de communiquer avec __/php5-fcgi__
* **Alias** : Nous l'avons déjà vu le mode Alias ceci nous permet de redirigé une destination dans l'URL vers un autre __PATH__ sur le serveur. Dans notre cas ce sera __/usr/lib/cgi-bin/php5-fcgi__
* **FastCgiExternalServer** : Pour terminé nous spécifions que lors de la communication au fichier __/usr/lib/cgi-bin/php5-fcgi__ il doit le transmettre au __socket__ __/var/run/php5-fpm.sock__ via le système de __FastCgi__.

**WOOT**, j'ai presque compris :P , bon voyons les fichiers maintenant : 

        $ ls -l /usr/lib/cgi-bin/php5-fcgi
        ls: cannot access /usr/lib/cgi-bin/php5-fcgi: No such file or directory
        $ ls -l /var/run/php5-fpm.sock
        ls: cannot access /var/run/php5-fpm.sock: No such file or directory


Bon là si vous avez juste copiez collé les fichiers de configuration vous vous dites , voilà Thomas a écris la documentation après la victoire de la France contre l'Allemagne à __l'EURO__ 2016. Il était dans les patates ... Pas de panique j'ai cuvé depuis :P

Le fichier __/usr/lib/cgi-bin/php5-fcgi__ n'est pas vraie mais uniquement pour forcé l'appelle  du __FastCgiExternalServer__ , nous allons créer un fichier vide .

        $ sudo touch /usr/lib/cgi-bin/php5-fcgi
        $ ls -ld /usr/lib/cgi-bin/php5-fcgi
        -rw-r--r-- 1 root root 0 Jul  8 17:24 /usr/lib/cgi-bin/php5-fcgi

Le fichier __/var/run/php5-fpm.sock__ est un __socket__ définie par le service __php5-fpm__ nous allons donc le démarrer , bien entendu il faut aussi vous assurer que ce service redémarre lors d'un redémarrage du serveur tous comme apache.

        $ sudo /etc/init.d/php5-fpm start
        $ sudo /etc/init.d/php5-fpm status
         * php5-fpm is running
        $ ls -l  /var/run/php5-fpm.sock
         srw-rw---- 1 www-data www-data 0 Jul  8 17:26 /var/run/php5-fpm.sock

Activons la configuration :

        $ cd /etc/apache2/conf-enabled/
        $ sudo ln -s ../conf-available/php5-fpm.conf
Bon ça semble bon GO ?

        $ sudo apachectl configtest && sudo /etc/init.d/apache2 restart
        AH00526: Syntax error on line 3 of /etc/apache2/conf-enabled/php5-fpm.conf:
        Invalid command 'Action', perhaps misspelled or defined by a module not included in the server configuration
        Action 'configtest' failed.
        The Apache error log may have more information.

__Oupss__ il manquait un module 

        $ sudo a2enmod  actions

__RE__ GO ?

        $ sudo apachectl configtest && sudo /etc/init.d/apache2 restart
        Syntax OK
         * Restarting web server apache2
             ...done.

Validons l'URL : https://www.linux202-sitea.com/info.php
__Issh__ :   __You don't have permission to access /php5-fcgi/info.php on this server.__

Validons les logs, j'aime mettre quelque erreurs dans mes formations ceci permet de voir un peu de pratique d'analyse car malheureusement ça marche rarement du premier coup :P, ce sera probablement pas les même erreurs mais ça vous offre une démonstration d'analyse .

        $ tail /data/vhosts/siteA/logs/error-ssl.log
        [... OUPUT COUPÉ ...]
        [Fri Jul 08 17:29:39.669126 2016] [authz_core:error] [pid 473:tid 3051350848] [client 172.17.42.1:43232] AH01630: client denied by server configuration: /usr/lib/cgi-bin/php5-fcgi

Pourquoi ?? Rappelez au niveau de la sécurité j'aime bloqué l'ensemble du système avec depuis la racine résultat toutes nouvelle configuration m'oblige à ouvrir l'accès ... Nous allons donc modifier la configuration afin de permettre l'accès au répertoire __/usr/lib/cgi-bin/__. Ouvrons le fichier 

        <IfModule mod_fastcgi.c>
            AddHandler php5-fcgi .php
            Action php5-fcgi /php5-fcgi
            Alias /php5-fcgi /usr/lib/cgi-bin/php5-fcgi
            FastCgiExternalServer /usr/lib/cgi-bin/php5-fcgi -socket /var/run/php5-fpm.sock -pass-header Authorization

             # Authorization de l'access au repertoire cgi-bin
            <Directory /usr/lib/cgi-bin>
                Require all granted
            </Directory> 
        </IfModule>

C'est repartie :D : 

        $ sudo apachectl configtest && sudo /etc/init.d/apache2 restart

#### <a name="perf_php_php5-fpm_perf" /> test de performance avec php5-fpm

Visualisation des configurations de __mpm\_worker__ :

        $ cat /etc/apache2/mods-enabled/mpm_worker.conf
        <IfModule mpm_worker_module>
                StartServers                     2
                MinSpareThreads          25
                MaxSpareThreads          75
                ThreadLimit                      64
                ThreadsPerChild          25
                MaxRequestWorkers         25
                MaxConnectionsPerChild   0
        </IfModule>


Nous allons sur l'URL : https://www.linux202-sitea.com/info.php : **WOOT** ça marche ... Allez c'est le temps du stresse teste . Pour le calcule de l'utilisation de la RAM, j'ai changé un peu la commande car en plus d'apache nous devons être en mesure de calculer le service __php__ :

        $  ps aux  | tr -s " " | grep ^www-data
        www-data 422 0.0 0.2 86620 4700 ? S 17:26 0:00 php-fpm: pool www
        www-data 423 0.0 0.4 86620 9912 ? S 17:26 0:00 php-fpm: pool www
        www-data 551 0.0 0.1 8380 3200 ? S 17:36 0:00 /usr/sbin/fcgi-pm -k start
        www-data 552 0.0 0.3 232920 7016 ? Sl 17:36 0:00 /usr/sbin/apache2 -k start

        $  ps aux  | tr -s " " | grep ^www-data | cut -d " " -f 6,11- | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum/1024 " Megs"}'
        24.2461 Megs

Donc nous avons le processus __apache2__ mais aussi l'ensemble des processus en lien à la gestion de __php__ 

J'ai vraiment hâte de faire le teste de charge donc GO :). 

        [server]$ uptime 
        17:41:51 up 47 min,  1 user,  load average: 0.53, 0.47, 0.41

        [server]$  ps aux  | tr -s " " | grep ^www-data | cut -d " " -f 6,11- | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum/1024 " Megs"}'
        24.2461 Megs

        [client]$ ab  -n 100 -c 10 -l https://www.linux202-siteA.com/info.php
        Percentage of the requests served within a certain time (ms)
          50%    241
          66%    263
          75%    287
          80%    294
          90%    313
          95%    339
          98%    353
          99%    361
         100%    361 (longest request)

        [server]$ ps aux  | tr -s " " | grep ^www-data | cut -d " " -f 6,11- | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum/1024 " Megs"}'
        29.543 Megs

        [server]$ uptime
         17:43:26 up 49 min,  1 user,  load average: 0.95, 0.59, 0.46

Deuxième teste :

        [server]$ $ uptime
         17:46:41 up 52 min,  1 user,  load average: 0.45, 0.57, 0.48
        [server]$ ps aux  | tr -s " " | grep ^www-data | cut -d " " -f 6,11- | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum/1024 " Megs"}'
         29.543 Megs

         [client]$ ab  -n 300 -c 30 -l https://www.linux202-siteA.com/info.php
         Percentage of the requests served within a certain time (ms)
           50%    781
           66%    842
           75%    886
           80%    933
           90%   1106
           95%   1229
           98%   1348
           99%   1404
          100%   1417 (longest request)

         [server]$ uptime
          17:46:55 up 52 min,  1 user,  load average: 2.42, 1.00, 0.62
         [server]$ ps aux  | tr -s " " | grep ^www-data | cut -d " " -f 6,11- | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum/1024 " Megs"}'
          39.4375 Megs

REF : https://www.digitalocean.com/community/questions/apache-2-4-with-php5-fpm


#### <a name="perf_php_php5-fpm_perf_vs_mod_php5" /> Comparatif avec prefork et mod_php5


Reprenons le teste avec le __mod\_prefork__ avec 100 requête dont 10 concurrentes , voici la configuration du __prefork__ :

        $ cat /etc/apache2/mods-enabled/mpm_prefork.conf
        <IfModule mpm_prefork_module>
                StartServers                     5
                MinSpareServers           5
                MaxSpareServers          10
                #       MaxRequestWorkers        150
                MaxRequestWorkers        25
                MaxConnectionsPerChild   0
         </IfModule>

C'est repartie pour le teste de charge 

        [server]$ uptime
        08:40:58 up 22 min,  1 user,  load average: 0.17, 0.44, 0.41
        [server]$ ps aux  | tr -s " " | cut -d " " -f 6,11- | grep apache | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum/1024 " Megs"}'
         59.332 Megs

        [client] $ ab  -n 100 -c 10 -l https://www.linux202-siteA.com/info.php
            Connection Times (ms)
              min  mean[+/-sd] median   max
              Connect:       51  191  65.0    197     334
              Processing:     9   41  23.0     34     133
              Waiting:        1   21  16.0     18      95
              Total:         65  232  73.9    230     407

        Percentage of the requests served within a certain time (ms)
          50%    230
          66%    269
          75%    289
          80%    296
          90%    327
          95%    340
          98%    383
          99%    407
         100%    407 (longest request)

        [server]$ ps aux  | tr -s " " | cut -d " " -f 6,11- | grep apache | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum/1024 " Megs"}'
         130.27 Megs
        [server]$ uptime
          08:41:58 up 23 min,  1 user,  load average: 0.14, 0.38, 0.39

Deuxième teste avec 300 requêtes dont 30 concurrentes :

        [server]$ uptime
         08:30:49 up 13 min,  1 user,  load average: 0.11, 0.18, 0.21
        [server]$ ps aux  | tr -s " " | grep ^www-data | cut -d " " -f 6,11- | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum/1024 " Megs"}'
        43.6719 Megs

        [client]$  ab  -n 300 -c 30 -l https://www.linux202-siteA.com/info.php
        Percentage of the requests served within a certain time (ms)
          50%    736
          66%    810
          75%    845
          80%    867
          90%    940
          95%    986
          98%   1135
          99%   1233
         100%   1284 (longest request)


        [server]$ $ ps aux  | tr -s " " | grep ^www-data | cut -d " " -f 6,11- | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum/1024 " Megs"}'
        324.855 Megs

        [server]$ uptime
         08:31:56 up 14 min,  1 user,  load average: 2.36, 0.67, 0.36


**conclusion** 

Dans la situation actuelle avec un serveur qui à très peu de CPU nous avons des résultats très similaire dans les deux modes ,en terme de temps de réponse des pages web . Nous pouvons aussi constater que la charge sur le CPU est très similaire si nous nous référons au __load average__ du système . Nous pouvons constater une grosse amélioration de l'utilisation du système au niveau de la mémoire nous avons une énorme économique en utilisant le mode __mpm\_worker__ .

### <a name="perf_bandwidth" /> Correction de transfert de donnée

Nous avons vu l'utilisation de __mod\_cache__ qui nous à permit de définir un système de cache sur les pages qui sont appeler sur notre serveur améliorant ainsi la charge du CPU utilisé lors de l'appel. Je vais faire mention d'un autre module à analyser si vous avez un autre type de problème. Je ne prendrai pas le temps de faire la démonstration de son utilisation, je vous laisse se plaisir . Je pense que ma plus value n'est pas tant dans la démonstration de chaque fonctionnalité mais plutôt  dans la démonstration des principes.

Si vous avez un problème d'utilisation de bande passante, votre site transmet énormément de donnée ceci congestionnant le lien internet ou causant un ralentissement lors du transfert au client. Avec le module [mod\_deflate](http://httpd.apache.org/docs/current/fr/mod/mod_deflate.html) vous pourrez mettre un place un système de compression de votre site lors du transfert au client . Bien entendu ceci aura un impacte sur l'utilisation du CPU sur votre machine car la compression a un coup !

Je vous laisse le plaisir de consulter  le site d'apache en lien avec ce module : [mod\_deflate](http://httpd.apache.org/docs/current/fr/mod/mod_deflate.html) .

## <a name="perf_concept_generic" /> Considération globale pour améliorer les performances

J'aurais peut-être du commencer par ça mais j'aime bien allé dans le vif du sujet pour commencer et revenir sur les considérations moins critique par la suite. Car L'ensemble des instructions ci-dessous vous pouvez les trouver sur l'Internet sans moi, donc il y a moins de valeur de mon point de vue.

Pour améliorer les performances vous devriez considérer les points suivant :

* **Répartition de l'accès disque** : L'accès au disque dur reste un point "problématique" lors de l'optimisation des performances , le disque étant lent vous pouvez avoir un gain de performance en ajustant l'organisation de votre système de fichier selon l'accès . Voici des manières plus concrète de l'utilisation :
    * **Définir vos logs sur un disque dur distinct** : Il peut être optimal que votre système apache écrit les logs sur un disque dur dédier ceci évitera qu'il parcourt le même disque pour écrire le logs ET fournir l'information du site web.
    * **Définir le cache sur un disque dédier** : Tous comme les logs il est plus optimal de dédier un disque pour le système de cache au lieu de le mettre sur le reste du système de fichier.
* **Désactivation des logs verboses** : Si vous activer le mode de __logs__ de type __debug__ le système devra écrire une grande quantité sur le disque ralentissent ainsi le système à cause d'accès disque . Nous retrouvons le mode __debug__ pour __php__ ou encore __mod\_rewrite__. 
* **Désactivé TOUS les modules que vous n'utilisez pas** : L'ensemble des modules utilise de la mémoire , que vous utilisiez le mode __worker__ ou __prefork__ si vous ne les utilisez pas désactivez les . Bien entendu avec le mode __prefork__ l'impacte sera encore plus significatif.
* **Désactivé la directive HostnameLookups** : Si vous activez cette directive Apache réalisera un reverse __DNS__ sur l'adresse IP afin d'avoir le nom de domaine associé pour l'écrire dans les logs. Même si cette information peut vous être utile je vous conseille de réaliser cette opération lors de la génération des statistiques d'accès au site quand votre site web est moins sollicité.
* **Utilisation d'adresse IP dans la configuration au lieu des nom DNS** : Je suis ambigüe sur cette recommandation , mais je l'ai vu à plusieurs reprise. Il y a ici une relation forte entre gestion / maintenance de l'infrastructure et la performance. Si vous définissez uniquement des adresses IP effectivement nous économisons une requête __DNS__. Cependant ceci peut avoir un coût sur la gestion, car vous perdez la flexibilité de pouvoir modifier l'infrastructure environnante sans modifier l'application. Faut donc voir selon votre problème.
* **Désactivation de la gestion des fichier .htaccess** : telle que présenter lors de la démonstration des fichiers __.htaccess__ afin d'éviter que Apache cherche ce fichier dans chaque répertoire désactivé le complètement. 
* **Utilisez Apache pour les données dynamique** : Apache est un couteau suisse du web, nous pouvons faire énormément de chose . Par contre Apache n'est pas le serveur web est un peu gourmand avec le temps d'autre solution on vu le jours, avec certes  moins de fonctionnalité mais plus rapide. Si vous avez des problèmes pour fournir vos clients vous pourriez configurer un serveur __lighttpd__ ou __ngnix__ pour fournir l'ensemble du contenu statique (images, vidéos , ...) et Apache pour le contenu dynamique (__php__, ...).

## <a name="perf_protection" /> Protection de votre site web 

Je vais faire un petit écart sur la considération des performances, car peut importe les configurations que vous mettrez en place si vous êtes victimes d'une [DDOS](https://fr.wikipedia.org/wiki/Attaque_par_d%C3%A9ni_de_service) votre site va s'écraser. L'objectif de la solution est simple, un système analyse les logs de votre site web et selon des règles établie va bloquer l'adresse de provenance du client. Les règles peuvent être simple telle qu'un nombre répété d'erreur 404 vers votre site ou ou alors un nombre de requête dans un délais définie , indiquant que nous avons affaire à un robot. 
Le système mettra en place une règles __iptables__ __firewall__ applicatif sur la machine.
Le logiciel ce nomme : [fail2ban](http://www.fail2ban.org).

REF: https://www.digitalocean.com/community/tutorials/how-to-protect-an-apache-server-with-fail2ban-on-ubuntu-14-04
REF: http://r3dux.org/2013/06/how-to-stop-apache-dos-attacks-with-fail2ban/

* URL :
    * http://httpd.apache.org/docs/current/misc/perf-tuning.html
    * https://www.devside.net/articles/apache-performance-tuning
    * http://www.monitis.com/blog/2011/07/05/25-apache-performance-tuning-tips
    * https://wiki.mikejung.biz/Apache


# <a name="Reference" /> Référence :

* http://httpd.apache.org/docs/current/misc/perf-tuning.html
* https://www.devside.net/articles/apache-performance-tuning
* http://www.monitis.com/blog/2011/07/05/25-apache-performance-tuning-tips
* https://wiki.mikejung.biz/Apache




