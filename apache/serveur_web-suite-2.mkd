<meta http-equiv='Content-Type' content='text/html; charset=utf-8' /> 
<style>
pre{background:#F8F8FF; border:black dashed 1px; padding:6px}
</style>

TODO corriger les \_

# Index 

* [ Autorisation d'accès avec authentification local](#auth_local_access) 
       * [ Création du fichier de mot de passe ( __htpasswd__ )](#htpasswd) 
       * [ Gestion d'accès des utilisateurs et par groupe](#htpasswd_group) 
       * [ Utilisation de système d'authentification externe](#Auth_methode) 
           *Mysql
           *Ldap 
       * [ Combinaison d'une authentification externe et local](#htpasswd_file-et-externe) 
* [ Webdav pour avoir un lieu de stockage de fichiers](#mod_webdav) 
       * [ Client webdav sous GNU/Linux](#mod_webdav-client) 
       * [ Sécuriser son webdav ](#mod_webdav-securisation) 
       * [ Sécuriser son webdav pour chaque opération](#mod_webdav-securisation_granulaire) 
           * [ Limiter l'utilisation du service webdav ](#mod_webdav-securisation_limitation) 
* [ Performance et analyse d'apache](#performance) 
       * [ Visualisation de la situation](#perf_view) 
       * [ Simulation de charge sur le serveur](#perf_simulation) 
           * [ Utilisation du logiciel ApacheBench (AB)](#perf_bench_ab) 
               * [ Utilisation du logiciel ApacheBench (AB) avec Authentification](#perf_bench_ab_auth) 
           * [ Utilisation du Siege ](#perf_bench_seige) 
               * [ Utilisation du logiciel Siege  avec Authentification](#perf_bench_siege_auth) 
               * [ Avantage de l'utilisation du logiciel Siege](#perf_bench_siege_plus) 
           * [ Utilisation de JMeter](#perf_bench_jmeter) 
           * [ Utilisation de Ngrinder](#perf_bench_ngrinder) 
       * [ Analyse des performances ](#perf_view) 
           * [ Visualisation des processus Apache](#perf_view_apache_process) 
           * [ Visualisation des pages traité par le processus](#perf_view_apache_process_status) 
           * [ Analyse problème de charge CPU](#perf_view_cpu_prob) 
* [ Référence :](#Reference) 

# <a name="auth_local_access" /> Autorisation d'accès avec authentification local

Nous allons maintenant revoir notre configuration pour l'accès au répertoire admin , au lieu d'utiliser un système de limitation par adresse ip, nous allons mettre en place une authentification local. La limitation par adresse ip c'est bien, malheureusement quand nous sommes en mouvement nous n'avons pas toujours la même adresse ip. Nous allons utiliser le module apache [mod\_authn\_core](https://httpd.apache.org/docs/2.4/mod/mod_authn_core.html#authtype). 

Commençons par valider que ce dernier est bien chargé :

        $ ls -l /etc/apache2/mods-enabled/*auth*
        lrwxrwxrwx 1 root root 33 Nov 25 08:20 /etc/apache2/mods-enabled/auth_basic.load -> ../mods-available/auth_basic.load
        lrwxrwxrwx 1 root root 33 Nov 25 08:20 /etc/apache2/mods-enabled/authn_core.load -> ../mods-available/authn_core.load
        lrwxrwxrwx 1 root root 33 Nov 25 08:20 /etc/apache2/mods-enabled/authn_file.load -> ../mods-available/authn_file.load
        lrwxrwxrwx 1 root root 33 Nov 25 08:20 /etc/apache2/mods-enabled/authz_core.load -> ../mods-available/authz_core.load
        lrwxrwxrwx 1 root root 33 Nov 25 08:20 /etc/apache2/mods-enabled/authz_host.load -> ../mods-available/authz_host.load
        lrwxrwxrwx 1 root root 33 Nov 25 08:20 /etc/apache2/mods-enabled/authz_user.load -> ../mods-available/authz_user.load

Comme nous pouvons le constater plusieurs module d'authentification sont chargé par défaut incluant [mod_authn_core](https://httpd.apache.org/docs/2.4/mod/mod_authn_core.html#authtype) (ligne 2 :P )

Pour information voici le contenu :

        $ cat /etc/apache2/mods-enabled/authn_core.load 
        LoadModule authn_core_module /usr/lib/apache2/modules/mod_authn_core.so

Apache charge un fichier **.so** qui est l'équivalent d'un **DLL** qui permet d'avoir une suite d'instruction en plus, disponible pour le service. Le module fut compilé pour la version spécifique d'Apache il n'est pas possible de prendre un module écrit pour la version 2.2 et le faire fonctionner sur la version 2.4 . Nous verrons plus en détail plus tard les modules apaches cependant il est bien d'avoir une compréhension, sommaire du fonctionnement.


Procédons à la modification du fichier de configuration de notre site par défaut (**/etc/apache2/sites-enabled/siteA-ssl.conf**). Voici la configuration :

        <Directory /data/vhosts/siteA/docroot/admin/ >
            Options none
            AllowOverride None
            #  Section d'authentification
            AuthType Basic
            AuthName "Authentication Required"
            AuthUserFile "/data/vhosts/siteA/privates/.htpasswd-admin"
            Require valid-user
        </Directory>

Analysons les paramètres :

* [AuthType](https://httpd.apache.org/docs/2.4/fr/mod/mod_authn_core.html#authtype) : Définie le type de module d'authentification , nous avions vu que plusieurs module été disponible dans le cas présent nous utiliserons le mode __Basic__. Il est important de souligné que dans le mode de communication actuelle le transfert du mot de passe est transmis en claire . Afin d'augmenter le niveau de sécurité nous devrions activer le support __SSL__ nous y reviendrons. Voici les type disponibles :
    * [Basic](https://httpd.apache.org/docs/2.4/fr/mod/mod_auth_basic.html) 
    * [Digest](https://httpd.apache.org/docs/2.4/fr/mod/mod_auth_digest.html)
    * [form](https://httpd.apache.org/docs/2.4/fr/mod/mod_auth_form.html)
* [AuthName](https://httpd.apache.org/docs/2.4/fr/mod/mod_authn_core.html#authname) : message affiché à l'utilisateur afin qu'il entre les informations d'authentification requis .
* [AuthUserFile](https://httpd.apache.org/docs/2.4/fr/mod/mod_authn_file.html#authuserfile) : Ficher local sur le serveur web contenant la liste des utilisateurs et mot de passe permettant de valider l'authentification des utilisateurs.
* [Require](https://httpd.apache.org/docs/2.4/fr/mod/mod_authz_core.html#require) : Instruction spécifiant le critère d'autorisation, dans les démonstrations passé nous avions utilisé les adresses ip comme critère ici nous pourrons utiliser des noms d'utilisateur ou définir comme dans le cas présent n'importe quelle utilisateur s'authentifiant avec succès. 


Validons qu'il n'y pas d'erreur syntaxique et rechargeons le fichier de configuration :

        $ sudo apache2ctl configtest && sudo service apache2 restart
        Syntax OK
        * Restarting web server apache2
        *    ...done.

Donc si nous allons à l'URL nous avons bien le message demandant le nom d'utilisateur et mot de passe :

![imgs/auth_admin-request.png](imgs/auth_admin-request.png)

Par contre, comme nous n'avons jamais définie de nom d'usagé / mot de passe quand on rentre n'importe quoi nous avons une [erreur 500](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes#5xx_Server_Error) indiquant un problème sur le serveur. Le message d'erreur sur le serveur est très claire :

        $ sudo tail /var/log/apache2/error.log
        [Tue Dec 01 08:40:05.516453 2015] [authn_file:error] [pid 457:tid 2869857088] (2)No such file or directory: [client 172.17.42.1:52744] AH01620: Could not open password file: /data/vhosts/siteA/privates/.htpasswd-admin


## <a name="htpasswd" /> Création du fichier de mot de passe ( __htpasswd__ )

Pour réaliser la création du fichier contenant le nom d'utilisateur et le mot de passe nous avons besoin de l'application **htpasswd** , cette application est disponible dans le pacquage : **apache2-utils**

        $ sudo apt-get install apache2-utils

Nous allons faire la création du fichier :

        $ sudo htpasswd -c /data/vhosts/siteA/privates/.htpasswd-admin admin
        New password:
        Re-type new password:
        Adding password for user admin
        $ sudo htpasswd  /data/vhosts/siteA/privates/.htpasswd-admin robert
        New password: 
        Re-type new password: 
        Adding password for user robert

**IMPORTANT** : entre le 2 commandes il y a une différence, pour réaliser la création du fichier j'ai utilisé l'option **-c** par la suite je ne l'utilise pas . En fait il faut surtout pas que je l'utilise sinon ça vide le fichier pour créer un nouveau fichier , nous perdons donc l'information :-/ . Ouin c'est dangereux, heureusement que vous savez ce que vous faites :D, sinon il y a les backups ...

Visualisons le contenu du fichier, dans les 2 cas j'ai mis le même mot de passe (toto) :

        $ cat /data/vhosts/siteA/privates/.htpasswd-admin
        admin:$apr1$6gHZyTty$lxisZ66JPD7yK6K8fcXlU.
        robert:$apr1$fUI6se3h$40k/ftJPUtVOrptHlMiYB0

Si nous retournons à l'URL nous devrions avoir une authentification avec succès avec l'un ou l'autre des utilisateurs. La page indiquant que nous sommes dans une "section prive" devrais s'afficher.


## <a name="htpasswd_group" /> Gestion d'accès des utilisateurs et par groupe

L'exemple ci-dessus est vraiment la méthode la plus simple vous avec un fichier de mot de passe peut importe l'utilisateur s'il réussie à établir une connexion ce dernier à accès. Par contre si vous avez plusieurs section qui oblige l'utilisation d'une authentification vous aimeriez probablement utilisé 1 fichier de mot de passe et définir qui à accès dans le fichier de configuration apache.

Si vous connaissez le nom des utilisateurs vous pouvez changé la ligne suivante avec la liste des nom : 

            Require valid-user

Voici la version avec les nom spécifiques :

            Require user admin thomas robert


Ceci est bien mais si vous avez travailler un peu avec ce mode de définition l'ajout et la suppression d'un utilisateur est ennuyeuse comme ceci est définie dans la configuration apache ou son extension via le fichier **.htaccess** ce ne peut pas être délégué .

Nous allons donc définir des groupes qui pourrons être éditer éventuellement par un tiers ou être réutilisé dans un autre contexte. Nous allons créer un fichier texte avec la définition des groupes. 

        $ cat  /data/vhosts/siteA/privates/htgroupe 
        admins: admin robert 
        superAdmins: admin thomas
        noobs: robert

Nous allons définir ce fichier de groupe et définir quelle groupe peut accéder au dossier , voici donc la nouvelle configuration :

        <Directory /data/vhosts/siteA/docroot/admin/ >
            Options none
            AllowOverride None
            #  Section d'authentification
            AuthType Basic
            AuthName "Authentication Required"
            AuthUserFile "/data/vhosts/siteA/privates/.htpasswd-admin"
            AuthGroupFile "/data/vhosts/siteA/privates/htgroupe"
            Require group admins
        </Directory>


Donc nous voyons 2 changements :

* **AuthGroupFile** : ceci permet de définir le fichier groupe qui sera lut avec l'information des membres
* **Require group admins** : contenant le ou les groupes qui sont autorisé 


Réalisons maintenant la validation syntaxique et redémarrons apache : 

        $  sudo apachectl configtest && sudo /etc/init.d/apache2 restart
        AH00526: Syntax error on line 33 of /etc/apache2/sites-enabled/siteA-ssl.conf:
        Invalid command 'AuthGroupFile', perhaps misspelled or defined by a module not included in the server configuration
        Action 'configtest' failed.
        The Apache error log may have more information.

**OUPSS** une erreur :D , bon 2 possibilité :

* l'option **AuthGroupFile** est mal écrite ou n'existe pas
* Il manque un module ...

Je vais profité de l'occasion pour remontré l'importance et la qualité de la documentation du site d'apache. 

TODO : ajouter le screen shot pour le module 

Effectivement si nous listons les modules actifs et les modules disponible il nous manque le module pour la gestion du fichier de groupe :

        $ ls /etc/apache2/mods-enabled/*group* /etc/apache2/mods-available/*group*
        ls: cannot access /etc/apache2/mods-enabled/*group*: No such file or directory
        /etc/apache2/mods-available/authz_groupfile.load

Activons se dernier et nous allons confirmer que ceci fonctionne à présent :

        $ cd /etc/apache2/mods-enabled
        $ sudo ln -s ../mods-available/authz_groupfile.load .
        $ sudo apachectl configtest && sudo /etc/init.d/apache2 restart
        Syntax OK
         * Restarting web server apache2
            ...done.

Nous pouvons maintenant valider l'accès : https://www.linux202-sitea.com/admin/


## <a name="Auth_methode" /> Utilisation de système d'authentification externe

### Mysql

Documentation : https://blog.froese.org/2014/06/13/authn-dbd-mysql-ubuntu-trusty/

### Ldap 

Documentation : https://httpd.apache.org/docs/2.4/mod/mod_authnz_ldap.html


## <a name="htpasswd_file-et-externe" /> Combinaison d'une authentification externe et local

Bien que nous n'ayons pas traiter l'utilisation d'une authentification externe j'aimerai glisser un mot sur la possibilité de combiner interne et externe. 

Voici un exemple de configuration d'authentification utilisant une authentification **ldap**  et une authentification par fichier :

        <Directory "/www/docs/private">

            AuthName "Private"
            AuthType Basic
            AuthBasicProvider file ldap
            AuthUserFile "/usr/local/apache/passwd/passwords"
            AuthLDAPURL ldap://ldaphost/o=yourorg
            Require valid-user

         </Directory>

Dans le cas présent si l'authentification avec __LDAP__ ou depuis le fichier de mot de passe est réussie avec une utilisateur ce dernier aura accès.

Référence :

* http://httpd.apache.org/docs/current/fr/howto/auth.html

# <a name="mod_webdav" /> Webdav pour avoir un lieu de stockage de fichiers

Lors de la formation sur __rsnapshot__ j'avais fait mention de l'utilisation d'une serveur **webdav** pour faire le transfert de fichier . Malheureusement nous n'étions pas encore rendu à la mise en place d'apache nous n'avions donc pas pu couvrir cette fonctionnalité. Je n'avais pas pour objectif primaire de faire la démonstration puis suite à des demandes de participants voici une exemple de configuration. Après tous la formation elle est pour **VOUS** :D !!

Le protocole [webdav](http://www.webdav.org/) permet de réaliser du transfert de fichier, il existe plusieurs client pour toutes les plateformes , nous verrons la possibilité de __mounté__ le système de fichier sous Linux. Mettons en place la configuration puis nous analyserons ensemble la configuration . 

Nous allons activer 2 modules **mod\_dav** et **mod\_dav\_fs** , 2 méthodes pour réaliser l'opération la réalisation des liens symbolique manuellement ou l'utilisation de la commande **a2enmod**.

        $ sudo a2enmod dav
          Enabling module dav.
          To activate the new configuration, you need to run:
            service apache2 restart
        $ sudo a2enmod dav_fs
        Considering dependency dav for dav_fs:
          Module dav already enabled
          Enabling module dav_fs.
          To activate the new configuration, you need to run:
            service apache2 restart

Maintenant nous allons modifier la configuration du __siteA__ afin de pouvoir utiliser le répertoire __/webdav__ comme répertoire de stockage . Voici le contenu à ajouter :

        <Directory /data/vhosts/siteA/docroot/webdav/>
            Dav On
        </Directory>

**WOwww** magie :D, validons tous de même peut-être que je vous ment :P, ça semble trop facile ... Créons un fichier dans le répertoire __/data/vhosts/siteA/docroot/webdav/__

        $ cat /data/vhosts/siteA/docroot/webdav/toto
        super fichier dans webdav

Si vous accédez à l'URL : https://www.linux202-sitea.com/webdav/ , vous aurez quelques chose qui ressemble à ceci , vous pouvez cliquez sur le fichier __toto__ et voir son contenu :

![webdav_simple-step1.png](./imgs/webdav_simple-step1.png)

Ceci est bien pratique pour offrir du contenu mais pourquoi mettre en place un __webdav__ alors que l'on peut aussi afficher le contenu avec apache sans avoir la couche **webdav** . L'intérêt réside principalement lors de la manipulation de fichier d'écriture et modification , ou la synchronisation de contenu. Voyons le tous avec un client pour nous permettre l'écriture... 


## <a name="mod_webdav-client" /> Client webdav sous GNU/Linux

Il existe plusieurs client sur internet, ici je ne couvrirais que ceux qui sont libre bien entendu :P, commençons par celui que j'utilise principalement soit l'accès avec un point de montage . L'avantage principale de cette solution est de me permettre d'avoir accès au fichier comme si c'était des fichiers locaux. 

Nous avons besoin du logiciel **davfs2** , sous __Ubuntu__ :

        $ sudo apt-get install davfs2

Par la suite nous montons le __webdav__ comme si c'était un périphérique :

        $ sudo mkdir /mnt/dav
        $  sudo mount.davfs https://www.linux202-sitea.com/webdav/ /mnt/dav/
        [sudo] password for xerus:
        Please enter the username to authenticate with server
        https://www.linux202-sitea.com/webdav/ or hit enter for none.
          Username:
        Please enter the password to authenticate user  with server
        https://www.linux202-sitea.com/webdav/ or hit enter for none.
          Password:
        mount.davfs: the server certificate is not trusted
        issuer:      training, X3rus, Montreal, Quebec, CA
        subject:     training, X3rus, Montreal, Quebec, CA
        identity:    www.linux202-sitea.com
        fingerprint: e5:5c:6b:4f:c3:0b:62:9a:55:49:6d:ab:4b:5d:54:c7:16:2b:bd:5d
        You only should accept this certificate, if you can
        verify the fingerprint! The server might be faked
        or there might be a man-in-the-middle-attack.
        Accept certificate for this session? [y,N] y


Nous pouvons à présent lister le contenu du répertoire et voir le fichier __toto__ :

        $ ls -ld /mnt/dav/
        drwxr-xr-x 3 root root 104 May 31 17:19 /mnt/dav/
        $ ls -l /mnt/dav/
        total 1
        drwx------ 2 root root  0 May 31 17:08 lost+found
        -rw-r--r-- 1 root root 26 May 31 08:46 toto
        $ cat /mnt/dav/toto
        super fichier dans webdav

Réalisons une écriture d'un fichier !!! 

        $ touch /mnt/dav/titi
        touch: cannot touch ‘/mnt/dav/titi’: Permission denied
        $ mkdir /mnt/dav/rep
        mkdir: cannot create directory ‘/mnt/dav/rep’: Permission denied

Une idée de la source du problème ?? 
Si nous regardons les permissions assigné au répertoire **/mnt/dav** il n'est pas possible d'écrire dans le répertoire localement car ce dernier est propriété de __root__ . Nous allons modifier la configuration afin de permettre au groupe __users__d'écrire dans ce dernier, groupe dont je fait partie.

        $ ls -ld /mnt/dav/
        drwxr-xr-x 3 root root 104 May 31 17:19 /mnt/dav/
        $ sudo chown :users /mnt/dav
        $ sudo chmod g+w /mnt/dav
        $ ls -ld /mnt/dav
        drwxrwxr-x 3 root users 104 May 31 17:19 /mnt/dav/

Recommençons à présent !

        $ touch /mnt/dav/titi
        touch: cannot touch ‘/mnt/dav/titi’: Input/output error

**COOL** , vous me direz pourquoi cool ?!? Car nous n'avons pas le même message nous avançons donc vers la solution :D, le chemin vers la solution est rarement direct ;-).

Je propose de regarder les logs sur le serveur et de refaire la même opération :

        $ tail -f /data/vhosts/siteA/logs/ssl_error.log
        [ ... OUTPUT COUPÉ ... ]
        [Tue May 31 17:26:19.965651 2016] [dav:error] [pid 62] [client 172.17.42.1:47400] Could not save .locknull file.  [500, #0]
        [Tue May 31 17:26:19.965726 2016] [dav:error] [pid 62] (2)No such file or directory: [client 172.17.42.1:47400] Error opening /data/vhosts/siteA/docroot/webdav/.DAV/.locknull for writing  [500, #0]


Nous voyons bien des erreurs qui provienne du modules **dav** , le message indique qu'il n'a pas pu écrire le fichier de verrou (__lock__) dans le répertoire : __/data/vhosts/siteA/docroot/webdav/.DAV/__. Regardons les permissions du répertoires :

        $  ls -ld /data/vhosts/siteA/docroot/webdav/.DAV/
        ls: cannot access /data/vhosts/siteA/docroot/webdav/.DAV/: No such file or directory
        $ ls -ld /data/vhosts/siteA/docroot/webdav/
        drwxr-xr-x 2 root root 4096 May 31 17:19 /data/vhosts/siteA/docroot/webdav/

Donc le répertoire **.DAV** n'est pas présent si nous regardons un niveau plus haut le répertoire **webdav** uniquement l'utilisateur __root__ peut écrire dans le répertoire. Lorsque nous communiquons avec le système de __webdav__ l'ensemble des communication transige par le service apache. Telle que mentionné dans des cours précédent le processus d'apache n'est pas exécuté sous l'usager __root__ afin de limité les opérations possible par le site web , surtout si ce dernier est compromit. Validons l'utilisateur qui exécute le service apache.

        $ $ ps aux | grep apach
        root        55  0.0  0.9  90412 19440 ?        Ss   17:04   0:00 /usr/sbin/apache2 -k start
        www-data    60  0.0  0.5  90652 10956 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    61  0.0  0.4  90544  9400 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    62  0.0  0.5  90652 11108 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    63  0.0  0.5  90660 11376 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    64  0.0  0.5  90652 11424 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    78  0.0  0.4  90544  9400 ?        S    17:05   0:00 /usr/sbin/apache2 -k start
        www-data    90  0.0  0.2  90444  5472 ?        S    17:09   0:00 /usr/sbin/apache2 -k start

Dans notre cas l'utilisateur est **www-data**, je vais donc ajuster la configuration afin de permettre à ce dernier d'écrire dans le répertoire. 

        $ sudo chown www-data /data/vhosts/siteA/docroot/webdav/
        $ ls -ld /data/vhosts/siteA/docroot/webdav/
        drwxr-xr-x 2 www-data root 4096 May 31 17:19 /data/vhosts/siteA/docroot/webdav/

C'est l'occasion de refaire un teste :

        $ touch /mnt/dav/titi
        $ ls -l /mnt/dav/titi
        -rw-r--r-- 1 xerus xerus  0 May 31 17:36 titi

**Cool** regardons le résultat sur le serveur 

        $ ls -l /data/vhosts/siteA/docroot/webdav
        total 4
        -rw-r--r-- 1 www-data www-data  0 May 31 17:37 titi
        -rw-r--r-- 1 root     root     26 May 31 08:46 toto


Nous voyons les permissions sur le serveur appartienne à l'utilisateur qui à écrit le fichier donc le processus **apache** soit l'utilisateur **www-data** dans notre cas.

TODO : Voir avec nautilus !!

## <a name="mod_webdav-securisation" /> Sécuriser son webdav 

Ceci est vraiment intéressant, mais je doute que vous désirez mettre en place un lieu de stockage sur internet libre à tous le monde de transférer des données. Vous désirez fort probablement pouvoir protéger vos données et ceux de vos collaborateur. J'en profite pour souligner l'importance de réaliser la configuration avec une communication **httpS** afin que lors de l'échange du nom d'utilisateur / mot de passe ces derniers soit chiffrés.


Afin de réaliser la démonstration de la mise en place de la sécurisation je vais faire la création de répertoire et fichier sous le répertoire **webdav** :

        $ cd /data/vhosts/siteA/docroot/webdav
        $ sudo mkdir -p commun   devs   marketing   marketing/campagne_GPL   marketing/campagne_FSF   finance   finance/super_secret
        $ sudo touch commun/activites_pour_nowel   commun/le_footgolf   devs/pourquoi_les_licences_c_important   devs/les_bases_de_python   marketing/campagne_GPL/copyleft_est_un_copyright   marketing/campagne_GPL/la_licence_c_important   marketing/campagne_FSF/Le_libre_pour_tous   marketing/campagne_FSF/Le_libre_c_pour_TOI   marketing/campagne_FSF/Le_libre_c_mieux   marketing/campagne_future_a_planifier   finance/benefice   finance/client_prospect   finance/client   finance/super_secret/lettre_de_recouvrement_de_la_banque   finance/super_secret/compte_au_panama

Ce qui donne ceci :

        $ ls -1R
        ./commun:
        activites_pour_nowel
        le_footgolf

        ./devs:
        les_bases_de_python
        pourquoi_les_licences_c_important

        ./finance:
        benefice
        client
        client_prospect
        super_secret

        ./finance/super_secret:
        compte_au_panama
        lettre_de_recouvrement_de_la_banque

        ./marketing:
        campagne_FSF
        campagne_GPL
        campagne_future_a_planifier

        ./marketing/campagne_FSF:
        Le_libre_c_mieux
        Le_libre_c_pour_TOI
        Le_libre_pour_tous

        ./marketing/campagne_GPL:
        copyleft_est_un_copyright
        la_licence_c_important


Nous allons réutiliser ce que nous avons appris plus tôt avec la limitation avec authentification et la gestion d'accès par groupe. Avant de mettre en place la limitation nous allons définir notre stratégie par groupe :

* toutes personnes authentifier peut accéder à la section **commun**
* le groupe DEVS peut accéder à la section **devs**
* le groupe FINANCE peut accéder à la section **finance** mais pas le répertoire **super\_secret**
* le groupe FINANCE\_CA peut accéder à la section **finance** ainsi que le répertoire **super\_secret**
* le groupe MARKETING peut accéder à la section **marketing**

Nous allons donc faire la création des groupes et utilisateurs :


        $ cat /data/vhosts/siteA/privates/.htpasswd-admin
        admin:$apr1$U8mylBZo$3aAVkmX.CkWpuwsx7/HT80

        $ cat /data/vhosts/siteA/privates/htgroupe
        [ ... OUTPUT COUPÉ ... ]
        DEVS: bob robert bonny
        FINANCES: lee peter perry nesta
        FINANCES_CA: perry nesta
        MARKETING: dj-foot wailers

        $ LST_USERS=$(cat /data/vhosts/siteA/privates/htgroupe | grep ^[A-Z] | cut -d ":" -f 2 | tr -s " " "\n" | sort | uniq )
        $ for user in $LST_USERS ; do echo "le_mot_de_passe" | sudo htpasswd -i /data/vhosts/siteA/privates/.htpasswd-admin  $user ; done
        Adding password for user bob
        Adding password for user bonny
        Adding password for user dj-foot
        Adding password for user lee
        Adding password for user nesta
        Adding password for user perry
        Adding password for user peter
        Adding password for user robert
        Adding password for user wailers 
        $ cat .htpasswd-admin 
        admin:$apr1$U8mylBZo$3aAVkmX.CkWpuwsx7/HT80
        bob:$apr1$W.1roeGD$aLq8NNfz.XEpbrtZ.LEdu.
        bonny:$apr1$4BxK5D3a$ludP1cVjXYyJ5WN/5cyQa0
        dj-foot:$apr1$BmNukD9R$mYXNIPMNgYHV2IwnRr/lO0
        lee:$apr1$IobzpSiP$QAk5sntB/I/o5ebasxNBE.
        nesta:$apr1$WBLpPKWv$wu8AXh9xo4xNWUkkzzWHe0
        perry:$apr1$DoWpviXH$Mt3iVvf/4/huSdumjnsqx0
        peter:$apr1$SkCasVdW$4IgS2L3TvHPxdN4NUJICS1
        robert:$apr1$YS.v9LIw$z/Uc4cA/REfZ1QqWUZlLI.
        wailers:$apr1$ZuDB1LPB$DYcrun7qhjyxY6mX326Fq/


Voilà nous avons donc maintenant l'ensemble de nos groupes de créés ainsi que nos utilisateurs avec le même mot de passe mais pour les besoins de la démonstration pas besoin de plus . Ceci ma aussi permet de montrer comment automatiser via un script la création / assignation de mot de passe avec la commande **htpasswd**.


Mettons en place la nouvelle configuration pour le site web et nous allons réaliser quelque essaye :

        $  cat /etc/apache2/sites-enabled/siteA-ssl.conf
        [ ... OUTPUT COUPÉ ... ]
        ################
        # Setup WEBDAV #
        ################
        <Directory /data/vhosts/siteA/docroot/webdav/>
            Dav On

            #  Section d'authentification
            AuthType Basic
            AuthName "Authentication Required"
            AuthUserFile "/data/vhosts/siteA/privates/.htpasswd-admin"
            AuthGroupFile "/data/vhosts/siteA/privates/htgroupe"
            Require valid-user
         </Directory>
                                                                                                                                       <Directory /data/vhosts/siteA/docroot/webdav/devs>
            Require group DEVS
         </Directory>
         <Directory /data/vhosts/siteA/docroot/webdav/finance>
            Require group FINANCES
         </Directory>
         <Directory /data/vhosts/siteA/docroot/webdav/finance/super_secret>
            Require group FINANCES_CA
         </Directory>
         <Directory /data/vhosts/siteA/docroot/webdav/marketing/>
            Require group MARKETING
         </Directory>
        [ ... OUTPUT COUPÉ ... ]


C'est le temps d'expliquer un peu le contenu , pour la racine du **webdav** je définie l'authentification avec le fichier de mot de passe et celui contenant la liste des membres des groupes. Dans cette section je définie que tous le monde peu avoir accès grâce  à l'instruction **Require valid-user**. Avec cette configuration toute personne authentifier aura accès aux fichiers à la racine du __webdav__ ainsi que **tous** les sous répertoires !!
Par la suite je définie des limitations par répertoire , que ce soit pour les **devs** , les **finances** , etc. Chaque répertoire est limité par groupe, l'avantage de cette méthode est qu'il n'y a pas répétition des instructions d'authentification ceci aide la visibilité et la gestion dans le temps :D.

Voyons maintenant le résultat de cette configuration , je vais établir une connexion avec l'utilisateur : **bob** ce dernier n'est membre que du groupe **DEVS** . Accédons à l'URL : https://www.linux202-sitea.com/webdav/

Voici ce que l'on voit : 

![webdav_auth_multi-group.png](./imgs/webdav_auth_multi-group.png)

Suite à l'authentification avec succès nous voyons bien les fichier __titi__ et __toto__ à la racine  ainsi que le répertoire **commun**. Comme l'utilisateur est membre du groupe **DEVS** il voit aussi le répertoire **devs** mais PAS les autres répertoires dont il n'a pas les autorisations ! 

Si je réalise la même opérations avec un point de montage **GNU/Linux**, la vue est un peu différente

        $ sudo mount.davfs https://www.linux202-sitea.com/webdav/ /mnt/dav/
        Please enter the username to authenticate with server
        https://www.linux202-sitea.com/webdav/ or hit enter for none.
          Username: bob 
        Please enter the password to authenticate user bob with server
        https://www.linux202-sitea.com/webdav/ or hit enter for none.
          Password:  

        $ ls -l /mnt/dav/
        total 2
        drwxr-xr-x 2 root  root   0 Jun  1 08:54 commun
        drwxr-xr-x 2 root  root   0 Jun  1 08:53 devs
        drwxr-xr-x 2 root  root  64 Jun  1 08:52 finance
        drwx------ 2 root  root   0 May 31 17:08 lost+found
        drwxr-xr-x 2 root  root  64 Jun  1 08:51 marketing
        -rw-r--r-- 1 xerus xerus  0 May 31 17:37 titi
        -rw-r--r-- 1 root  root  26 May 31 08:46 toto

        $ ls -l /mnt/dav/finance/
        total 0
        $ ls -l /mnt/dav/devs/
        total 0
        -rw-r--r-- 1 root root 0 Jun  1 08:53 les_bases_de_python
        -rw-r--r-- 1 root root 0 Jun  1 08:53 pourquoi_les_licences_c_important
        $ ls -l /mnt/dav/marketing/
        total 0

Donc lors de l'accès avec un point de montage les répertoires à la racine sont visible mais le contenu est vide ! Ceci est vraiment un détail mais ce doit être pris en considération selon la situation. 
Vous pourrez faire les testes avec les autres utilisateurs ... :D.

## <a name="mod_webdav-securisation_granulaire" /> Sécuriser son webdav pour chaque opération

Il est possible d'y allé de manière plus granulaire, bien entendu plus nous y allons de manière granulaire plus la gestion peut devenir compliqué. C'est à vous de faire le bon choix et d'être en mesure de changé d'avis si vous constater que la première option n'était pas la bonne :D.

Dans l'exemple ci-dessus nous limitons l'accès par répertoire, cependant une fois que la personne à accès au répertoire il peut réalisé l'ensemble des opérations ( Écrire, Supprimer , Copier , Lire , ... ). Comme l'ensemble des opérations sous réalisé à travers le processus Apache il n'est pas possible de limité les accès via le système de fichier. Alors comment faire pour offrir un accès en lecture seul et ne permettre que certain type d'opération.

TODO: changer les liens pour les avoir en Francais 

C'est l'occasion de voir une autre instruction [Limit](https://httpd.apache.org/docs/2.4/mod/core.html#limit) et [LimitExcept](https://httpd.apache.org/docs/2.4/mod/core.html#limitexcept)

### <a name="mod_webdav-securisation_limitation" /> Limiter l'utilisation du service webdav 

Nous allons pouvoir réaliser une limitation sur les requêtes HTTP suivante : 

* Méthode générale du [protocole HTTP](https://en.wikipedia.org/wiki/Atomic_commit) :
    * __GET__ : C'est la méthode la plus courante pour demander une ressource. Une requête GET est sans effet sur la ressource, il doit être possible de répéter la requête sans effet.
    * __POST__ : Cette méthode est utilisée pour transmettre des données en vue d'un traitement à une ressource (le plus souvent depuis un formulaire HTML). L'URI fourni est l'URI d'une ressource à laquelle s'appliqueront les données envoyées. Le résultat peut être la création de nouvelles ressources ou la modification de ressources existantes. À cause de la mauvaise implémentation des méthodes HTTP (pour Ajax) par certains navigateurs (et la norme HTML qui ne supporte que les méthodes GET et POST pour les formulaires), cette méthode est souvent utilisée en remplacement de la requête PUT, qui devrait être utilisée pour la mise à jour de ressources.
    * __PUT__ : Cette méthode permet de remplacer ou d'ajouter une ressource sur le serveur. L'URI fourni est celui de la ressource en question.
    * __DELETE__ : Cette méthode permet de supprimer une ressource du serveur.
    * __CONNECT__ : Cette méthode permet d'utiliser un proxy comme un tunnel de communication
    * __OPTIONS__ : Cette méthode permet d'obtenir les options de communication d'une ressource ou du serveur en général.
    * __PATCH__ : Cette méthode permet, contrairement à PUT, permet de faire une modification partielle d'une ressource
* Méthode spécifique au [protocole __webdav__](https://en.wikipedia.org/wiki/WebDAV):
    * __PROPFIND__ : Cette méthode permet la récupération de propriété, en format __XML__, depuis une ressource du serveur. Cette méthode permet aussi d'extraire un groupe de structure (aussi nommé répertoire hiérarchique ) depuis le serveur. 
    * __PROPPATCH__ : Cette méthode permet de modifier et supprimer plusieurs propriété d'une ressource avec une action de type [Atomic act](https://en.wikipedia.org/wiki/Atomic_commit).
    * __MKCOL__ : Cette méthode permet la création de répertoire.
    * __COPY__ : Cette méthode permet de copier une ressource depuis une URI vers une autre
    * __MOVE__ : Cette méthode permet de déplacer une ressource depuis une URI vers une autre
    * __LOCK__ : Cette méthode permet de verrouiller une ressource, __Webdav__ permet le verrouillage exclusif ou partagé.
    * __UNLOCK__ : Cette méthode permet de retirer le verrouillage d'une ressource.


Donc nous pouvons y allé de manière granulaire sur les autorisations, 2 instructions est disponibles :

* [Limit](https://httpd.apache.org/docs/2.4/fr/mod/core.html#limit) : Nous permet de lister les méthodes permises par un utilisateur ou un groupe.
* [LimitExcept](https://httpd.apache.org/docs/2.4/fr/mod/core.html#limitexcept) : Nous permet de définir les méthodes **NON**  permises donc par défaut ceci est autorisé.

Afin d'avoir le contexte dans lequel cette instruction peut être utilisé :

![limit_screenshot-doc.png](./imgs/limit_screenshot-doc.png)

Résultat si nous désirions avoir un accès en Lecture seule et un accès complet pour la section __dev__ par exemple ceci donnera : 

        $ cat /data/vhosts/siteA/privates/htgroupe
        [ ... OUTPUT COUPÉ ... ]
        DEVS: bob robert bonny
        DEVS_RO : nesta
        FINANCES: lee peter perry nesta
        [ ... OUTPUT COUPÉ ... ]

Je réalise l'ajout du groupe __DEVS\_RO__ avec comme membre __nesta__.

Configuration du serveur virtuel :

        [ ... OUTPUT COUPÉ ... ]
        <Directory /data/vhosts/siteA/docroot/webdav/devs>
            <Limit POST PUT DELETE PROPFIND PROPPATCH MKCOL COPY MOVE LOCK UNLOCK>
                Require group DEVS
            </Limit>
            <Limit GET OPTIONS PROPFIND>
                Require group DEVS_RO DEVS
            </Limit>
        </Directory>
        [ ... OUTPUT COUPÉ ... ]


Suite au changement vous devez recharger la configuration apache.
Utilisation du client, réalisation du point de montage  avec l'utilisateur membre du groupe en Lecture seul:

        $ sudo mount.davfs -o uid=xerus https://www.linux202-sitea.com/webdav/ /mnt/dav/
        Please enter the username to authenticate with server
        https://www.linux202-sitea.com/webdav/ or hit enter for none.
          Username: nesta
        Please enter the password to authenticate user nesta with server
        https://www.linux202-sitea.com/webdav/ or hit enter for none.
          Password:

        $ ls -l /mnt/dav/
        total 1
        drwxr-xr-x 2 xerus root  0 Jun  1 08:54 commun
        drwxr-xr-x 2 xerus root  0 Jun  1 08:53 devs

Si vous essayons de créer un fichier dans le répertoires __devs__ nous aurons un message d'erreur :

        $ touch /mnt/dav/devs/un_fichier
        touch: setting times of ‘/mnt/dav/devs/un_fichier’: No such file or directory

Si nous regardons les logs sur le serveur  nous avons le message explicite du "problème"

        $ tail /data/vhosts/siteA/logs/ssl_error.log
        [ ... OUTPUT COUPÉ ... ]
        [Thu Jun 09 08:48:52.731436 2016] [authz_core:error] [pid 115] [client 172.17.42.1:53514] AH01631: user nesta: authorization failure for "/webdav/devs/un_fichier": 

Bien entendu avec un utilisateur dans le bon groupe nous n'aurons pas cette problématique, vous pouvez maintenant limiter adéquatement l'accès au différent répertoire.


Autre aspect intéressant de limitation sera la restriction de la taille des fichiers qui pourront être __uploadé__ sur le serveur vous n'avez probablement pas envie qu'un utilisateur utilise votre serveur __webdav__ pour s'échanger des films par exemple. Nous allons donc voir la possibilité de restreindre la taille des fichiers . L'instruction [LimitRequestBody](https://httpd.apache.org/docs/2.4/fr/mod/core.html#limitrequestbody) offre la fonctionnalité de restreindre la taille utilisable.

![limitrequestbody_screenshot-doc.png](./imgs/limitrequestbody_screenshot-doc.png)

**ATTENTION** : La taille fournit est en octects donc si vous désirez permettre un transfert de 2 Gig par exemple la valeur est astronomique 2147483647 :).

Voyons un exemple d'utilisation , dans mon exemple je vais limiter à __100K__ ce sera plus rapide pour sur le temps de transfert. Voici la configuration apache : 

        [ ... OUTPUT COUPÉ ... ]
        <Directory /data/vhosts/siteA/docroot/webdav/devs>
            LimitRequestBody 102400
            <Limit POST PUT DELETE PROPFIND PROPPATCH MKCOL COPY MOVE LOCK UNLOCK>
                Require group DEVS
            </Limit>
            <Limit GET OPTIONS PROPFIND>
                Require group DEVS_RO DEVS
            </Limit>
        </Directory>
        [ ... OUTPUT COUPÉ ... ]

Nous avons donc définie  la limite si j'essaye de copier un fichier sur le serveur __webdav__ :

        $ mount | grep dav
        https://www.linux202-sitea.com/webdav/ on /mnt/dav type fuse (rw,nosuid,nodev,relatime,user_id=1000,group_id=0,allow_other,max_read=16384,uid=1000,gid=0,helper=davfs)

        $ du -hs /tmp/access-denied.jpg
        348K    /tmp/access-denied.jpg
        $ cp /tmp/access-denied.jpg  /mnt/dav/devs/test_fichier.jpg
        $ echo $?
        0
        $ du -hs /mnt/dav/devs/test_fichier.jpg
        346K    /mnt/dav/devs/test_fichier.jpg
        [ ... Quelque seconde plus tard ... ]
        $ du -hs /mnt/dav/devs/test_fichier.jpg
        du: cannot access ‘/mnt/dav/devs/test_fichier.jpg’: No such file or directory

Si nous regardons sur le serveur les logs :

        $ tail -f /data/vhosts/siteA/logs/ssl_error.log
        [ ... OUTPUT COUPÉ ... ]
        [Fri Jun 10 08:40:00.051902 2016] [dav:error] [pid 66] (-102)Unknown error -102: [client 172.17.42.1:53868] An error occurred while reading the request body (URI: /webdav/devs/test_fichier.jpg)  [500, #0]

        [ ... OUTPUT COUPÉ ... ]

Pourquoi lors du transfert original le fichier été présent puis après il a disparu ? Le système de __mount__ afin d'optimiser les accès n'écrit pas directement mais cache l'opération. Ceci n'est pas toujours l'idéal mais quand il n'y a pas de problème ceci permet de ne pas bloquer le système le temps de l'écriture . 
Bien entendu ceci oblige votre logiciel à réaliser une validation __post-écriture__

* Référence :

    * https://httpd.apache.org/docs/2.4/fr/mod/mod\_dav.html

# <a name="performance" /> Performance et analyse d'apache

Il est très difficile de faire une section performance, car les problèmes peuvent être très varié. Une configuration peut avoir un impacte d'amélioration signification pour un environnement et dans un autre environnement avoir un impacte négatif. De plus selon le point de vue la perception peut être différente , exemple de propos :

* le sysadmin dit : "Le problème est le code, le développeur à mal codé son truc :P "
* Le développeur dit : "Ça marche très bien sur mon poste , le problème est au niveau du serveur "
* Le chargé de projet : "Les accès au système sont plus nombreux que planifié "

Où est la vérité dans tous ça ? Je vous dirai que la réalité est un mixe dans tous ça , il y a probablement une amélioration du code possible car le serveur est différent du poste de travail du développeur. Le sysadmin doit être en mesure d'ajuster ça configuration pour les applications qui est installé sur la machine. N'oublions pas le chargé de projet :P , il faut être en mesure de réaliser des testes de performance sur le système avant afin de connaître le nombre de client que l'on peut prendre en charge.

Quelles sont les problèmes classiques que nous retrouvons :

* Problème de __DNS__
* La charge sur la machine est trop haute ( utilisation du CPU ) 
* L'utilisation de la mémoire est élevé
* Les pages mettes beaucoup de temps à répondre  , c'est tellement générale que ça ne donne pas beaucoup d'information 
* L'accès aux ressources sur le disque dur est lent 
* Selon la période de la journée, le site réponds difficilement
* L'utilisation de la bande passante est saturé 

## <a name="perf_view" /> Visualisation de la situation

Avant de commencé à mettre des efforts pour corriger le / les problème(s) essayons de les identifier. Évidement nous allons voir quelques applications qui ne touche pas apache, mais qui sont purement système. 
Idéalement vous avez un système de monitoring et d'historique d'utilisation qui vous permet d'identifier la période du problème. Lors que je fais mention de monitoring de fait référence à un système de type [nagios](https://www.nagios.com/) qui permet de recevoir courriel ou __SMS__ lors de problème. Si votre système de monitoring ne vous permet pas de conserver des graphiques sur les valeurs dans le passé , je vous conseille d'en mettre un en place pour pouvoir identifier après coup une période en problème. Vous avez [cacti](http://www.cacti.net/) qui permet de réaliser cette opération. 
Nous y reviendrons probablement , je vais tous de même fournir une liste d'outils qui nous permette de réaliser l'analyse sur le moment sans ces outils.

Débutons avec un problème d'utilisation du CPU.

## <a name="perf_simulation" /> Simulation de charge sur le serveur

En tant lors des formations sur la performance nous terminons avec la simulation de charge cependant si je veux vous présenter les outils avec la configuration que j'ai actuellement uniquement avec mon portable sans client **réelle** ceci risque d'être un peu compliqué. Nous allons donc voir tous de suite la simulation de charge ceci peut être aussi utile en début de projet si vous désirez valider votre application avant de vous lancer en production. 

Nous allons voir plusieurs outils certain plus complexe que d'autre, malheureusement ceci sera encore un survole car pour faire de bon teste de performance il faut que ces derniers soit en lien avec votre application. Ceci vous offrira un point de départ pour réaliser votre configuration.
Nous commencerons par des applications simple et nous monterons en puissance à ce stade nous analyserons uniquement les logs pour voir  les accès par la suite nous regarderons les outils d'analyse de performance pour apache.

L'utilisation des utilitaires présentés par la suite devrons être exécuté sur une autre machine que le serveur. Ceci afin de valider aussi l'ensemble de l'infrastructure réseau. Le comportement en local et à distance peut varier, de plus vos clients seront à distance donc autant simulé le même comportement. Si vous réalisez des testes de performance je vous invite aussi à utiliser plusieurs machines afin de monter en charge le serveur avec plusieurs sources de connexion.

### <a name="perf_bench_ab" /> Utilisation du logiciel ApacheBench (AB)

**ApacheBench** (**ab**) est un programme en ligne de commande pour la mesure de performance et les tests de charge de serveur HTTP. À l'origine conçu pour Apache HTTP Serveur, il est désormais utilisable sur tous les serveurs HTTP classiques. L'application est disponible bien entendu sous GNU/Linux et Windows (probablement Mac). 

Installons l'application :

        $ sudo apt-get install apache2-utils

Débutons avec une petite requête simple nous allons réaliser au total 100 requêtes donc 10 simultanés sur la pages principale du site. Avec l'option **-w** vous pouvez avoir le résultat en format __HTML__  ça peut être pratique: 

        $ ab  -n 100 -c 10 -l https://www.linux202-siteA.com/
        [ ... OUTPUT COUPÉ ... ]
        Benchmarking www.linux202-siteA.com (be patient).....done

        Server Software:        Apache/2.4.7
        Server Hostname:        www.linux202-siteA.com
        Server Port:            443
        SSL/TLS Protocol:       TLSv1.2,ECDHE-RSA-AES256-GCM-SHA384,2048,256

        Document Path:          /
        Document Length:        Variable

        Concurrency Level:      10
        Time taken for tests:   2.263 seconds
        Complete requests:      100
        Failed requests:        0
        Total transferred:      36900 bytes
        HTML transferred:       10000 bytes
        Requests per second:    44.19 [#/sec] (mean)
        Time per request:       226.313 [ms] (mean)
        Time per request:       22.631 [ms] (mean, across all concurrent requests)
        Transfer rate:          15.92 [Kbytes/sec] received

        Connection Times (ms)
                      min  mean[+/-sd] median   max
        Connect:       33  189  77.2    201     456
        Processing:     1   22  19.3     19      86
        Waiting:        0   16  16.5      9      76
        Total:         34  210  82.5    215     457

        Percentage of the requests served within a certain time (ms)
        50%    215
        66%    237
        75%    253
        80%    258
        90%    288
        95%    363
        98%    403
        99%    457
        100%   457 (longest request)


Explication des arguments :

* **-n** : Nombre total de requête qui seront transmise 
* **-c** : Nombre de requête concurrente transmise 
* **-l** : L'application ne va pas rapporter d'erreur si le temps de traitement de la requête n'est pas identique à la première réalisé . Si votre site est dynamique il est fort probable que le temps de traitement varie quelque peu.


Explication du résultat :

        Concurrency Level:      10
        Time taken for tests:   2.263 seconds
        Complete requests:      100
        Failed requests:        0
        Total transferred:      36900 bytes
        HTML transferred:       10000 bytes
        Requests per second:    44.19 [#/sec] (mean)
        Time per request:       226.313 [ms] (mean)
        Time per request:       22.631 [ms] (mean, across all concurrent requests)
        Transfer rate:          15.92 [Kbytes/sec] received

* __Concurrency Level: 10__ : Information sur le nombre de connexion concurrente 
* __Time taken for tests: 2.263 seconds__ : Le temps total du teste de charge
* __Complete requests: 100__ : Le nombre total de requête
* __Failed requests: 0__ : Le nombre de requête en erreur 
* __Total transferred: 36900 bytes__ : La quantité de donnée transmis lors du teste
* __HTML transferred: 10000 bytes__ : La quantité de donnée __HTML__, excluant les images et autres média
* __Requests per second: 44.19 \[#/sec\] (mean)__ : Le nombre de requête par seconde
* __Time per request: 226.313 \[ms\] (mean)__: Le temps requis pris pour chaque requête
* __Time per request: 22.631 \[ms\] (mean, across all concurrent requests)__ : Le temps par requête en gros ceci reprend la valeur mentionné plus tôt divisé par le nombre de requête concurrent.
* __Transfer rate: 15.92 \[Kbytes/sec\] received__ : Le taux de transfert

La seconde partie :

                      min  mean[+/-sd] median   max
        Connect:       33  189  77.2    201     456
        Processing:     1   22  19.3     19      86
        Waiting:        0   16  16.5      9      76
        Total:         34  210  82.5    215     457

* __Connect__: Le temps pris pour établir une connexion au serveur
* __Processing__: Le temps pris pour transmettre les premiers __bytes__ au serveur et recevoir les premiers __bytes__ de réponses
* __Waiting__ : Le temps entre l'envoie du premier __bytes__ de donnée et le dernier __bytes__

#### <a name="perf_bench_ab_auth" /> Utilisation du logiciel ApacheBench (AB) avec Authentification

Nous avons vu précédemment la possibilité de mettre en place un système d'authentification sur des sections du site, nous l'avons fait pour une section d'administrateur ou lors de la mise en place de la solution __WebDav__. Il est donc probable que vous désiriez valider ces sections aussi. 
Si vous avez mis en place une authentification de type apache (__htaccess__) vous pouvez utiliser l'option **-A** :

        $ ab  -n 100 -c 10 -l -A admin:mot_passe  https://www.linux202-siteA.com/admin/

Cependant si vous avez mis en place une authentification dans votre application ceci ne fonctionnera pas , vous avez probablement utilisé une méthode utilisant une session / cookie. Si c'est le cas vous devez utiliser une autre option :

        $ ab  -n 100 -c 10 -l -C '_x3access_session=BAh7CUkiD3Nlc...' https://www.linux202-siteA.com/

REF : http://work.stevegrossi.com/2015/02/07/load-testing-rails-apps-with-apache-bench-siege-and-jmeter/


### <a name="perf_bench_seige" /> Utilisation du Siege 

__ApacheBench__ (ab) est bien mais voyons un autre produit qui offre d'autre possibilité , la combinaison des 2 nous permettra de mieux valider les capacités de notre serveurs. Reprenons globalement le même teste qui fut réalisé avec __ApacheBench__ afin de nous faire la main avec quelque chose de connu, par la suite nous explorons l'avantage de __Siege__.

Cette fois ci le nom du pacquage est plus claire :

        $ sudo apt-get install siege 

Les arguments sont un peu différent d'__ab__ nous allons donc refaire les 100 requêtes totale donc 10 concurrentes. Voici la "formule" avec __siege__.

        $ siege  -r 10 -c 10  https://www.linux202-siteA.com/
        ** SIEGE 3.0.5
        ** Preparing 10 concurrent users for battle.
        The server is now under siege..      done.

        Transactions:                    100 hits
        Availability:                 100.00 %
        Elapsed time:                   6.75 secs
        Data transferred:               0.01 MB
        Response time:                  0.06 secs
        Transaction rate:              14.81 trans/sec
        Throughput:                     0.00 MB/sec
        Concurrency:                    0.89
        Successful transactions:         100
        Failed transactions:               0
        Longest transaction:            0.19
        Shortest transaction:           0.03


Explication des arguments :

* **-r** : Le nombre de requêtes ici 10 
* **-c** : Le de requêtes concurrente ici 10

Résultat nous aurons 10 requête (-r) \* 10 requêtes concurrentes (-c) = 100 Requêtes totales

Le résultat de __siege__ est moins détaillé que __ApacheBench__, bien que ceci peut être suffisant selon le besoin établie. Je pense  que l'information transmise est claire si ce n'est pas le cas m'informer je tenterai de mettre à jour le document. 


#### <a name="perf_bench_siege_auth" /> Utilisation du logiciel Siege  avec Authentification

Tous comme __ApacheBench__ __siege__ est en mesure de gérer l'authentification apache ou d'utiliser un code de __cookie sessions__.

Pour l'authentification de type Apache vous devez éditer / créer le fichier **.siegerc** dans votre répertoire personnel, avec la ligne suivante :

        login = admin:mot_de_passe

Pour l'utilisation de session __cookie__ vous définirez un __header__ avec l'information :

        $ siege  -r 10 -c 10 -H 'Cookie:_x3access_session=BAh7CUkiD3Nlc...'  https://www.linux202-siteA.com/

#### <a name="perf_bench_siege_plus" /> Avantage de l'utilisation du logiciel Siege

À ce stade __siege__ et __ApacheBench__ réalise la même opération voyons ce qui démarque __siege__.
Lors des 2 testes précédent nous réalisions un teste de charge uniquement sur UNE __URL__, __siege__ nous permet de définir un fichier contenant plusieurs __URL__ ceci nous permettant de valider non pas seulement la page principale mais une série de page du site web , car soyons réaliste vos utilisateurs ne se contenterons pas d'une page.

L'option **-f** nous permet de définir une liste d'__URL__ __siege__ va utilisez ses dernières de manière aléatoire pour réaliser les requêtes au site web. Démonstration :

        $ cat sitea_urls.txt 
        https://www.linux202-sitea.com/
        https://www.linux202-sitea.com/info.php
        https://www.linux202-sitea.com/articles/2016/super_validation
        https://www.linux202-sitea.com/app.php

        $ sudo siege  -r 10 -c 10  -f sitea_urls.txt
        ** SIEGE 3.0.5
        ** Preparing 10 concurrent users for battle.
        The server is now under siege..      done.

        Transactions:                    100 hits
        Availability:                 100.00 %
        Elapsed time:                   8.20 secs
        Data transferred:               0.52 MB
        Response time:                  0.10 secs
        Transaction rate:              12.20 trans/sec
        Throughput:                     0.06 MB/sec
        Concurrency:                    1.22
        Successful transactions:         100
        Failed transactions:               0
        Longest transaction:            0.40
        Shortest transaction:           0.03


Si vous consultez le fichier de logs du site web nous voyons clairement le coté aléatoire des requêtes 

        $ tail -f /data/vhosts/siteA/logs/ssl_access.log
        [ ... OUTPUT COUPÉ ... ]
        172.17.0.2 - - [17/Jun/2016:08:12:01 -0400] "GET / HTTP/1.1" 200 2146 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"
        172.17.0.2 - - [17/Jun/2016:08:12:01 -0400] "GET /articles/2016/super_validation HTTP/1.1" 200 2798 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"
        172.17.0.2 - - [17/Jun/2016:08:12:01 -0400] "GET / HTTP/1.1" 200 2146 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"
        172.17.0.2 - - [17/Jun/2016:08:12:01 -0400] "GET /info.php HTTP/1.1" 200 19541 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"
        172.17.0.2 - - [17/Jun/2016:08:12:01 -0400] "GET /info.php HTTP/1.1" 200 19545 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"
        172.17.0.2 - - [17/Jun/2016:08:12:01 -0400] "GET /info.php HTTP/1.1" 200 19539 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"
        172.17.0.2 - - [17/Jun/2016:08:12:02 -0400] "GET /app.php HTTP/1.1" 200 1923 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"
        172.17.0.2 - - [17/Jun/2016:08:12:02 -0400] "GET / HTTP/1.1" 200 2146 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"
        172.17.0.2 - - [17/Jun/2016:08:12:02 -0400] "GET /info.php HTTP/1.1" 200 19538 "-" "Mozilla/5.0 (pc-i686-linux-gnu) Siege/3.0.5"


Tous en utilisant la possibilité d'utiliser une suite d'__URL__ aléatoire nous allons définir un nombre d'utilisateur concurrent pour une période de temps. Nous allons aussi définir un délais entre chaque requête des utilisateurs par défaut le délais entre chaque requêtes est de 1 secondes , cependant pour simulé le temps de "lecture" ou de prise de conscience du contenu nous allons définir 5 secondes entres les requêtes.

Donc 25 utilisateurs concurrent, pendant 5 minutes , avec 5 secondes de délais entre les requêtes pour une période de 5 minutes.

        $ siege -c 25 -t 5M -d 5 -f sitea_urls.txt
        ** SIEGE 3.0.5
        ** Preparing 25 concurrent users for battle.
        The server is now under siege...
        Lifting the server siege...      done.

        Transactions:                   2950 hits
        Availability:                 100.00 %
        Elapsed time:                 299.19 secs
        Data transferred:              13.05 MB
        Response time:                  0.04 secs
        Transaction rate:               9.86 trans/sec
        Throughput:                     0.04 MB/sec
        Concurrency:                    0.44
        Successful transactions:        2950
        Failed transactions:               0
        Longest transaction:            0.36
        Shortest transaction:           0.03

Nous nous retrouvons avec un teste plus représentatif de l'utilisation dans la nature de notre site web, le problème avec cette solution est votre teste n'est pas reproductible. En effet comme le choix des URL est réalisé de manière aléatoire 2 testes même consécutif ne réaliserons pas les même accès, nous pouvons dire que ceci est bien car il est peut probable que vos utilisateurs accèdes toujours dans la même séquence vos pages mais le résultat des chiffres sont plus compliqué à interpréter.


### <a name="perf_bench_jmeter" /> Utilisation de JMeter



REF : 

* http://jmeter.apache.org/

### <a name="perf_bench_ngrinder" /> Utilisation de Ngrinder


REF :

* https://hub.docker.com/r/ngrinder/controller/
* https://github.com/naver/ngrinder/wiki/

## <a name="perf_view" /> Analyse des performances 

Maintenant que nous sommes en mesure de simuler du trafic sur notre serveur nous allons être en mesure de visualiser le comportement de ce dernier. Nous allons voir le comportement d'apache lors de la monté en charge, cette partie de visualisation est aussi importante que la section configuration. Chaque combinaisons serveur / site web étant unique vous devez être en mesure d'identifier le point problématique pour être en mesure de l'améliorer. Il n'y a pas de recette qui s'applique peut importe la sauce. 

### <a name="perf_view_apache_process" /> Visualisation des processus Apache

Commençons par la visualisation des processus Apache, le serveur web peut fonctionner en 2 mode :

* [prefork](https://httpd.apache.org/docs/2.4/fr/mod/prefork.html) : Ce module multi-processus (MPM) implémente un serveur web avec démarrage anticipé de processus. Chaque processus du serveur peut répondre aux requêtes entrantes, et un processus parent contrôle la taille du jeu de processus enfants. Nous avons donc le processus Apache qui démarre généralement sous l'utilisateur **root** afin de pouvoir écouter sur le port 80 et/ou 443 , par la suite les autres processus sont **forké** sous l'utilisateur Apache.
Heu **for** quoi ?? Chaque nouveau processus est démarré suivant le principe de **fork** . La fonction **fork** fait partie des appels système standard d'__UNIX__ (norme __POSIX__). Cette fonction permet à un processus (un programme en cours d'exécution) de donner naissance à un nouveau processus qui est sa copie conforme, par exemple en vue de réaliser un second traitement parallèlement au premier. Un bon moyen de visualiser l'effet d'un **fork** sur un processus est d'imaginer une bactérie qui se coupe en deux. 
En d'autre mot une copie complète du processus avec un nouveau **PID** est généré sur le système, l'ensemble des allocations mémoire réalisé du processus parent sont transmis au processus enfant. 
Apache essaie toujours de maintenir plusieurs processus serveurs __inactifs ou en réserve__, afin de pouvoir traiter les requêtes entrantes. De cette façon, les clients n'ont pas besoin d'attendre le démarrage d'un nouveau processus enfant pour que leurs requêtes puissent être traitées.
La directive [MaxConnectionsPerChild](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#maxconnectionsperchild) permet de contrôler la fréquence à laquelle le serveur recycle ses processus en arrêtant les plus anciens et en en lançant de nouveaux.
* [worker](https://httpd.apache.org/docs/2.4/fr/mod/worker.html) : Ce module multi-processus (MPM) implémente un serveur hybride multi-processus multi-thread. En utilisant les __threads__ pour servir les requêtes, il peut en traiter un grand nombre tout en consommant moins de ressources qu'un serveur à base de processus. Cependant, il conserve une grande partie de la stabilité d'un serveur à base de processus en maintenant plusieurs processus disponibles, chacun de ces derniers possédant de nombreux __threads__. Un processus de contrôle unique (le parent) a pour tâche de lancer les processus enfants. Chaque processus enfant crée un nombre fixe de __threads__ serveurs selon la valeur de la directive ThreadsPerChild, ainsi qu'un __thread__ chargé d'attendre les connexions et de les passer à un __thread__ serveur pour traitement au fur et à mesure de leur arrivée.
Le serveur HTTP Apache essaie toujours de maintenir un jeu de __threads__ serveurs inactifs ou en réserve, qui se tiennent prêts à traiter les requêtes entrantes. De cette façon, les clients n'ont pas besoin d'attendre la création d'un nouveau __thread__ ou d'un nouveau processus pour que leurs requêtes puissent être traitées. 
Le gros avantage de ce module est que contrairement au système __fork__ ce n'est pas une copie complète du processus parent qui est dupliqué mais uniquement un processus démarrer, il utilise aussi moins de mémoire car les __threads__ partage un espace mémoire afin d'échanger de l'information sur le serveur. Cependant l'ensemble des module apache ne fonctionne pas tous en mode __threadé__ le plus connue **php** ne fonctionne pas à ce jour (2016) en mode __worker__.


Voici une représentation graphique des 2 modes :

![prefork-vs-worker.png](./imgs/prefork-vs-worker.png)

Je vais me concentré sur le système **mpm_prefork**, je vous laisserai le plaisir si votre système utilise **worker** de réaliser la corrélation avec l'autre mode. 

Visualisons la configuration actuelle du mode __mpm_prefork__ : 

        $ cat /etc/apache2/mods-enabled/mpm_prefork.conf 
        # prefork MPM
        # StartServers: number of server processes to start
        # MinSpareServers: minimum number of server processes which are kept spare
        # MaxSpareServers: maximum number of server processes which are kept spare
        # MaxRequestWorkers: maximum number of server processes allowed to start
        # MaxConnectionsPerChild: maximum number of requests a server process serves

        <IfModule mpm_prefork_module>
            StartServers                     5
            MinSpareServers           5
            MaxSpareServers          10
            MaxRequestWorkers         150
            MaxConnectionsPerChild   0
        </IfModule>

Quand nous démarrons le service **httpd** nous aurons donc 5 processus __apache__ disponible (**StartServers**).

        $ sudo /etc/init.d/apache2 start
        * Starting web server apache2
        * 
        $ ps aux | grep apache
        root        51  0.6  0.9  90420 19460 ?        Ss   17:04   0:00 /usr/sbin/apache2 -k start
        www-data    56  0.0  0.2  90452  5376 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    57  0.0  0.2  90452  5380 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    58  0.0  0.2  90452  5380 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    59  0.0  0.2  90452  5380 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    60  0.0  0.2  90452  5380 ?        S    17:04   0:00 /usr/sbin/apache2 -k start


Si j'accède au site web 1 des processus ci-dessus prendra la tâche et fournira l'information demandé au client. Si nous montons en charge le système va créer d'autre processus pour répondre à la demande . Démonstration, vous pouvez utiliser la commande **top** pour visualiser en direct l'augmentation de processus ...

        [client ]$ ab  -n 100 -c 10 -l https://www.linux202-siteA.com/

        [server ]$ ps aux | grep apache 
        root        51  0.0  0.9  90420 19460 ?        Ss   17:04   0:00 /usr/sbin/apache2 -k start
        www-data    56  0.1  0.4  90512  8432 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    57  0.1  0.4  90512  8432 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    58  0.1  0.4  90512  8432 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    59  0.1  0.4  90512  8432 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    60  0.1  0.4  90512  8432 ?        S    17:04   0:00 /usr/sbin/apache2 -k start
        www-data    70  5.2  0.4  90512  8432 ?        S    17:10   0:00 /usr/sbin/apache2 -k start
        www-data    71  2.1  0.4  90512  8432 ?        S    17:10   0:00 /usr/sbin/apache2 -k start
        www-data    72  1.7  0.4  90512  8432 ?        S    17:10   0:00 /usr/sbin/apache2 -k start

Donc nous voyons qu'a présent nous avec 9 processus apache.
Soyons un peu plus brutal à présent :

        [client]$ ab  -n 200 -c 20 -l https://www.linux202-siteA.com/
        
        [server]$ ps aux | grep apache
        root        51  0.0  0.9  90420 19460 ?        Ss   17:04   0:00 /usr/sbin/apache2 -k start
        www-data    56  0.2  0.4  90512  8436 ?        S    17:04   0:01 /usr/sbin/apache2 -k start
        www-data    57  0.2  0.4  90512  8436 ?        S    17:04   0:01 /usr/sbin/apache2 -k start
        www-data    58  0.2  0.4  90512  8436 ?        S    17:04   0:01 /usr/sbin/apache2 -k start
        www-data    59  0.2  0.4  90512  8436 ?        S    17:04   0:01 /usr/sbin/apache2 -k start
        www-data    60  0.2  0.4  90512  8436 ?        S    17:04   0:01 /usr/sbin/apache2 -k start
        www-data    70  0.6  0.4  90512  8436 ?        S    17:10   0:01 /usr/sbin/apache2 -k start
        www-data    71  0.6  0.4  90512  8436 ?        S    17:10   0:00 /usr/sbin/apache2 -k start
        www-data    72  0.5  0.4  90512  8436 ?        S    17:10   0:00 /usr/sbin/apache2 -k start
        www-data   130  2.5  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   136  1.9  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   161  6.6  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   164  4.5  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   165  3.5  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   168  2.3  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   169  3.3  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   170  2.3  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   171  5.0  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   174  1.0  0.3  90488  7380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   175  1.0  0.3  90488  7380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   178  1.0  0.3  90488  7380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   179  0.0  0.2  90452  5380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   180  0.0  0.2  90452  5380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   181  0.0  0.2  90452  5380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start 

Nous voyons le nombre de processus Apache monté en flèche , une fois la monté en charge terminé le nombre de processus va réduire tout seule. Ce nombre correspond à la directive __MaxSpareServers__ :

        [server] $ ps aux | grep apache
        root        51  0.0  0.9  90420 19460 ?        Ss   17:04   0:00 /usr/sbin/apache2 -k start
        www-data    56  0.1  0.4  90512  8436 ?        S    17:04   0:01 /usr/sbin/apache2 -k start
        www-data    57  0.1  0.4  90512  8436 ?        S    17:04   0:01 /usr/sbin/apache2 -k start
        www-data    70  0.3  0.4  90512  8436 ?        S    17:10   0:01 /usr/sbin/apache2 -k start
        www-data    72  0.2  0.4  90512  8436 ?        S    17:10   0:00 /usr/sbin/apache2 -k start
        www-data   130  0.3  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   161  0.1  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   164  0.1  0.4  90512  8432 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   174  0.0  0.3  90488  7380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   175  0.0  0.3  90488  7380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start
        www-data   181  0.0  0.2  90452  5380 ?        S    17:12   0:00 /usr/sbin/apache2 -k start

En théorie le nombre de processus qu'apache pourrait démarrer correspond  à la directive __MaxRequestWorkers__ , cependant dans mon cas mon portable ne sera plus en mesure de répondre à la charge avant :P. Pourquoi limité le nombre de processus me direz vous ? Si vous êtes __slashdoté__ par exemple donc une augmentation significative de l'accès à votre site web , si le nombre de processus était illimité, dans le cas où votre site web est en mesure de fournir 1000 utilisateurs lors que le 1001 arrive votre serveur ne serait plus en mesure de répondre TOTALEMENT à AUCUN utilisateur. Si vous avez configurer adéquatement votre serveur apache le 1001 utilisateur ne sera pas en mesure d'accéder à la page cependant les 1000 autres n'y verront rien.

### <a name="perf_view_apache_process_status" /> Visualisation des pages traité par le processus

Bon voir les processus apache c'est très bien, ça nous permet de visualiser l'utilisation du serveur mais si nous voyons un processus apache qui prend 100% du __CPU__ ou un nombre énorme de processus comment puis je savoir la source et ou la destination des requêtes ?!?! Certain me dirons de consulter les logs, c'est une TRÈS bonne idée malheureusement si vous avez mutualiser 200 sites sur votre serveur ce sera complètement illisible :-/. Vous pouvez utiliser des systèmes de google analytique ou __piwik__  par contre vous risquez d'avoir quelques problème à faire la corrélation avec les __PID__ du processus sur votre machine :-(. Bon vous vous doutez bien que si je prends autant de temps pour vous dire tous ceci c'est que j'ai une solution :P.

Il existe un module qui permet d'avoir l'information en temps réelle des accès sur le serveur ce dernier est **mod_status**, le module est activé par défaut sur **Ubuntu** mais accessible uniquement localement sur le serveur. Nous allons donc réaliser une petite configuration afin de permettre l'accès depuis notre machine.

        $ sudo vim /etc/apache2/mods-enabled/status.conf
        [... OUTPUT COUPÉ ...]
                <Location /server-status>
                    SetHandler server-status
                    #Require local
                    Require ip 172.17.42.1
                </Location>
        [... OUTPUT COUPÉ ...]

Dans la situation j'ai permis uniquement l'IP 172.17.42.1, faut __reloader__ la configuration apache pour que ce soit actif.

Voici le résultat à froid :

![server-status_empty.png](./imgs/server-status_empty.png)

Nous pouvons déjà voir que la requêtes à cette page fut traité par le **PID** 383. Effectivement si je liste les processus en cours sur la machine : 

        $ ps aux | grep apache
        root       380  0.0  0.9  90420 19552 ?        Ss   17:42   0:00 /usr/sbin/apache2 -k start
        www-data   383  0.0  0.4  90684  8836 ?        S    17:42   0:00 /usr/sbin/apache2 -k start
        www-data   384  0.0  0.2  90452  5424 ?        S    17:42   0:00 /usr/sbin/apache2 -k start

Nous allons voir à présent le comportement lors de l'accès a plusieurs page à l'aide de __siege__ :

        $ cat sitea_urls.txt 
        https://www.linux202-sitea.com/
        https://www.linux202-sitea.com/info.php
        https://www.linux202-sitea.com/articles/2016/super_validation
        https://www.linux202-sitea.com/app.php
        $ siege  -r 20 -c 20  -f sitea_urls.txt


![server-status_siege-20-20.png](./imgs/server-status_siege-20-20.png)

Donc le gros avantage est de pouvoir avoir le détail de ce que réalise un processus, vous avez le __pid__ ainsi que le __VirtualHost__ qui est demandé ainsi que la page demandée. Le tous avec l'adresse __ip__ de provenance , si vous êtes donc victime d'un **DOS** vous êtes en mesure de savoir d'où et surtout vers quelle page.

Nous pouvons voir l'état des demandes de page web à l'aide du système d'identifiant :

        Scoreboard Key:
        "_" Waiting for Connection
        "S" Starting up
        "R" Reading Request,
        "W" Sending Reply
        "K" Keepalive (read)
        "D" DNS Lookup,
        "C" Closing connection
        "L" Logging
        "G" Gracefully finishing
        "I" Idle cleanup of worker
        "." Open slot with no current process

__Anecdote__ : Dans le passé, un client avait un problème de disponibilité de page web, une page dynamique qui été plus que sollicité. Le problème été que le serveur web ne pouvait plus traité les demandes, grâce à la visualisation de la page demandé nous avons pu mettre une page web statique __html__, donc moins lourde à traité mentionnant un problème de disponibilité du service.


### <a name="perf_view_cpu_prob" /> Analyse problème de charge CPU

Pour réaliser l'analyse nous allons installer le pacquage **sysstat** si ceci n'est pas déjà présent .

        $ apt-cache search iostat
        sysstat - system performance tools for Linux
        $ sudo apt-get install sysstat

Pour continuer nous allons mettre une page __php__ non performante , et c'est moi qui l'ai fait :D ... Je voulais une page qui prenne beaucoup de __CPU__. J'ai donc créer une page qui affiche 100 fois un nombre aléatoire de 10000 caractère. On repassera pour la beauté de l'opération, mais le résultat est au rendez-vous le CPU augmente :D.

        $ sudo vim /data/vhosts/siteA/docroot/perf/random.php
        <?php
            function generateRandomString($length = 100000 ) {
                $characters = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';
                $charactersLength = strlen($characters);
                $randomString = '';

                for ($i = 0; $i < $length; $i++) {
                    $randomString .= $characters[rand(0, $charactersLength - 1)];
                }
                return $randomString;
            }

            for ($x = 0 ; $x < 100000 ; $x++ ) {
                if ( $x == 1 ) {
                    echo generateRandomString();
                }
                echo "<br>";
            }

        ?>


Si vous allons sur l'URL : https://www.linux202-sitea.com/perf/random.php , vous aurez une liste de caractère, si vous cliquez pour rafraichir la page d'autre nombre seront présenter.

Nous allons à présent monter en charge le serveur, nous visualiserons le comportement avec la commande __vmstat__ :

        [client]$ ab  -n 200 -c 10 -l https://www.linux202-siteA.com/perf/random.php
        Concurrency Level:      10
        Time taken for tests:   20.719 seconds
        Complete requests:      200
        Failed requests:        0
        Total transferred:      100047400 bytes
        HTML transferred:       100000000 bytes
        Requests per second:    9.65 [#/sec] (mean)
        Time per request:       1035.974 [ms] (mean)
        Time per request:       103.597 [ms] (mean, across all concurrent requests)
        Transfer rate:          4715.49 [Kbytes/sec] received

        Connection Times (ms)
         min  mean[+/-sd] median   max
         Connect:       64  143  36.9    139     293
         Processing:   400  883 129.8    897    1265
         Waiting:      141  545  96.4    551     889
         Total:        540 1026 141.6   1038    1430

        Percentage of the requests served within a certain time (ms)
        50%   1038
        66%   1088
        75%   1116
        80%   1141
        90%   1183
        95%   1224
        98%   1334
        99%   1398
        100%   1430 (longest request)

        $ vmstat 5 20
        procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
        r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
        13  0    940 951656  74600 503100    0    0   266    37  322  525 26  3 70  1  0
        11  0    940 947320  74600 503140    0    0     0     0 1228 3242 94  6  0  0  0
        10  0    940 946772  74624 503164    0    0     0    13 1271 3252 94  6  0  0  0
        11  0    940 955588  74648 503192    0    0     0    12 1172 3224 94  6  0  0  0
         5  0    940 955292  74672 503208    0    0     0    11 1286 3170 94  6  0  0  0
         0  0    940 959788  74696 503236    0    0     0    14  812 1145  8  3 89  0  0
         1  0    940 961992  74720 503248    0    0     0    13  727  899  3  1 96  0  0


Bien entendu vous pouvez aussi utiliser la commande __top__ pour visualiser le comportement , je voulais vous présenter une autre méthode possible qui se script bien et fournit l'ensemble de l'information du système ( Mémoire, __Input/Ouput__ , __cpu__ ...). Si vous désirez utilisé top en script c'est aussi possible avec l'option **-b** pour __batch__  qui est bien pratique.

        # Avant test de charge
        $ uptime
         17:11:59 up 22 min,  1 user,  load average: 0.96, 1.62, 1.42

        # Après test de charge
        $ uptime
         17:13:02 up 23 min,  1 user,  load average: 2.81, 1.96, 1.55

Dans la situation suivant , quelle est la solution ? 

* Corriger le code **php**, ce serait LA solution à mettre en place car clairement il y a un problème, cependant ceci n'est pas toujours possible à notre niveau 

Donc quelle est la solution **de contournement** que l'on peut mettre en place ? 

* Bien entendu ceci dépend de votre application , dans le cas présent la question que je peux me poser : est est-ce que les chiffres aléatoire doivent changé à chaque rafraichissement ? Puis je mettre en place un système de cache afin que cette dernier soit générer uniquement selon un intervalle définie ?

Nous pourrions modifier le code __php__ afin qu'il ajoute un __header__ (en tête) __html__ afin que le client __cache__ le contenu de la page. Ceci est une très bonne solution malheureusement comme le système de __cache__ sera réalisé au niveau du client si j'ai énormément de requête provenant de source multiple , l'opération de __caching__ de la page ne s'effectuera PAS. Du moins pas comme nous l'entendu , la charge sur le serveur sera identique , ça ne solutionnera le problème que si le même client / fureteur accède à la page.

Nous allons donc introduire le système de __cache__ au niveau du serveur , le résultat sera le suivant :

* Le serveur va générer le résultat de la page dynamique __php__ une fois
* Par la suite le serveur apache va cacher le contenu dans ça mémoire 
* Lors des prochaines requêtes peut importe le client le même contenu sera transmis au demandeur
* Un fois le cache expirer la page sera régénéré et caché , ainsi de suite.

Bien entendu le coté négatif de cette opération est que le contenu dynamique ne sera pas généré à chaque requête , mais si l'on y pense un peu si nous prenons un site de nouvelle telle que lemonde.fr , lapresse.ca , ... Si nous utilisons un système de cache de 5 minutes permettant de répondre à des milliers voir millions de requêtes est-ce vraiment critique ?!?! 

#### <a name="perf_mod_cache" /> Utilisation de mod_cache

Le module que nous utiliserons pour nos besoin sera [mod_cache](https://httpd.apache.org/docs/current/fr/mod/mod_cache.html) , nous verrons uniquement un survole, cependant ceci vous offrira la possibilité d'aller plus loin par vous même.

Le système __mod\_cache__ fonction avec 2 mode :


* [mod\_cache\_disk](https://httpd.apache.org/docs/current/fr/mod/mod_cache_disk.html)
implémente un gestionnaire de stockage sur disque. Les en-têtes et corps sont stockés séparément sur le disque dans une structure de répertoires basée sur le condensé md5 de l'URL mise en cache. Plusieurs réponses à contenu négocié peuvent être stockées en même temps, mais la mise en cache de contenus partiels n'est pas supportée par ce module. L'utilitaire htcacheclean permet de lister et de supprimer les URLs mises en cache, et de maintenir le cache en deçà de certaines limites de taille et de nombre d'inodes.
* [mod\_cache\_socache](https://httpd.apache.org/docs/current/fr/mod/mod_cache_socache.html)
Implémente un gestionnaire de stockage basé sur un cache d'objets partagés. Les en-têtes et corps sont stockés ensemble sous une seule clé basée sur l'URL de la réponse mise en cache. Des réponses à contenus multiples négociés peuvent être stockées simultanément, mais ce module ne supporte pas la mise en cache de contenus partiels. 

Nous allons débuter avec le premier c'est très équivalant avec le deuxième donc pas de stresse :D. Attention le nom du module pour caché en mémoire n'est pas le même avec la version apache 2.2.

Nous allons activer les modules qui est déjà disponible sous Ubuntu. 

        $ ls /etc/apache2/mods-available/*cache*
        /etc/apache2/mods-available/authn_socache.load  /etc/apache2/mods-available/file_cache.load
        /etc/apache2/mods-available/cache.load          /etc/apache2/mods-available/socache_dbm.load
        /etc/apache2/mods-available/cache_disk.conf     /etc/apache2/mods-available/socache_memcache.load
        /etc/apache2/mods-available/cache_disk.load     /etc/apache2/mods-available/socache_shmcb.load
        /etc/apache2/mods-available/cache_socache.load
        $ sudo a2enmod cache 
        Enabling module cache.
        To activate the new configuration, you need to run:
          service apache2 restart
        $ sudo a2enmod cache_disk
        Considering dependency cache for cache_disk:
        Module cache already enabled
        Enabling module cache_disk.
        To activate the new configuration, you need to run:
          service apache2 restart
        $ ls /etc/apache2/mods-enabled/*cache*
        cache.load  cache_disk.conf  cache_disk.load  socache_shmcb.load

Regardons le fichier de configuration de cache pour le disque dur qui est définie par défaut sans les commentaires :

        $ cat /etc/apache2/mods-enabled/cache_disk.conf  | grep -v "#" | grep -v "^$"
        <IfModule mod_cache_disk.c>
                CacheRoot /var/cache/apache2/mod_cache_disk
                CacheDirLevels 2
                CacheDirLength 1
        </IfModule>

Nous avons la configuration du répertoire qui sera utilisé pour stocké le contenu mis en cache ceci via la directive [CacheRoot](https://httpd.apache.org/docs/current/fr/mod/mod_cache_disk.html#cacheroot). La directive [CacheDirLevels](https://httpd.apache.org/docs/current/fr/mod/mod_cache_disk.html#cachedirlevels) permet de définir le nombre de niveaux de sous-répertoires que comportera le cache. La directive [CacheDirLength](https://httpd.apache.org/docs/current/fr/mod/mod_cache_disk.html#cachedirlength) permet de définir le nombre de caractères que comportera chaque nom de sous-répertoire de la hiérarchie du cache. 
 
Si nous regardons le répertoire définie par __CacheRoot__ nous constaterons que les permissions sont définie pour l'utilisateur qui exécute le serveur __web__ :

        $ ls -ld /var/cache/apache2/mod_cache_disk
        drwxr-xr-x 2 www-data www-data 4096 Jan 14 12:46 /var/cache/apache2/mod_cache_disk

Si vous optez pour changer cette configuration n'oubliez pas d'ajuster les configurations en conséquences. 

À ce stade même si je refait un teste de charge j'aurais exactement le même comportement qu'avant car bien que les modules sont chargé et configurer "globalement" aucun serveur virtuel ne l'a d'activer !! 
Nous allons donc l'activer pour le serveur virtuel __siteA__.

        $  sudo vim /etc/apache2/sites-enabled/siteA-ssl.conf 
        [... OUTPUT COUPE ...]
                Alias "/cm-images" "/data/vhosts/common/images"

                # Mise en cache de tous les contenus
                CacheEnable  disk  /

                <Directory /data/vhosts/siteA/docroot/>
                    Options none
                    AllowOverride ALL
                    Require all granted
                </Directory>
                                                                                                
        [... OUTPUT COUPE ...]

On valide la configuration et on redémarre, je dois faire un __restart__ , car il y a des modules à charger.

        $ sudo apachectl configtest && sudo /etc/init.d/apache2 restart
        Syntax OK
         * Restarting web server apache2
         ...done.

Nous avons activé le cache et réalisé le redémarrage d'apache , allons sur les pages du site . 

* https://www.linux202-sitea.com/perf/random.php
* https://www.linux202-sitea.com/

Avec la commande **htcacheclean** vous pouvez voir le contenu qui est mis en cache :

        $ sudo htcacheclean -A -p /var/cache/apache2/mod_cache_disk/
        https://www.linux202-sitea.com:443/Free_Software_Foundation_logo.png? 620 37866 200 0 1466682926812864 1466769326812864 1466682926812463 1466682926812864 1 0
        https://www.linux202-sitea.com:443/index.html? 612 109 200 0 1466682926780187 1466769326780187 1466682926779031 1466682926780187 1 0
        $ sudo htcacheclean -a -p /var/cache/apache2/mod_cache_disk/
        https://www.linux202-sitea.com:443/Free_Software_Foundation_logo.png?
        https://www.linux202-sitea.com:443/index.html?

**ATTENTION** : N'oubliez pas d'utiliser la commande avec __sudo__ sinon votre utilisateur n'ayant pas la permissions d'accéder au contenu vous aurez un résultat VIDE. 

**heuu**  pourquoi on ne voit pas la page __PHP__ dans le système la liste des page qui caché ?!?! 
Nous allons devoir mettre une petite modification dans la page __php__, nous allons devoir définir des en-tête (__header__) __HTML__ . Voici ce que nous allons rajouter :

        $ sudo vim /data/vhosts/siteA/docroot/perf/random.php
        <?php
        header("Cache-Control: must-revalidate, max-age=3600");
        header("Vary: Accept-Encoding");
        ?>
        <?php
        function generateRandomString($length = 100000) {
        [... OUTPUT COUPÉ ...]

Nous avons 2 en-tête :
TODO : a completer

* *Cache-Control: must-revalidate, max-age=3600** : 
* __Vary: Accept-Encoding__ :

On valide :D, on retourne sur la page et on réutilise la commande  :

        $ sudo htcacheclean  -a -p /var/cache/apache2/mod_cache_disk/
        https://www.linux202-sitea.com:443/perf/random.php
        [... OUTPUT COUPÉ ...]


C'est le temps de refaire un test de performance :D.

        [client]$ ab  -n 200 -c 10 -l https://www.linux202-siteA.com/perf/random.php
        Concurrency Level:      10
        Time taken for tests:   4.369 seconds
        Complete requests:      200
        Failed requests:        0
        Total transferred:      2134200 bytes
        HTML transferred:       2080000 bytes
        Requests per second:    45.78 [#/sec] (mean)
        Time per request:       218.458 [ms] (mean)
        Time per request:       21.846 [ms] (mean, across all concurrent requests)
        Transfer rate:          477.02 [Kbytes/sec] received

        Connection Times (ms)
         min  mean[+/-sd] median   max
         Connect:       34  190  86.2    209     328
         Processing:     1   20  18.1     14      93
         Waiting:        1   13  14.2      9      79
         Total:         35  210  94.7    239     341

        Percentage of the requests served within a certain time (ms)
         50%    239
         66%    283
         75%    297
         80%    302
         90%    313
         95%    320
         98%    325
         99%    330
        100%    341 (longest request)

        $ uptime
        # avant 
         17:25:22 up 35 min,  1 user,  load average: 0.70, 0.85, 1.06
        $ vmstat 5 20
         procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
          r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
          1  0    940 877884  75524 520964    0    0   174    28  365  604 25  3 71  1  0
         10  0    940 875124  75524 520992    0    0     0     1  844 1999 64  4 31  0  0
          0  0    940 876540  75548 521004    0    0     0    30  855 1650 33  4 64  0  0 

        # Apres 
        $ uptime
         17:26:16 up 36 min,  1 user,  load average: 1.06, 0.96, 1.09

On peut dire que ça MARCHE :D , woot !! Bon c'est pas une raison pour programmer comme un porc ;-).

Je vous ai dit ce n'est qu'une introduction au système nous allons tous de même prendre le temps d'exploirer un peu les options disponible on est dedans faut en profiter :D.

Quand nous activons un système de **cache** la première question que l'on se pose souvent est combien de temps le système va caché l'information ?!?! Ceci est définie par la directive [CacheDefaultExpire](https://httpd.apache.org/docs/current/fr/mod/mod_cache.html#cachedefaultexpire)

![CacheDefaultExpire-screenshot.png](./imgs/CacheDefaultExpire-screenshot.png)

Comme vous pouvez le voir la valeur par défaut est 3600 secondes , mais j'aimerai surtout porter votre attention sur le lieu où peut être définie cette directive , le context :    configuration du serveur, serveur virtuel, répertoire, .htaccess.

Comme vous pouvez le constater ceci peut être sur-définie à plusieurs lieux selon le besoin !!

L'autre intérogation qui peut être soulever est , ouin mais moi je veux pas que TOUS mon site web soit caché , c'est juste une section qui me pose problème ... 

Effectivement pour la démonstration j'ai activé le cache pour l'ensemble du site mais regardons la directive [CacheEnable](https://httpd.apache.org/docs/current/fr/mod/mod_cache.html#cacheenable). 

![CacheEnable-screenshot.png](./imgs/CacheEnable-screenshot.png)

Encore une fois je vous pointe la ligne **contexte** qui indique une liste non négligeable où nous pouvons activer le mode de caching. 

Bon pour les personnes qui veulent l'activer pour un répertoire mais pas un fichier , oui il y a des besoins parfois comme ça :P . La directive [CacheDisable](https://httpd.apache.org/docs/current/fr/mod/mod_cache.html#cachedisable) est la pour ça encore une fois la liste des lieux où ceci peut être définie est conséquente au besoin ...

![CacheDisable-screenshot.png](./imgs/CacheDisable-screenshot.png)

Conformément à la définition de la directive vous pouvez l'utiliser comme suit :

        <Location "/foo">
            CacheDisable on
        </Location>
        
        # Ou
        CacheDisable "/path/url/fichier/toto.html"

Je ne couvrirai pas ici le module pour caché en mémoire le concept étant similaire je vais continuer pour couvrir plus de matière dans le cas où vous désiriez que je rajoute cette section SVP le dire :D.


#### <a name="perf_wait_access" /> Augmentation de la charge du à un problème d'Input/Output (tmpfs)

Bon nous avons corrigé le problème de charge du CPU , comme nous avons pu le constater lors de l'exemple précédent la charge du CPU été principalement du à une augmentation du pourcentage CPU utilisateur. Nous générions un processus qui générais un nombre aléatoire (poche :P) ce qui avait comme conséquence d'augmenter la charge .

         procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
        r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
        13  0    940 951656  74600 503100    0    0   266    37  322  525 26  3 70  1  0
        11  0    940 947320  74600 503140    0    0     0     0 1228 3242 94  6  0  0  0
        10  0    940 946772  74624 503164    0    0     0    13 1271 3252 94  6  0  0  0

Comme  nous pouvons le voir ci-dessus l'augmentation est sous la colonne **US** pour la section CPU.
Voyons un autre cas de figure l'augmentation de la charge mais cette fois dû à un problème de **wait-access** (**WA**), généralement causé par un accès intensif d'écriture ou de lecture du disque dur. 

Je vais créer un fichier texte de 27 __Megs__ nommé __data.dtd__ :

        $ pwd
        /data/vhosts/siteA/docroot/perf
        $ tail data.dtd 
        2016-06-13 08:42:31 status unpacked sysstat:i386 10.2.0-1
        2016-06-13 08:42:31 status unpacked sysstat:i386 10.2.0-1
        2016-06-13 08:42:31 status unpacked sysstat:i386 10.2.0-1
        2016-06-13 08:42:31 status unpacked sysstat:i386 10.2.0-1
        2016-06-13 08:42:31 status unpacked sysstat:i386 10.2.0-1
        2016-06-13 08:42:31 status half-configured sysstat:i386 10.2.0-1
        2016-06-13 08:42:32 status installed sysstat:i386 10.2.0-1
        2016-06-13 08:42:32 trigproc libc-bin:i386 2.19-0ubuntu6 <none>
        2016-06-13 08:42:32 status half-configured libc-bin:i386 2.19-0ubuntu6
        2016-06-13 08:42:32 status installed libc-bin:i386 2.19-0ubuntu6
        $ du -hs data.dtd
        27M     data.dtd

Je vais créer un fichier __php__ qui va lire et écrire ce fichier sous un autre nom  puis le supprimer :

        $ sudo vim /data/vhosts/siteA/docroot/perf/io-file.php
        <?php

        function gen_io($id=0,$data="") {
            
            $file_name="./tmp/test".$id.".txt";
            $file = fopen($file_name,"w");
            echo fwrite($file,$data);
            fclose($file);
            unlink($file_name);
        }
        
        $file_data = fopen("data.dtd","r");
        $data = fread($file_data,filesize("data.dtd"));

        for ($x = 0 ; $x < 100000; $x++ ) {
            if ($x == 1 ) {
                echo gen_io($x,$data);
            }
            echo "<br>";
            }

        fclose($file_data);

        ?> 

        $ sudo mkdir /data/vhosts/siteA/docroot/perf/tmp
        $ sudo chown www-data  /data/vhosts/siteA/docroot/perf/tmp

Comme il y a écriture sur le disque dur , je ne veux pas que ma page soit caché sinon le système ne réalisera pas l'opération à chaque accès au site :-/ . Donc l'option de mise en cache avec __mod\_cache__ n'est pas une option dans le cas présent je désactive donc l'option . 

        $ head -30  /etc/apache2/sites-enabled/siteA-ssl.conf

        <VirtualHost 172.17.0.1:443>
                ServerAdmin webmaster@localhost
                ServerName www.linux202-siteA.com
                ServerAlias linux202-siteA.com
                ServerAlias toto.linux202-siteA.com

                DocumentRoot /data/vhosts/siteA/docroot/

                Alias "/cm-images" "/data/vhosts/common/images"

                # Mise en cache de tous les contenus
                #CacheEnable  disk  /
                #CacheIgnoreCacheControl On
                #CacheDefaultExpire 3600

        [... OUTPUT COUPÉ ...]

On redémarre le service apache et on va faire un test

        $ sudo apachectl configtest && sudo /etc/init.d/apache2 restart

Je vais réutiliser la commande __ab__ pour charger le serveur et nous allons visualiser le comportement avec __vmstat__ sur le serveur.

        [client]$ ab  -n 200 -c 10 -l https://www.linux202-siteA.com/perf/io-file.php
        Document Path:          /perf/io-file.php
        Document Length:        Variable

        Concurrency Level:      10
        Time taken for tests:   66.105 seconds
        Complete requests:      200
        Failed requests:        0
        Total transferred:      80040200 bytes
        HTML transferred:       80002000 bytes
        Requests per second:    3.03 [#/sec] (mean)
        Time per request:       3305.268 [ms] (mean)
        Time per request:       330.527 [ms] (mean, across all concurrent requests)
        Transfer rate:          1182.42 [Kbytes/sec] received

        Connection Times (ms)
                      min  mean[+/-sd] median   max
        Connect:       34  130  64.4    128     338
        Processing:   260 3153 1847.1   2666    8556
        Waiting:      205 2879 1841.3   2405    8336
        Total:        295 3283 1841.0   2767    8675

        Percentage of the requests served within a certain time (ms)
         50%   2767
         66%   3643
         75%   4174
         80%   4630
         90%   5822
         95%   7789
         98%   8035
         99%   8477
        100%   8675 (longest request)

        [server]$ vmstat 2 30 
        procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
        r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
         1  0   3280 369692  72788 1029732    0    1   186  1194  337  594 10  5 82  3  0
        10  0   3280 238252  72796 1050980    0    0    50    60  533  765 18 12 70  0  0
         7  0   3280 224696  72800 1056976    0    0    22 26014 5236 11333 35 62  4  0  0
         0 12   3784  52768  72800 1071464   16  252    62 47898 4806 10102 33 61  0  6  0
         3 13   4652  52848  72816 1065776   12  434    60 36304 6132 13241 11 27  0 62  0
         2  9   4888  55556  72148 1062744    0  118    20 34436 1815 3370 22 22  0 56  0
         0 10   5088  53288  69948 1068768    8  100    16 17190 4251 8884  9 14  0 77  0
         2 12   5092 108800  69980 1051752    0    2    20 45946 1419 3885  7 18  1 73  0
         9  1   9412  95056  70020 1059816    0 2160     0 20222 1549 5115  8 13  4 75  0
         0  3   9412  72108  70044 1056564    0    0     4 36604 1299 5678 28 32  0 40  0
         6  0   9512  50720  70060 1078776    0   50     0 41082 4313 10174  6 32  2 60  0
        11  0   9792  69936  70060 1058804    0  140     0 63094 4520 10074 38 60  1  1  0
         0  4   9792  58196  70072 1064724    0    0     0 59588 5369 12786 33 54  1 13  0
        11  0   9792 154456  70088 1055740    0    0     4 29520 2257 8491 12 19  0 68  0
        10  1  10324 147376  67184 1047248    0  266     8 68910 4080 8758 37 57  2  4  0
         0  6  10324  77544  67192 1054612    0    0     6 15918 4640 10404 27 46  0 27  0
         8  2  11644  54444  62904 1084604    0  660    10 41374  955 7323 10 25 14 52  0
         0  5  11968  68560  62232 1067420    0  162     4 20014 3465 8940 30 37  0 33  0
         0  2  12224  95116  62244 1047644    0  128     8 67342 2957 6338 34 57  1  8  0
         2  5  13148  51240  62248 1091084    0  462     2 59418 2167 5202 16 27  1 56  0
         0  3  13256  51636  62256 1090584    0   54     0 11078  484  442  2  1  0 97  0
         6  0  13616 157088  58512 1040012    0  180    12 37504 4452 9477 30 43  0 27  0
         0  7  13620  48864  58148 1100000    0    2    14 59066 3285 7892 26 55  0 19  0
         7  9  14476 160316  57192 1059464    0  428    98 52044 4935 30204 24 33  0 43  0
         0 10  14476  58264  57192 1088112    0    0    18  3938 2510 4311  5 18  0 77  0
         0  7  19244  67108  49160 1087016    0 2384     4 60674 3020 8848 26 45  0 29  0
         0  4  19244  62888  49164 1097100    0    0     0 18604  800 1125  3  2  0 95  0
         8  3  19244 120060  49208 1074256    0    0   140 31384 1019 5032 26 29  0 44  0
         1  6  19244  64604  49224 1107128    0    0     0 71612 2090 12644 36 57  1  6  0
         2  3  20540  53464  39044 1121280    0  648     0 21408 5930 12650  3 14  0 83  0
         $ uptime
         17:22:34 up 27 min,  1 user,  load average: 9.56, 3.39, 1.67


La question est comment puis je corriger ce problème, la mise en cache n'est pas une option car il faut que l'écriture soit réaliser à chaque appel. Je ne peux pas fournir une page pré généré au client, encore une fois il est possible probablement de corriger le problème au niveau du code (yeahhh I'm a sysadmin , so the problem is the code :P ) . Bon quelle solution de contournement s'offre à moi ?!?!
Dans le cas présent ce pourrait être aussi un accès réseaux sur un disque partagé ou autre ... Soyons imaginatif :D.

La première idée que l'on se dit faut un __SSD__ , c'est une très bonne idée quelle est la taille requis ?!?! Et vous avez combien de serveur qui doivent avoir se __SSD__ de présent ? Imaginons que ces fichiers soit des fichiers "temporaire" de traitement donc vous auriez besoin de 2 ou 3 __Gig__ sur chaque serveur , avec un __cluster__ de 30 machines. 
Le prix des __SSD__ pour les serveurs sont très chères et malheureusement le __SSD__ n'est pas optimal pour l'écriture la longévité des __HD__ sont considérablement impacté.

La deuxième idée pourquoi on l'écrit pas dans la mémoire ... Le script __php__ va conservé l'information en mémoire et faire tous de suite le traitement ... Super idée mais est-ce que le processus suivant est réalisé par la page __php__ ?? Est-ce un processus qui fait le traitement et combien de temps ce dernier prends ? Est-ce vraiment envisageable de gardé l'utilisateur le temps des 2 traitements ?!? Probablement pas .

Voici ma proposition, mettre en place un faux répertoire qui sera en fait dans la mémoire du système , résultat le temps d'écriture est SUPER performant car effectué en mémoire. Le fichier sera disponible sur le système de fichier comme un fichier normale et pourra donc être traité par une autre application le temps venu. 
**Le point négatif**: Si le serveur **crash** les données sont perdu , yep rien n'est parfait :P .

Voyons le résultat , mis en place de la solution : 

        $ sudo vim /etc/fstab 
        [... OUTPUT COUPÉ ...]
        tmpfs /data/vhosts/siteA/docroot/perf/tmp tmpfs   nodev,nosuid,size=1G          0  0

Je configure le service **tmpfs** afin qu'il soit définie pour le répertoire __/data/vhosts/siteA/docroot/perf/tmp__ je lui alloué __1 Gig__ de mémoire maximum. __Mountons__ ce dernier.

        $ sudo mount /data/vhosts/siteA/docroot/perf/tmp
        $ sudo mount | grep perf
        tmpfs on /data/vhosts/siteA/docroot/perf/tmp type tmpfs (rw,nosuid,nodev,relatime,size=1048576k)

On refait un test ?? 


        [client] $ ab  -n 200 -c 10 -l https://www.linux202-siteA.com/perf/io-file.php
        Document Path:          /perf/io-file.php
        Document Length:        Variable

        Concurrency Level:      10
        Time taken for tests:   28.298 seconds
        Complete requests:      200
        Failed requests:        0
        Total transferred:      80040200 bytes
        HTML transferred:       80002000 bytes
        Requests per second:    7.07 [#/sec] (mean)
        Time per request:       1414.915 [ms] (mean)
        Time per request:       141.492 [ms] (mean, across all concurrent requests)
        Transfer rate:          2762.15 [Kbytes/sec] received

        Connection Times (ms)
                      min  mean[+/-sd] median   max
        Connect:       38  145  41.2    140     255
        Processing:   584 1258 196.2   1267    1685
        Waiting:      399  946 166.2    955    1299
        Total:        693 1402 211.1   1403    1885

        Percentage of the requests served within a certain time (ms)
        50%   1403
        66%   1491
        75%   1557
        80%   1592
        90%   1660
        95%   1741
        98%   1834
        99%   1840
        100%   1885 (longest request)


        [server] $ $ vmstat 2 40
        procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
        r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
        1  0  21452 331592  35516 1115720    0    4   117  1266  329  583 13  4 79  3  0
        10  0  21532 100284  32940 1121244    0   40    12    40 3836 7251 27 49 24  0  0
        10  0  21768 216136  32940 1086536    0  118     0   118 2377 3998 47 54  0  0  0
        10  0  21768  90072  32948 1111180    0    0     0     6 1966 4121 43 57  0  0  0
        9  0  21768  67004  32972 1128720    0    0     0    30 3253 6686 45 55  0  0  0
        13  0  22488 173208  32972 1080800    0  360     0   360 3488 6753 47 53  0  0  0
        11  0  22488 237528  32996 1090832    0    0     0    30 4113 8468 49 50  1  0  0
        7  0  22488  96588  32996 1094072    0    0     0     8 1474 3155 43 57  0  0  0
        10  0  22664 155992  32448 1074988    0   88     0    88 1934 4156 47 53  0  0  0
        6  0  22664 183056  32472 1059836    0    0     0    28 1299 2791 47 53  0  0  0
        9  0  22664 130136  32472 1076684    0    0     0     0 4219 8722 41 59  0  0  0
        9  0  22664 222444  32496 1063548    0    0     0    30 2267 4985 50 50  0  0  0
        8  0  22664 111852  32496 1081300    0    0     0     0 3195 6426 41 59  0  0  0
        10  0  22664 160976  32496 1061252    0    0     0     0 3926 8204 44 56  0  0  0
        10  0  22664 225652  32520 1088308    0    0     0    28 3439 7062 49 51  0  0  0  
        $ uptime
         17:39:35 up 44 min,  1 user,  load average: 2.86, 1.25, 1.10


Nous le voyons clairement, l'accès au disque est resté à 0 tous le long du processus , la charge sur le CPU est monté mais uniquement à cause des processus utilisateur, mais beaucoup moins. Le résultat du testes de charge est beaucoup mieux.

Mais je le répète, si vous utilisez cette technique vous devez faire une copie ou un traitement des fichiers qui sont TEMPORAIRE . S'il y a crash il y a perte de donnée , bien entendu vous pourriez mettre tous votre site web en mémoire ceci augmentera la performance du serveur :D.

### <a name="perf_conf_worker_prefork" /> Configuration de l'exécution d'apache (Worker vs Prefork)

Lors de la présentation des processus apache j'ai fait mention de 2 modes disponibles avec le système de __prefork__ et avec le système de __Thread__. Ceci était une présentation simple afin d'informer de la situation nous allons maintenant voir plus en détail les 2 modes , nous avons débuter avec la configuration par défaut pour la présentation, nous allons la manipulé à présent.


#### <a name="perf_prefork" /> MPM prefork

Telle que mentionné lors de la présentation précédent le système de __prefork__ , __fork__ un nouveau processus apache pour faire la gestion des nouvelles requêtes. Lors du __Fork__ une copie du processus parent est réalisé avec sont pile mémoire, ceci est le système originale mis en place avec apache, donc l'ensemble des modules fonctionne avec ce mode , ce qui n'est pas vrai avec l'autre système.

Un processus de contrôle unique a pour tâche de lancer les processus enfants qui attendent les connexions et les traitent au fur et à mesure qu'elles arrivent. Apache __httpd__ essaie toujours de maintenir plusieurs processus serveurs inactifs ou en réserve, afin de pouvoir traiter les requêtes entrantes. De cette façon, les clients n'ont pas besoin d'attendre le démarrage d'un nouveau processus enfant pour que leurs requêtes puissent être traitées.

Le processus parent est en général démarré en tant que __root__ sous Unix afin de pouvoir se mettre à l'écoute sur le port 80, les processus enfants sont lancés par Apache __httpd__ sous un utilisateur avec privilèges restreints. On peut contrôler les privilèges accordés aux processus enfants d'Apache __httpd__ à l'aide des directives **User** et **Group**. Les processus enfants doivent être en mesure de lire tous les contenus destinés à être servis, mais leurs privilèges doivent être aussi bas que possible.

Les directives [StartServers](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#startservers), [MinSpareServers](https://httpd.apache.org/docs/2.4/fr/mod/prefork.html#minspareservers), [MaxSpareServers](https://httpd.apache.org/docs/2.4/fr/mod/prefork.html#maxspareservers) et [MaxRequestWorkers](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#maxrequestworkers) permettent de contrôler la manière dont le processus parent crée les processus enfants pour traiter les requêtes. Les sites qui doivent traiter plus de 256 requêtes simultanées doivent augmenter la valeur de [MaxRequestWorkers](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#maxrequestworkers), alors que les sites dont la ressource mémoire est limitée doivent la diminuer afin d'éviter une __hyperactivité__ du serveur (utilisation excessive de la mémoire virtuelle sur disque). 

Nous allons analyser la configuration actuelle : 

        $ cat /etc/apache2/mods-enabled/mpm_prefork.conf
        [ ... OUTPUT COUPÉ ... ]
        <IfModule mpm_prefork_module>
                StartServers              5
                MinSpareServers           5
                MaxSpareServers          10
                MaxRequestWorkers       150
                MaxConnectionsPerChild    0
        </IfModule>
        [ ... OUTPUT COUPÉ ... ]


* **StartServers**

    ![StartServers-screenshot.png](./imgs/StartServers-screenshot.png)

    Définie le nombre de processus qui seront démarrer lors de l'initialisation du service , avec le module __preforf__ la valeur par défaut est **5**. Cette valeur est généralement assez basse , l'objectif est d'être en mesure de répondre au première requêtes rapidement, par la suite lors de la monté en charge ce sera les directive **\*SparesServers** qui prendront le relais.

* **MinSpareServers**

    ![MinSpareServers-screenshot.png](./imgs/MinSpareServers-screenshot.png)

    La directive MinSpareServers permet de définir le nombre minimum désiré de processus serveurs enfants inactifs. Un processus inactif est un processus qui ne traite pas de requête. S'il y a moins de MinSpareServers processus inactifs, le processus parent va créer de nouveaux enfants de la manière suivante : il en crée un, attend une seconde, il en crée deux, attend une seconde, il en crée quatre, puis continue ainsi exponentiellement jusu'à ce que son taux de création de processus enfants soit de 32 par seconde. Il ne s'arrête que lorsque le nombre de processus enfants correspond à la définition de la directive MinSpareServers.
    Je vais insister sur l'aspect de processus inactif ! Si vous démarrez votre service apache, vous aurez 5 processus apache (en dehors du parent présent pour écouter sur le port ) 
        
            $ ps aux | grep ^www-data
            www-data    59  0.0  0.2  90588  5568 ?        S    08:42   0:00 /usr/sbin/apache2 -k start
            www-data    60  0.0  0.2  90588  5572 ?        S    08:42   0:00 /usr/sbin/apache2 -k start
            www-data    61  0.0  0.2  90588  5572 ?        S    08:42   0:00 /usr/sbin/apache2 -k start
            www-data    62  0.0  0.2  90588  5572 ?        S    08:42   0:00 /usr/sbin/apache2 -k start
            www-data    63  0.0  0.2  90588  5572 ?        S    08:42   0:00 /usr/sbin/apache2 -k start

    Si vous accéder à l'URL **Server-status** (https://www.linux202-sitea.com/server-status), vous pourrez voir l'état actuelle des processus 

            CPU Usage: u0 s0 cu0 cs0
            0 requests/sec - 0 B/second -
            1 requests currently being processed, 4 idle workers

   1 Requête en cours 4 en attentes , mais l'instruction **MinSpareServers** indique que nous devons avoir 5 processus en attente , effectivement si vous réalisé la commande **ps** vous aurez bien 6 processus apache en execution , l'URL **server-status** vous donnera la même information. 

* **MaxSpareServers** 

    ![MaxSpareServers-screenshot.png](./imgs/MaxSpareServers-screenshot.png)

    La directive MaxSpareServers permet de définir le nombre maximum souhaité de processus serveurs enfants inactifs. Un processus inactif est un processus qui ne traite pas de requête. S'il y a plus de MaxSpareServers processus inactifs, le processus parent arrêtera les processus excédentaires.

    La modification de ce paramètre n'est nécessaire que dans le cas de sites très sollicités. Définir ce paramètre à une valeur très grande est cependant dans la plupart des cas une mauvaise idée.
    Dans notre cas le nombre minimum est de 5 , s'il y a un nombre de requête excessif le système va démarrer plus de processus pour traiter les demandes . Une fois la charge terminé le apache va tuer les processus inactifs excédent ce nombre, cependant quand le nombre de processus apache sera égale à **MaxSpareServers** le système les laissera ceci causera une utilisation de mémoire pour conserver ces processus.

* **MaxRequestWorkers** (__MaxClients__ avant la version 2.3.13)

    ![MaxRequestWorkers-screenshot.png](./imgs/MaxRequestWorkers-screenshot.png)

    La directive [MaxRequestWorkers](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#maxrequestworkers) permet de fixer le nombre maximum de requêtes pouvant être traitées simultanément. Si la limite __MaxRequestWorkers__ est atteinte, toute tentative de connexion sera normalement mise dans une file d'attente, et ceci jusqu'à un certain nombre dépendant de la directive [ListenBacklog](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#listenbacklog). Lorsqu'un processus enfant se libèrera suite à la fin du traitement d'une requête, la connexion en attente pourra être traitée à son tour.

    Pour les serveurs non __threadés__ (c'est à dire utilisant **prefork**), la directive __MaxRequestWorkers__ définit alors le nombre maximum de processus enfants qui pourront être lancés simultanément pour traiter les requêtes. La valeur par défaut est 256 ; si vous l'augmentez, vous devez aussi augmenter la valeur de la directive [ServerLimit](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#serverlimit).

* **MaxConnectionsPerChild**

    ![MaxConnectionsPerChild-screenshot.png](./imgs/MaxConnectionsPerChild-screenshot.png)

    La directive [MaxConnectionsPerChild](https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html#maxconnectionsperchild) permet de définir le nombre maximum de connexions qu'un processus enfant va pouvoir traiter au cours de son fonctionnement. Lorsqu'il a traité __MaxConnectionsPerChild__ connexions, le processus enfant est arrêté. Si __MaxConnectionsPerChild__ est définie à 0, il n'y a plus aucune limite sur le nombre de connexions que le processus pourra traiter.

    Définir __MaxConnectionsPerChild__ à une valeur non nulle limite la quantité de mémoire qu'un processus peut consommer à cause de fuites (accidentelles) de mémoire. Il est donc fortement recommandé de définir une valeur afin d'avoir un recyclage des processus.

##### <a name="perf_prefork_optimisation" /> MPM prefork Optimisation

Maintenant que l'on comprend un peu mieux la configuration du système de démarrage des processus apache nous allons pouvoir discuter de modification de configuration afin d'améliorer les performances. Je vous préviens tous de suite à moins d'avoir un site web ultra chargé les gains de performances ne seront pas si significatif, de plus vous devrez faire des testes de validation et prendre des " risques " jusqu'à un certain point lors des modifications. 
Le plus gros gains que vous allez avoir est si vous avez un __VPS__ avec peu de __RAM__ ou si vous prenez une instance __Amazon EC2__ avec peu de mémoire et __cpu__.

Voyons un exemple de configuration "classique" si vous avez 25 processus enfants 


        ps aux  | tr -s " " | cut -d " " -f 6,11- | grep apache | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum}'

        ab  -n 200 -c 200 -l https://www.linux202-siteA.com/


         # Prise 2 
        cat /etc/apache2/mods-enabled/mpm_prefork.conf 

        MaxRequestWorkers         150

        ab  -n 250 -c 250 -l https://www.linux202-siteA.com/
        Percentage of the requests served within a certain time (ms)
          50%   2416
          66%   2622
          75%   2753
          80%   2801
          90%   3089
          95%   3352
          98%   3735
          99%   4689
          100%   4805 (longest request)


        ps aux  | tr -s " " | cut -d " " -f 6,11- | grep apache | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum}'
        bob@xerus:~$ bc -l
        bc 1.06.95
        Copyright 1991-1994, 1997, 1998, 2000, 2004, 2006 Free Software Foundation, Inc.
        This is free software with ABSOLUTELY NO WARRANTY.
        For details type `warranty'.
        799480 / 1024
        780.74218750000000000000


        # Prise 3 
        cat /etc/apache2/mods-enabled/mpm_prefork.conf 

        MaxRequestWorkers         50

        $ ps aux  | tr -s " " | cut -d " " -f 6,11- | grep apache | egrep -v "grep|htcache" | awk '{ sum+=$1} END {print sum}'
        441432


        ab  -n 250 -c 250 -l https://www.linux202-siteA.com/
        Percentage of the requests served within a certain time (ms)
          50%   2467
          66%   2746
          75%   2857
          80%   2954
          90%   3488
          95%   3894
          98%   4298
          99%   4748
         100%   4806 (longest request)


* Référence :
    * https://httpd.apache.org/docs/2.4/fr/mod/mpm_common.html
    * https://httpd.apache.org/docs/2.4/fr/mod/prefork.html

### <a name="perf_php" /> Amélioration des performances de php

Personnellement je ne suis pas un grand fan de __PHP__ pas que ce soit un mauvais langage de programmation, cependant ça simplicité de développement a amené  sont lot de page mal programmé. Résultat j'ai un préjugé négatif de ce langage , je suis honnête dans mon propos, cependant c'est une réalité que les pages __php__ sont très présent dans notre réalité.

Nous donc voir comment nous pouvons améliorer les performances de notre système apache lorsque nous devons exécuter du __php__.

Idée :
* __Jmeter__
* __cactis  / piwik__
* __sleep mysql__ : http://dev.mysql.com/doc/refman/5.7/en/miscellaneous-functions.html#function_sleep
* __fail 2 ban__ : against DOS
* __php5-fpm - server-side, HTML-embedded scripting language (FPM-CGI binary)__

* URL :
    * http://httpd.apache.org/docs/current/misc/perf-tuning.html
    * https://www.devside.net/articles/apache-performance-tuning
    * http://www.monitis.com/blog/2011/07/05/25-apache-performance-tuning-tips
    * https://wiki.mikejung.biz/Apache


# <a name="Reference" /> Référence :

* [Documentation Apache 2.4](https://httpd.apache.org/docs/2.4/) : https://httpd.apache.org/docs/2.4/
* [Liste des code d'état du protocole http](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes): https://en.wikipedia.org/wiki/List_of_HTTP_status_codes
* http://httpd.apache.org/docs/current/fr/howto/auth.html



