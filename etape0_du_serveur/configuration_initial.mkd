<meta http-equiv='Content-Type' content='text/html; charset=utf-8' /> 
<style>
pre{background:#F8F8FF; border:black dashed 1px; padding:6px}
</style>

TODO corriger les \_

# Index 


# <a name="intro" /> Introduction 

Nous aurions probablement dû commencer la formation avec ce chapitre, mais comme cette formation est écrite selon l'envie et les demande , nous ne le couvrons que maintenant. Le bon côté est que vous avez pu déjà commencé à jouer un peu plus avec **apache** , **git** et **docker** :D. 
Ce chapitre va couvrir les opérations importante à faire quand vous mettez un serveur en production , ceci s'applique à l'ensemble des serveurs , bien entendu si vous avez plusieurs serveurs je vous invite à standardisé vos installations.
Nous allons donc voir les étapes à réaliser **avant** de mettre en place votre service , que nous parlions de __apache__, __mysql__ , __django__ , ... 

Nous parlerons un peu sécurité , mais très légèrement ...

# <a name="first_step" /> Réception de la machine 

Je vais partir du principe qu'une entité externe vous a fournit une machine , que ce soit une **VM** , un **VPS** , ou une machine physique. Le principe est le même si vous avez réalisé une nouvelle installation , si vous réalisez vous même l'installation d'une machine:

* Installé le minimum , quand vous réaliserez les mise à jours du serveur vous serez très content que l'opération soit super rapide car il y aura pas une multitude d'application non utilisé à mettre à jours.
* Vous limiterez en plus le nombre de faille de sécurité éventuelle du serveur.
* N'installez pas de compilateur ceci ouvre un nombre de possibilité élevé au attaquant , a moins bien entendu que ce soit requis pour votre utilisation. Je doute que ce soit le cas dans la pratique.

Voici les étapes à réaliser lors de la réception de la machine : 

1. Établir une connexion sur la **box**, __Yep__ :P 
2. Valide les informations de la machine selon les spécifications demandé :
    * Mémoire
        
            $ Free -m 
            total        used        free      shared  buff/cache   available
            Mem:           2009         483        1127           7         398        1490
            Swap:          5006           0        5006

    * CPU

            $ cat /proc/cpuinfo
            [...OUTPUT COUPÉ...]
            processor       : 1
            vendor_id       : GenuineIntel
            cpu family      : 6
            model           : 15
            model name      : Intel(R) Core(TM)2 CPU         U7600  @ 1.20GHz
            stepping        : 2
            microcode       : 0x57
            cpu MHz         : 800.000
            cache size      : 2048 KB
            [...OUTPUT COUPÉ...]

    * Taille du disque dur

            $ df -h | grep sda
            /dev/sda1        51G   33G   16G  68% /
            $ cat /proc/scsi/scsi
            Attached devices:
            Host: scsi0 Channel: 00 Id: 00 Lun: 00
              Vendor: ATA      Model: MCCOE64GEMPP     Rev: 03  
              Type:   Direct-Access                    ANSI  SCSI revision: 05
    
            $ dmesg  | grep sda
            [    1.242858] sd 0:0:0:0: [sda] 117210240 512-byte logical blocks: (60.0 GB/55.8 GiB)
            [    1.242968] sd 0:0:0:0: [sda] Write Protect is off
            [    1.242975] sd 0:0:0:0: [sda] Mode Sense: 00 3a 00 00
            [    1.243023] sd 0:0:0:0: [sda] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
            [    1.244227]  sda: sda1 sda2

    * Partitionnement (si spécifié)
        
            $ df -h | grep ^/

    * Système de configuration du __RAID__ si disponible 

            $ cat /proc/mdstats

3. Valider la distribution :

        $ cat /etc/lsb-release 
        DISTRIB_ID=Ubuntu
        DISTRIB_RELEASE=14.04
        DISTRIB_CODENAME=trusty
        DISTRIB_DESCRIPTION="Ubuntu 14.04 LTS"
         
        ou 
         
        $ cat /etc/redhat-release

4. Prendre un café, une petite bière ou un verre de vin pour de félicité de cette nouvelle machine
5. Vous pouvez toujours remercier votre Sysadmin ou fournisseur du service :D, lui aussi aime les courriels gentils , surtout si c'est le sysadmin __Day__ :P


Pour la suite des opérations je vous suggère d'utiliser un système de gestion de mot de passe par exemple :

* __Keepass__
* __Keepassx__
* ou peu importe , sauf un post-it :P

# <a name="Mise_a_jour" /> Mise à jour du système

Je fais une section juste pour cette opération , car on est tellement excité , d'avoir la nouvelle machine que l'on oublie cette opération. Je sais que vous avez reçu la machine et on se dit la machine est à jour ... 

HA HA HA HA HA **MORTEL** que tu est drôle !!

        La présomption est mère de tous les emmerdements du monde !!!! 

Donc tous de suite réalisons la mise à jour du système afin de s'assurer que tous est bon et que le redémarrage du système fonctionnera encore après. 

        # apt-get update
        # apt-get dist-upgrade 

Et pour compléter le tous un redémarrage 

        # reboot

Vous pouvez rétablir une connexion __ssh__ à la machine.

# <a name="take_controle" /> Prise de contrôle de la machine

Bon c'est le temps de prendre en main la bête !!! C'est le moment de se l'approprier ! 

Si vous n'avez pas __vim__ de présent, je présume que vous n'avez pas attendu d'être à cette section pour l'installer, mais pour pas prendre de chance :

        # apt-get install vim

Ha on se sent mieux déjà :D, allez c'est partie.

0. Initialisation de la configuration dans un contrôleur de révision
    * Avant de faire des modifications dans la configuration prenons une copie de la configuration en place dans le système de contrôleur de révision.
    * J'utilise le système __GIT__ car ceci ne m'oblige pas à avoir un serveur de source telle que __subversion__ 
    * Par contre ceci me permet de conserver une trace dans le temps et de revenir en arrière en cas de problème.

    1. Installation de __git__ et initialisation du dépôt pour **/etc**
            
            # apt-get install git
            # cd /etc
            # git init .

    2. Personnellement je n'active pas la révision sur l'ensemble des fichiers à tord ou à raison , chacun son plaisir , par exemple je ne désir pas que les mot de passe soit conservé , même chiffré , dans le dépôt. La raison principale est que je synchronise mon dépôt local sur un serveur et pour des considérations de sécurité je ne suis pas confortable. Je vais donc ajouter à la pièce les fichiers 

            # git add passwd group network/interfaces crontab cron.* ssh/sshd_config ssh/ssh_config
            # git config --global --edit   # pour faire la configuration de l'utilisateur avant de commiter
            # git commit -a -m "Configuration initial"

    3. Ajout d'un fichier **.gitignore** afin que le résultat de la commande **git status** ne montre pas une liste énorme de fichier non géré par __git__

            # vim /etc/.gitignore
            X11/
            acpi/
            adjtime
            aliases.db
            alternatives/
            bash.bashrc
            console-setup/
            byobu/
            dbus-1/
            debconf.conf
            debian_version
            default/
            deluser.conf
            dhcp/
            dpkg/
            fuse.conf
            gai.conf
            groff/
            group-
            gshadow-
            gss/
            hddtemp.db   
            ifplugd/
            [ ... OUTPUT COUPÉ ...]
            # template
            *.swp
            [ ... OUTPUT COUPÉ ...]

    4. Ajout du fichier à __git__ et validation des fichiers oublié .

            # cd /etc && git add .gitignore
            # git commit -m "Ajout du fichier .gitignore"
            # git status 

1. Étape difficile mais essentiel la définition du nom (__hostname__) de la machine ! Soyez créatif nommer la machine c'est lui donner une âme ! (Ok j'irais pas plus loin, je veux pas faire peur à personne ;) )

        # vim /etc/hostname
        # # pour l'activer tous de suite avant le reboot
        # hostname Votre_hostname.Le_domaine.com


1. Changer le mot de passe de l'utilisateur fournit, car connu du fournisseur de service , si vous utilisé **root** oublié la deuxième partie .

        $ passwd

2. Changer le mot de passe de l'utilisateur **root** 

        $ su - 
        # passwd 

3. Création d'un utilisateur que vous utiliserez régulièrement , ici j'utiliserai __bob__

        #  adduser bob
        Adding user `bob' ...
        Adding new group `bob' (1000) ...
        Adding new user `bob' (1000) with group `bob' ...
        Creating home directory `/home/bob' ...
        Copying files from `/etc/skel' ...
        Enter new UNIX password:
        Retype new UNIX password: 
        passwd: password updated successfully
        Changing the user information for bob
        Enter the new value, or press ENTER for the default
                Full Name []: Robert Nesta Marley
                Room Number []: 
                Work Phone []: 
                Home Phone []: 
                Other []: 
         Is the information correct? [Y/n] y
         # id bob
         uid=1000(bob) gid=1000(bob) groups=1000(bob)

4. Je préconise l'utilisation **EXCLUSIVE** de la commande **sudo** pour toute opération administrative j'ai pour principe de ne **JAMAIS** établir de connexion sous l'utilisateur **root**. Pourquoi ? 
    * Le mot de passe __root__ je ne l'utilise jamais il est stocké dans mon système de mot de passe et oublié
    * S'il y a une erreur de manipulation , j'en fait aussi ,  l'ensemble des commandes **sudo** sont conservées dans le fichier de logs
    * Comme il faut taper la commande **sudo** avant il y automatiquement réflexion avant de faire __ENTER__ sur la commande.

5. Installation de l'application __sudo__ et configuration d'un groupe 

        # apt-get install sudo
        # getent group sudo 
        sudo:x:27:
        ## S'il n'y a pas de retour avec la commande getent group creer un groupe
        # groupadd --system sudo 

    * Pourquoi la création du groupe __sudo__ , vous constaterez que tous le long de la configuration je vais définir plusieurs groupe auquel il y aura 1 ou 2 utilisateurs , éventuellement plus . Je préconise l'utilisation de groupe plutôt que d'utiliser les noms d'utilisateurs dans les configurations . La raison est simple :
        * La configuration s'exporte plus facilement d'un système à l'autre.
        * S'il y a explosions d'utilisateurs la gestion est plus simple, et surtout je suis prêt.
        * Mais **surtout** , lors de la suppression d'un utilisateur il est beaucoup plus simple de le supprimer des groupes plutôt que de parcourir plusieurs fichiers de configuration pour supprimé la définition de cette utilisateur. Il y a toujours des oublies malgré des __grep__ massif :P
    * Donc les membres du groupe **sudo** aurons la permission d'utiliser la commande **sudo** avec l'ensemble des droits

6. Configuration de __sudo__ , ajout de l'utilisateur **bob** dans le bon groupe et définition du __sudoers__

        # usermod -a -G sudo bob
        # id bob 
        uid=1000(bob) gid=1000(bob) groups=1000(bob),27(sudo)

        # visudo
        [... OUTPUT COUPÉ ...]
        # Members of the admin group may gain root privileges
        #%admin ALL=(ALL) ALL

        # Allow members of group sudo to execute any command
        %sudo   ALL=(ALL:ALL) ALL
        [... OUTPUT COUPÉ ...]

7. Valider la connexion avec l'utilisateur **bob** au serveur et validation de la configuration __sudo__ (ATTENTION: conservez la connexion initiale en cas de problème, donc ouvrir une nouvelle connexion)

        $ ssh bob@votre_serveur
        bob $ sudo -l 
        [sudo] password for bob:
        Matching Defaults entries for bob on atelier:
            env_reset, mail_badpass, secure_path=/usr/local/sbin\:/usr/local/bin\:/usr/sbin\:/usr/bin\:/sbin\:/bin

        User bob may run the following commands on atelier:
            (ALL : ALL) ALL

8. A partir ce moment plus **AUCUNE** opération ne sera réalisé avec l'utilisateur **root**.

9. Ajout des fichiers et commit dans **git**
    * Ajout des fichiers et commit les changements

            # cd /etc
            # git add /etc/sudoers /etc/group /etc/passwd /etc/hostname
            # git status         # Afin de visualiser les autres modifications
            # git add Autre_fichier_si_requis
            # git commit -m "Creation de l'utilisateur bob et ajout de ce dernier dans sudo "

# <a name="configue_init_with_bob" /> Configuration initial avec votre utilisateur

Donc vous êtes connecté avec votre utilisateur ici __bob__, nous allons pouvoir établir une première base de sécurité de la machine. Ici nous ne couvrirons pas de la sécurité optimal, mais un minimum "vital" .

## <a name="configue_ssh" /> Configuration du service OpenSSH

Pour débuter nous allons modifier un peu la configuration du service __OpenSSH__ , car ce dernier est le point d'entré à notre machine , nous désirons limité l'accès.

1. Création d'un groupe d'accès , nous allons créer un groupe dont les membres seront le seule à pouvoir établir une connexion ssh à la machine.

        $ sudo groupadd permit-ssh
        $ sudo usermod -a -G permit-ssh bob

    Donc nous avons maintenant le groupe **permit-ssh** et **bob** est maintenant membre de ce dernier

2. Configuration du service __OpenSSH__ , nous allons éditer la configuration afin de valider quelques entré 

        $ sudo vim /etc/ssh/sshd_config

    Entré à prendre en considération
    * **PermitRootLogin  without-password** : ceci indique que l'utilisateur __root__ ne peux pas établir de connexion avec un mot de passe. Il peut cependant établir une connexion au serveur via un système de clé SSH. J'active cette possibilité car mon système de backup utilisera ce mécanisme pour faire le transferts de fichier. Vous pouvez aussi définir à **NO** si non requis
    * **PermitEmptyPasswords no** : Désactivation de la possibilité d'établir une connexion si l'utilisateur à pas de mot de passe . :D
    * **Protocol 2** : Utilise uniquement le protocole 2 , qui est sécuritaire :D
    * **UsePrivilegeSeparation yes** : Permet d'avoir le traitement des connexions entrante avec un processus sans droit , une fois l'authentification réalisée avec succès un autre processus avec les bon droit est créé.
    * **AllowTcpForwarding yes** : Personnellement je laisse le défaut qui est à __YES__ , car j'utilise le système de __TCP forwarding__ qui permet d'utiliser SSH pour faire de la redirection de connexion __TCP__ . Cependant libre à vous de le désactiver
    * **AllowGroups root permit-ssh** : Ici nous avons la limitation des personnes qui peut utiliser le service __d'OpenSSH__ pour établir une connexion. Donc uniquement les membres du groupe __root__ et __permit-ssh__ peuvent établir une connexion, le groupe __root__ est présent toujours pour mon système de backup :P.

3. Redémarrage du service __OpenSSH__ pour activé la nouvelle configuration, pour cette étape faut un peu faire attention :P on veut pas de bloquer l'accès :P.
    1. Conservé votre connexion actuelle !!
    2. Redémarrer le service __Openssh__

            $ sudo /etc/init.d/ssh restart

    3. Juste pour être certain valider que votre serveur __SSHD__ a bien redémarrer en vérifiant l'heure, dans mon cas 8:31 c'est bon :D :

            $ sudo ps aux | grep sshd
            root         9  0.0  0.2   7812  4824 ?        S    08:31   0:00 /usr/sbin/sshd -D

    4. Établir une nouvelle connexion avec votre utilisateur , et confirmer que tous fonctionne bien . Surtout ne pas fermer votre connexion __ssh__ avant un succès :P

4. Commit les changements à __git__ suite au modification du service __OpenSSH__ et la création des groupes
    * Ajout des fichiers et commit

            # cd /etc
            # git status         # Afin de visualiser les autres modifications
            # git add Autre_fichier_si_requis
            # git commit -m "Modification d'openssh afin de limite avec le groupe "

5. Validation des clés __OpenSSH__ possiblement présent.
    * Bon pas que je fais pas confiance aux personnes qui m'ont fournit la machine , mais , mais ... Voilà quoi :P. Selon votre organisation ou entente de service il est possible que la compagnie veut se conservé une porte d'entré sur le serveur. Avant de procéder à une suppression de configuration assurez vous de l'entente :P.
    1. Recherche des clés __OpenSSH__ sur la machine , 2 méthodes , utilisation de la base de donné __locate__ ou un __find__ récursif, pour installer le __package locate__ **sudo apt-get install locate** .

            $ sudo updatedb    # mise à jour de la BD d'index pour locate
            $ sudo locate authorized_keys   # Tres important de le faire avec sudo sinon vous ne verrez pas tous !
            /home/support/.ssh/authorized_keys
            /root/.ssh/authorized_keys
            /usr/share/augeas/lenses/dist/authorized_keys.aug
            /usr/share/augeas/lenses/dist/tests/test_authorized_keys.aug
            /usr/share/man/man5/authorized_keys.5.gz

            $ sudo find / -name "authorized_keys"  # Ce sera plus long ...
            /home/support/.ssh/authorized_keys
            /root/.ssh/authorized_keys
            /usr/share/augeas/lenses/dist/authorized_keys.aug
            /usr/share/augeas/lenses/dist/tests/test_authorized_keys.aug
            /usr/share/man/man5/authorized_keys.5.gz

    2. Analyse du résultat
        * les seules fichiers "problématique" sont ceux contenu dans le répertoire **.ssh** , comme nous avons limité l'accès au groupe **permit-ssh** je présume que l'utilisateur __support__ n'est pas un risque . Pour l'utilisateur  __root__ si ce n'est pas votre clé :P , faut valider. Si nous venons de recevoir la machine personnellement je réaliserai l'opération suivante :
    3. Désactivation des clés, je ne supprime pas, car si un jour j'ai besoin du fournisseur de service ce sera plus rapide de lui re-fournir l'accès en changeant le nom du fichier plutôt qu'attendre qu'il me retransmette la clé.

            $ sudo mv /home/support/.ssh/authorized_keys /home/support/.ssh/disabled_keys
            $ sudo mv /root/.ssh/authorized_keys /root/.ssh/disabled_keys


## <a name="securisation_directory" /> Sécurisation minimal des répertoires 

1. Sécurisation du répertoire des utilisateurs .
    * Chose étrange par défaut sous Ubuntu le répertoire personnelle des utilisateurs est créé avec les permissions à tous de lire le contenu. Moi ça me dérange un peu je connais mes utilisateurs mais bon c'est pas super propre :P. Nous allons donc corriger le problème pour ceux déjà créer 

            $ cd /home
            $ sudo chmod o= *

    * Nous allons aussi faire en sorte que les prochains soit configurer convenablement , car c'est certain que nous oublierons de réaliser cette opération dans l'avenir.
            
            $ sudo vim /etc/adduser.conf
            # Modifier la ligne suivante  :
            DIR_MODE=0755 
            pour 
            DIR_MODE=0750

2. Validation des répertoires où tous le monde peut lire le contenu
    * Comme nous ne savons pas qui a monté la machine nous allons étendre l'analyse à l'ensemble du système, normalement à ce stade il n'y a pas beaucoup de fichier ce ne sera pas trop long .
    * Recherche des répertoires :
            
            $ cd /
            $ sudo find -perm -o=w  -type d 2>/dev/null| grep -v ^./proc            
            ./run/lock
            ./dev/mqueue
            ./dev/shm
            ./tmp
            ./tmp/.X11-unix
            ./tmp/.ICE-unix
            ./var/lib/php5
            ./var/tmp

    * L'ensemble des répertoires ci-dessus sont **normale** il n'est pas possible de supprimé l'écriture à tous de ces derniers.
    * Recherche des fichiers maintenant
        
            $ cd /
            $ sudo find -perm -o=w  -type f 2>/dev/null| grep -v ^./proc

## <a name="validation_dns" /> Validation de la configuration DNS en place

Malheureusement trop souvent mis de côté les __DNS__ il est essentiels d'avoir de BON __DNS__, et de s'assurer qu'ils sont disponible nous allons donc réaliser la vérification qui s'impose. Mais pourquoi c'est si important, si vos __DNS__ sont invalide ou problématique voici l'impacte:
* Ralentissement de l'ensemble du système : plusieurs processus vont réaliser une validation que ce soit __reverse dns__ (récupération de l'adresse IP et conversion en nom )  ou __DNS__ classique nom vers adresse IP. Si votre premier __DNS timeout__ ça veut dire que tous les processus qui réalise une requête doivent attendre le __timeout__ pour interroger le second.

1. Analyse de la configuration des __DNS__ en place :

        $ cat /etc/resolv.conf
        domain X3rus.com
        search x3rus.com
        nameserver 213.186.33.99
        nameserver 213.186.33.102
        nameserver 8.8.4.4

2. Dans le contexte actuelle comme vous pouvez le voir j'ai la configuration de 3 serveurs __DNS__ voyons c'est qui 

        $ dig -x 213.186.33.99 | grep -A 1 "^;; ANS"
        ;; ANSWER SECTION:
        99.33.186.213.in-addr.arpa. 86352 IN    PTR     cdns.ovh.net.

        $ dig -x 213.186.33.102 | grep -A 1 "^;; ANS"
        ;; ANSWER SECTION:
        102.33.186.213.in-addr.arpa. 86400 IN   PTR     dns.ovh.net.

        $ dig -x 8.8.4.4 | grep -A 1 "^;; ANS"
        ;; ANSWER SECTION:
        4.4.8.8.in-addr.arpa.   82657   IN      PTR     google-public-dns-b.google.com.

3. Nous allons valider que l'ensemble fonctionne , bon là on peut faire un __ping__ et voir le comportement , mais est-ce vraiment valide ?!? Si la résolution __dns__ est en cache nous aurons l'impression que tous fonctionne bien, mais nous n'aurons pas valider chaque serveur. Nous utiliserons la commande **dig** en forçant l'utilisation d'un serveur __DNS__.
    *  Voici un exemple lors d'un problème 
            
            $ dig lequipe.fr @213.186.33.99

            ; <<>> DiG 9.9.5-3ubuntu0.5-Ubuntu <<>> lequipe.fr @213.186.33.99
            ;; global options: +cmd
            ;; connection timed out; no servers could be reached

    * Voici la bonne réponse :

            $ dig lequipe.fr @213.186.33.99

            ; <<>> DiG 9.10.3-P4-Ubuntu <<>> lequipe.fr @213.186.33.99
            ;; global options: +cmd
            ;; Got answer:
            ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 51019
            ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 2, ADDITIONAL: 3

            ;; OPT PSEUDOSECTION:
            ; EDNS: version: 0, flags:; udp: 4096
            ;; QUESTION SECTION:
            ;lequipe.fr.                    IN      A

            ;; ANSWER SECTION:
            lequipe.fr.             300     IN      A       160.92.167.203

            ;; AUTHORITY SECTION:
            lequipe.fr.             79627   IN      NS      ns3.atos.net.
            lequipe.fr.             79627   IN      NS      ns4.atos.net.

            ;; ADDITIONAL SECTION:
            ns3.atos.net.           90092   IN      A       160.92.121.6
            ns4.atos.net.           90092   IN      A       193.56.46.248

            ;; Query time: 110 msec
            ;; SERVER: 213.186.33.99#53(213.186.33.99)
            ;; WHEN: Thu Sep 22 17:19:50 EDT 2016
            ;; MSG SIZE  rcvd: 131

    * Faite l'exercice pour l'ensemble des __dns__ configurer , une fois réaliser analyser le temps de réponse **Query time** indiquer à la fin . 

2. Modification du fichier **/etc/resolv.conf** 
    * Selon le temps de réponse changer l'ordre ou supprimer l'entrée .

            $ sudo vim /etc/resolv.conf

3. Enregistrement de la modification dans **git**

        $ cd /etc/
        $ sudo git status 
        $ sudo git add /etc/resolv.conf
        $ sudo git commit -m "Changement de la configuration DNS pour une meilleur perf :P "

## <a name="setup_timezone" /> Configuration du fuseau horaire et synchronisation du temps

Ici bien souvent c'est une catastrophe :P , j'arrive souvent sur des machines dont l'heure est complètement érroné , le fuseau horaire étant pré configurer c'est mieux mais encore :P. 
Pourquoi l'heure est importante ?
* Lors de l'analyse de problème , la lecture des logs si votre heures est mauvaise il est beaucoup plus dure de réaliser l'analyse de la séquence du problème.
* Si votre fuseau horaire est erroné vous êtes obligé de faire un +5 ou -2 heures c'est franchement pénible 
* Lors de l'analyse des fichiers qui furent créés , vous n'avez pas la bonne information, si votre heure se décale tranquillement vous avez quelques minutes de décalage encore une fois ça ne simplifie pas l'analyse
* Si votre système à trop de décalage sur l'heure l'établissement de connexion avec le protocole __SSL__ risque de ne pas marché, car la date de validation du certificat causera des problèmes
* Si vous utilisez un système d'authentification telle que **Kerberos** si votre système à plus de 15 minutes de décalage l'authentification ne fonctionnera pas
* etc etc 

Comme vous pouvez le voir, l'heure est importante , comme quand vous dites à votre femme que vous rentrez à une certaine heure :P.
Ceci s'applique pour **tous** les systèmes **VM** ou même les **conteneurs**.

1. Configuration du fuseau horaire
    * L'ensemble des fuseau sont contenu dans le répertoire : **/usr/share/zoneinfo/**

            $ ls /usr/share/zoneinfo/
            Africa      Australia  Cuba     Etc      GMT+0      Iceland  Kwajalein  NZ       Poland     Turkey     WET          right
            America     Brazil     EET      Europe   GMT-0      Indian   Libya      NZ-CHAT  Portugal   UCT        Zulu         zone.tab
            Antarctica  CET        EST      Factory  GMT0       Iran     MET        Navajo   ROC        US         iso3166.tab
            Arctic      CST6CDT    EST5EDT  GB       Greenwich  Israel   MST        PRC      ROK        UTC        localtime
            Asia        Canada     Egypt    GB-Eire  HST        Jamaica  MST7MDT    PST8PDT  Singapore  Universal  posix
            Atlantic    Chile      Eire     GMT      Hongkong   Japan    Mexico     Pacific  SystemV    W-SU       posixrules

    * Modification de la configuration pour avoir le bon fuseau horaire , dans mon cas je vais définir Montréal comme fuseau horaire, je vous laisse parcourir le répertoire afin d'identifier le plus proche de votre position :-)

            $ sudo ln -sf /usr/share/zoneinfo/America/Montreal /etc/localtime

    * Vous pouvez aussi utiliser la commande suivante qui permet d'avoir un menu vous aidant à faire la configuration

             $ sudo dpkg-reconfigure tzdata

2. Activation de la nouvelle configuration dans __git__

        $ cd /etc
        $ sudo git add localtime
        $ sudo git commit -m "Correction du fuseau horaire "

3. Redémarrage du système 
    Je vous suggère très fortement de réaliser un redémarrage du système afin de s'assurer que l'ensemble des applications prenne en considération la nouvelle configuration ! 

        $ sudo reboot

4. Mise en place de la synchronisation de l'heure avec des serveurs de référence avec le protocole **NTP (Network Time Protocol)**

    1. Installation de l'application et ajout du fichier de configuration par défaut dans git
                
                $ sudo apt-get install ntp ntpdate
                $ cd /etc
                $ sudo git add ntp.conf
                $ sudo git commit -m "Ajout fichier original de ntp"

    2. Configuration du service __ntp__ via le fichier **/etc/ntp.conf** , juste pour information je vais mettre en lumière 2 paramètre du fichier.

                $ cat /etc/ntp.conf | egrep  "^[server|restric]" | grep -v "#" 
                statistics loopstats peerstats clockstats
                server 0.ubuntu.pool.ntp.org
                server 1.ubuntu.pool.ntp.org
                server 2.ubuntu.pool.ntp.org
                server 3.ubuntu.pool.ntp.org
                server ntp.ubuntu.com
                restrict -4 default kod notrap nomodify nopeer noquery
                restrict -6 default kod notrap nomodify nopeer noquery
                restrict 127.0.0.1
                restrict ::1

       * l'instruction serveur est assez claire :P , vous pouvez avoir une liste différente sur le site de [ntp.org](http://support.ntp.org/bin/view/Servers/WebHome#Finding_A_Time_Server) . Je le met en lumière surtout si vous filtrez les communications en sortie
       * Vous pouvez valider le fonctionnement avec les serveurs avec la commande **ntpq** 

                $ sudo /etc/init.d/ntp start
                $ sudo ntpq -pn
                  remote           refid      st t when poll reach   delay   offset  jitter
                  ==============================================================================
                  211.233.40.78   131.107.13.100   2 u  151   64   14  390.465  -950167   1.659
                  131.234.137.64  .DCF.            1 u   89   64   16  188.313  -950198   9.302
                  24.122.14.21    .PPS.            1 u   18   64    7   89.726  -950193   5.180
                  +194.71.144.71   192.36.144.22    2 u   26   64   17  360.986  -950143  55.067
                  *91.189.94.4     193.79.237.14    2 u   23   64   17  169.261  -950200  14.560

       * Il est possible si vous avez une trop grande différence de temps entre "le monde" et votre système que malgré le démarrage du service ntp , le temps reste à la mauvaise heure. Ceci est du au fait que le système ne veut pas faire un trop gros saut dans le temps . Pour corriger le problème vous devez effectué l'opération manuellement 
      
                $ sudo /etc/init.d/ntp stop
                $ sudo ntpdate 91.189.94.4
                23 Sep 08:36:10 ntpdate[8423]: step time server 91.189.94.4 offset -950.214027 sec
                $ sudo /etc/init.d/ntp start


5. C'est le temps d'un boisson réconfortante je pense :D ... 


## <a name="checkup_crontab" /> Validation des tâches planifier mise en place

Encore une fois pas que je ne fait pas confiance au prestataire de service, cependant je désire savoir s'il y a eu une configuration mise en place qui est exécuté régulièrement. Pour donner un exemple **ovh** avait mis en place un système de monitoring qui transmet l'information sur la consommation __CPU__ , mémoire, etc . Ceci est très pratique quand on va sur l'interface client pour voir l'utilisation de la machine, donc l'idée n'est pas d'arracher les configurations en place mais en prendre connaissance :)  et prendre action si requis .

1. Analyse des configurations en place 
    * Vérification de la configuration du __crontab__ général

                $  cat /etc/crontab | grep -v "^#" | grep -v "^$"
                SHELL=/bin/sh
                PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin
                17 *    * * *   root    cd / && run-parts --report /etc/cron.hourly
                25 6    * * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily )
                47 6    * * 7   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly )
                52 6    1 * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly )
       
       Dans la configuration ci-dessus il n'y a pas de configuration particulière mise par une personne tierce uniquement l'exécution des tâches , au heures , journalière , hebdomadaire et par mois 

    * Vérification de l'ensemble des tâches :

                $  ls /etc/cron.*
                 /etc/cron.d:
                 anacron  rsnapshot
                 /etc/cron.daily:
                 0anacron  apt  bsdmainutils  dpkg  logrotate  man-db  passwd  upstart
                 /etc/cron.hourly:
                 /etc/cron.monthly:
                 0anacron
                 /etc/cron.weekly:
                 0anacron  fstrim  man-db

       Dans le contenu présenté ci-dessus uniquement le fichier **rsnapshot** est une particularité de l'environnement l'ensemble du système est normale. Bien entendu profité du moment pour prendre connaissance des scripts , toujours agréable de savoir les tâches qui roulent sur le système.

2. Validation des tâches utilisateurs 
    Si je dois "cacher" une exécution je le mettrai probablement pas sous **/etc** mais sous un utilisateur , malgré le problème de droit qui en découlerai ceci sera moins visible :P . L'ensemble des tâches utilisateurs sont contenu dans le répertoire **/var/spool/cron** . Nous allons donc valider le contenu de ce dernier , bien entendu il faut avoir les permissions **root** pour consulter le répertoire.

            $ sudo ls -lR /var/spool/cron/ 

    Analysez le résultat et faire le ménage si requis , toujours conformément aux règles en place selon le prestataire de service.

3. Commit du changement dans le dépôt **git** du répertoire **/etc** si vous avez réalisez des modifications

## <a name="checkup_log_sys" /> Confirmation que le système de log fonctionne bien 

Les logs , les logs , les logs c'est tellement inutile quand tous va bien !!! C'est tellement essentiel quand ça va mal, pourquoi attendre que le système soit en problème pour valider ces derniers. 

1. Validation que le système de gestion des logs est bien actif et en fonction

            $ ps aux | grep syslo
            syslog      71  0.0  0.1  31380  2756 ?        Ssl  17:13   0:00 /usr/sbin/rsyslogd
            $ sudo /etc/init.d/rsyslog status
             * rsyslogd is running

2. Validation de la configuration , par défaut la configuration sous __Ubuntu__ ainsi que l'ensemble des distributions sont convenable , mais jeté un œil prend quelques minutes et on peut valider du contenu.

                $ cat /etc/rsyslog.conf 
                $ cat /etc/rsyslog.d/50-default.conf

    Ce que je recherche est une entré du type :
    
                *.*   @@192.0.2.1:10514
                *.*   @@other-server.example.net:10514

    Ceci indiquerai que l'ensemble de vos logs sont transmise à un serveur distant , MOI j'aime pas :P , je supprimerai ces lignes , bien entendu conformément à l'entente de service ... blablabla.

3. Si vous réalisez des modifications n'oubliez pas de mettre à jour votre dépôt **git**
4. Redémarrage du service __rsyslog__ s'il y a eu modification

            $ sudo /etc/init.d/rsyslog restart

4. Validation du traitement des logs. 
    Nous allons utiliser un autre terminal pour établir une connexion sur le serveur , sur le serveur nous allons visualisé en continue les logs d'authentification

            $ sudo tail -f  /var/log/auth.log 
            Sep 23 17:23:00 xerus sudo: pam_unix(sudo:session): session opened for user root by bob(uid=0)
            Sep 23 17:23:00 xerus sudo: pam_unix(sudo:session): session closed for user root
            Sep 23 17:29:42 xerus sudo:      bob : TTY=pts/0 ; PWD=/var/log ; USER=root ; COMMAND=/usr/bin/tail -f /var/log/auth.log
            Sep 23 17:29:42 xerus sudo: pam_unix(sudo:session): session opened for user root by bob(uid=0)
            _
            _
            [ ... EN attente de la connexion ... ]
            Sep 23 17:30:55 xerus sshd[96]: Accepted password for bob from 172.17.42.1 port 48732 ssh2
            Sep 23 17:30:55 xerus sshd[96]: pam_unix(sshd:session): session opened for user bob by (uid=0)
            Sep 23 17:30:55 xerus sshd[96]: pam_env(sshd:session): Unable to open env file: /etc/default/locale: No such file or directory

    * Les logs sont bien actif et nous visualisons de l'activité
    * validez que **l'heure** est convenable , comme nous avons réalisé la configuration __ntp__ normalement pas de problème, mais bon 2 validations c'est mieux 
    * comme vous pouvez le constater j'ai une erreur de __pam__ que je vais devoir corrigé , merci la formation :P.

## <a name="minimum_apps" /> Installation d'application vital :P

Bon voilà les premières validations sont réalisez, nous allons finaliser la configuration de la prise en main en installant les applications essentiels pour la survie.

Comme il y a des petits malin qui saute les sections :P , je vais remettre les applications déjà installé précédemment .

        $ sudo apt-get install git vim screen tmux byobu netcat telnet net-tools wget whois openssh-client sudo rsync python3 ntp ntpdate a2

Faut rajouter ce que vous avez besoin ici c'est vraiment une liste minimal .

# <a name="base_security" /> Suggestion de mise en place de sécurité 

Cette partie est "optionnel" , bien que je pense vraiment importante nous allons mettre en place des mécanismes de sécurité , nous ne mettrons pas des systèmes ultra sophistiqué nous sommes à l'étape de prise en main de la machine. Je vous invite vraiment à faire ces opérations au début car par la suite c'est pénible et nous n'avons plus le temps de le faire.

Nous verrons la mise en place :
* d'un __firewall__ (In/Out)
* Mise en place d'une solution de validation des fichiers
* Mise en place d'une solution de surveillance du système (monitoring)

## <a name="setup_fw" /> Mise en place d'un firewall 

Tous le monde est d'accord pour mettre en place un __firewall__ pour l'ensemble des communications entrante, mais moi je dis plus . Définissez aussi un __firewall__ pour les communications sortante, honnêtement c'est un peu plus pénible à géré mais au moins on sait avec qui la machine communique vers l'externe. 
Nous utilisons des logiciels libre, mais ça ne veut pas dire que l'on est protégé d'envois d'information à l'externe. Honnêtement combien de fois avez vous lu le code source d'une application :P, ainsi que les __Release Note__ ou __Change Log__ d'une application lors d'une mise à jour :p. Il est possible que textuellement il est écrit que maintenant l'application envoie des statistique vers une machine externe . Qui blâmé dans cette situation ? Le développeur ou l'administrateur :P. 
Comme je lis pas toujours bien les __release notes__ :P et encore moins le code , je préfère mettre un firewall vers l'externe puis ouvrir les communications requise. 

Bon je planifie pas faire une formation __iptables__ ici , à ce stade pour le faire bien nous devrons faire un session spécial je fournit donc une fichier de configuration et on en parle rapidement. Par la suite je vous laisse modifier le fichier pour votre besoin puis on en reparle dans quelques mois :D.

1. Installation des applications requise

        $ sudo apt-get install iptables iptables-persistent

   Lors de la réalisation de l'installation en temps normale __iptables__ va démarrer tous seul et le pacquage __iptables-persistent__ vous demandera s'il faut sauvegarder la configuration. 
   Si ce n'est pas le cas :

        $ sudo /etc/init.d/iptables-persistent start

2. État de la situation lorsque __iptables__ est "actif"

        $ sudo iptables -L -n
        Chain INPUT (policy ACCEPT)
        target     prot opt source               destination         

        Chain FORWARD (policy ACCEPT)
        target     prot opt source               destination         

        Chain OUTPUT (policy ACCEPT)
        target     prot opt source               destination  

   Comme vous pouvez le voir il n'y a aucun limitation la **politique** (__policy__) est à accepté donc tous passe, c'est mieux comme ça :P , sinon vous n'auriez peut-être plus accès à la machine si le port 22 était bloqué :D.

3. Réalisation d'un fichier de configuration, bloquer les communications **entrante**

Nous débuterons par bloquer le plus important les communications en entré vers la machine, à ce point nous allons permettre UNIQUEMENT l'accès au port 22 . 

Le fichier de configuration du __firewall__ est présent dans le fichier : **/etc/iptables/rules.v4**, voyons le contenu à cette étape :

        $ sudo cat /etc/iptables/rules.v4
        # Generated by iptables-save v1.4.21 on Mon Sep 26 21:03:14 2016
        *nat
        :PREROUTING ACCEPT [0:0]
        :INPUT ACCEPT [0:0]
        :OUTPUT ACCEPT [6:368]
        :POSTROUTING ACCEPT [6:368]
        COMMIT
        # Completed on Mon Sep 26 21:03:14 2016
        # Generated by iptables-save v1.4.21 on Mon Sep 26 21:03:14 2016
        *filter
        :INPUT ACCEPT [10242:14498342]
        :FORWARD ACCEPT [0:0]
        :OUTPUT ACCEPT [7048:401819]
        COMMIT
        # Completed on Mon Sep 26 21:03:14 2016

Il n'y a pas de règles pour votre information nous allons ajouter des instructions pour l'entrée **INPUT**.

        $ sudo vim /etc/iptables/rules.v4
        $ sudo cat 
            1  # Generated by iptables-save v1.4.21 on Mon Sep 26 21:03:14 2016
            2  *nat
            3  :PREROUTING ACCEPT [0:0]
            4  :INPUT ACCEPT [0:0]
            5  :OUTPUT ACCEPT [6:368]
            6  :POSTROUTING ACCEPT [6:368]
            7  COMMIT
            8  # Completed on Mon Sep 26 21:03:14 2016
            9  # Generated by iptables-save v1.4.21 on Mon Sep 26 21:03:14 2016
           10  *filter
           11  :INPUT ACCEPT [10242:14498342]
           12  -A INPUT -p icmp -m comment --comment "000 accept all icmp" -j ACCEPT
           13  -A INPUT -i lo -m comment --comment "001 accept all to lo interface" -j ACCEPT
           14  -A INPUT -m comment --comment "002 accept related established rules" -m state --state RELATED,ESTABLISHED -j ACCEPT
           15  -A INPUT -p tcp -m multiport --dports 22 -m comment --comment "010 allow ssh from admins network" -j ACCEPT
           16  -A INPUT -m comment --comment "999 drop ALL" -j DROP
           17  :FORWARD ACCEPT [0:0]
           18  :OUTPUT ACCEPT [7048:401819]
           19  COMMIT
           20  # Completed on Mon Sep 26 21:03:14 2016

Ajout des lignes 12 à 16 , nous allons pouvoir recharger la configuration, petit truc du gars qui s'est déjà tiré une balle dans le pied tout seul comme un grand :D . __Yep__ le problème quand on charge des règles de __firewall__ à distance est de se bloquer du serveur. Quand la machine est a coté de vous c'est pas grave, mais dans un centre de donnée voir dans un autre pays c'est pénible. Puis appeler un techniciens pour lui dire qu'on s'est chier dessus c'est gênant :D !!

Donc truc d'expert :P :
    1. Démarrage de __screen__ , __tmux__ , __byobu__ vous avez le choix. Pourquoi je fais ça pour m'assurer que même si je perd m'a session sur la machine mes instructions seront toujours réalisé.

        $ byobu

    2. Activation  des règles de __firewall__ avec une pause après le chargement et l'arrêt du service de __firewall__

        $ sudo /etc/init.d/iptables-persistent reload && sleep 300 && sudo /etc/init.d/iptables-persistent flush 
         * Loading iptables rules...    
         * IPv4...           
         * skipping IPv6 (no rules to load)...                               [ OK ]
        [ APPUYEZ sur CTRL+C si tous fonctionne bien pendant le sleep ]

    3. Une fois les règles charger valider que vous avez toujours accès au serveur , établissez une autre connexion sur la machine si tous fonctionne bien , pendant le __sleep__ arrêtez l'opération avec les touches **CTRL+C**. Si vous avez perdu l'accès :P , ça arrive à tous le monde ... Vous devez attendre 5 minutes (60 sec * 5  = 300 sec )  que les règles se __flush__ pour reprendre le contrôle. Nous vous faites pas violence pendant ce temps , c'est le métier qui rentre :D.

Ceci offre le résultat : 

        $ sudo iptables -L -n
        Chain INPUT (policy ACCEPT)
        target     prot opt source               destination         
        ACCEPT     icmp --  0.0.0.0/0            0.0.0.0/0            /* 000 accept all icmp */
        ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0            /* 001 accept all to lo interface */
        ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0            /* 002 accept related established rules */ state RELATED,ESTABLISHED
        ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0            multiport dports 22 /* 010 allow ssh from admins network */
        DROP       all  --  0.0.0.0/0            0.0.0.0/0            /* 999 drop ALL */

        Chain FORWARD (policy ACCEPT)
        target     prot opt source               destination         

        Chain OUTPUT (policy ACCEPT)
        target     prot opt source               destination   

4. Explications de la configuration 
    1. La politique d'entré est toujours à **ACCEPT** cependant si vous regardez la dernière ligne juste avant __Chain FORWARD__ vous constatez qu'il y a l'instruction **DROP** qui enverra dans les limbes les paquets transmis (__aka timeout__).
    2. **ICMP** : les requêtes __ping__ sont acceptés donc nous répondons à ces dernières honnêtement j'aime bien laissé le __ping__ car pour diagnostiquer c'est vachement pratique.
    3. **Communication sur localhost** : Je désires bloquer l'extérieure mais toute communication sur l'interface __localhost__= 127.0.0.1 doit être autorisé , je ne vois pas la plus value de les bloquer.
    4. **related established rules** : C'est le GROS truc à pas oublier , généralement c'est cette règles que l'on oublie et qui fait que l'on perd l'accès à la machine. L'ensemble des règles de __firewall__ s'applique sur les nouveaux paquets qui arrive ( **new** ) paquet **SYN** , par la suite pour alléger le traitement l'ensemble transige dans la règle __002__ (numéro arbitraire dans ce cas).
    5. **multiport dports 22** : autorisation des communications vers le port 22 , donc du serveur __OpenSSH__.
    6. **DROP everythings** : Si aucune règle ne fut appliqué ci-dessus alors l'ensemble des paquets sont perdu , aucun réponse n'est fournit indiquant le problème la personne recevra un __timeout__ . Nous aurions pu ajouter une instruction __LOG__ afin de conservé un trace préalablement des communications qui sont coupé mais au nombre de connexion erroné que l'on reçoit d'Internet ceci génère beaucoup trop de logs. Nous verrons donc cette option lors de la limitation d'accès des communications vers l'externe.

    Prendre note que l'ordre définie ici est très important quand un paquet arrive sur la machine il traite chaque règle dès qu'une règle est applicable il sort du traitement. L'instruction **DROP** doit donc être impérativement à la fin de la liste !


5. Réalisation d'un fichier de configuration, bloquer les communications **sortante**
    Maintenant que nous avons bloqué les communications provenant de l'externe, si vous désirez bloquer les communications **sortante** , nous allons éditer le fichier de configuration pour ajouter des instructions dans la **chain OUTPUT** !
    Nous allons reprendre le fichier **/etc/iptables/rules.v4** , ajoutez le contenu suivant :

            $ sudo vim /etc/iptables/rules.v4
            -A OUTPUT -p icmp -m comment --comment "000 Authorize all icmp" -j ACCEPT
            -A OUTPUT -o lo -m comment --comment "001 Authorize all to lo interface" -j ACCEPT
            -A OUTPUT -m comment --comment "002 Authorized related established rules" -m state --state RELATED,ESTABLISHED -j ACCEPT
            -A OUTPUT -d 199.19.167.36/32 -p udp -m multiport --dports 123 -m comment --comment "300-123-NTP_0.ca.pool.ntp.org_-199.19.167.36--udp-123" -j ACCEPT
            -A OUTPUT -d 199.85.124.148/32 -p udp -m multiport --dports 123 -m comment --comment "300-123-NTP_0.ca.pool.ntp.org_-199.85.124.148--udp-123" -j ACCEPT
            -A OUTPUT -d 208.73.56.29/32 -p udp -m multiport --dports 123 -m comment --comment "300-123-NTP_0.ca.pool.ntp.org_-208.73.56.29--udp-123" -j ACCEPT
            -A OUTPUT -d 216.234.161.11/32 -p udp -m multiport --dports 123 -m comment --comment "300-123-NTP_0.ca.pool.ntp.org_-216.234.161.11--udp-123" -j ACCEPT
            -A OUTPUT -d 127.0.0.1/32 -p tcp -m multiport --dports 53 -m comment --comment "300-53-DNS-127.0.0.1--tcp-53" -j ACCEPT
            -A OUTPUT -d 127.0.0.1/32 -p udp -m multiport --dports 53 -m comment --comment "300-53-DNS-127.0.0.1--udp-53" -j ACCEPT
            -A OUTPUT -d 213.186.33.102/32 -p tcp -m multiport --dports 53 -m comment --comment "300-53-DNS-213.186.33.102--tcp-53" -j ACCEPT
            -A OUTPUT -d 213.186.33.102/32 -p udp -m multiport --dports 53 -m comment --comment "300-53-DNS-213.186.33.102--udp-53" -j ACCEPT
            -A OUTPUT -d 213.186.33.99/32 -p tcp -m multiport --dports 53 -m comment --comment "300-53-DNS-213.186.33.99--tcp-53" -j ACCEPT
            -A OUTPUT -d 213.186.33.99/32 -p udp -m multiport --dports 53 -m comment --comment "300-53-DNS-213.186.33.99--udp-53" -j ACCEPT
            -A OUTPUT -d 8.8.4.4/32 -p tcp -m multiport --dports 53 -m comment --comment "300-53-DNS-8.8.4.4--tcp-53" -j ACCEPT
            -A OUTPUT -d 8.8.4.4/32 -p udp -m multiport --dports 53 -m comment --comment "300-53-DNS-8.8.4.4--udp-53" -j ACCEPT
            -A OUTPUT -d 91.189.88.149/32 -p tcp -m multiport --dports 80 -m comment --comment "300-80-APT_-security.ubuntu.com--tcp-80" -j ACCEPT
            -A OUTPUT -d 142.4.218.29/32 -p tcp -m multiport --dports 80 -m comment --comment "300-80-APT_-ubuntu.bhs.mirrors.ovh.net--tcp-80" -j ACCEPT
            -A OUTPUT -d 216.239.32.0/19 -p tcp -m multiport --dports 80 -m comment --comment 600_google1 -j ACCEPT
            -A OUTPUT -d 173.194.0.0/16 -p tcp -m multiport --dports 80 -m comment --comment 600_google10 -j ACCEPT
            -A OUTPUT -d 172.217.0.0/20 -p tcp -m multiport --dports 80 -m comment --comment 600_google11 -j ACCEPT
            -A OUTPUT -d 64.233.160.0/19 -p tcp -m multiport --dports 80 -m comment --comment 600_google2 -j ACCEPT
            -A OUTPUT -d 66.249.80.0/20 -p tcp -m multiport --dports 80 -m comment --comment 600_google3 -j ACCEPT
            -A OUTPUT -d 72.14.192.0/18 -p tcp -m multiport --dports 80 -m comment --comment 600_google4 -j ACCEPT
            -A OUTPUT -d 209.85.128.0/17 -p tcp -m multiport --dports 80 -m comment --comment 600_google5 -j ACCEPT
            -A OUTPUT -d 66.102.0.0/20 -p tcp -m multiport --dports 80 -m comment --comment 600_google6 -j ACCEPT
            -A OUTPUT -d 74.125.0.0/16 -p tcp -m multiport --dports 80 -m comment --comment 600_google7 -j ACCEPT
            -A OUTPUT -d 64.18.0.0/20 -p tcp -m multiport --dports 80 -m comment --comment 600_google8 -j ACCEPT
            -A OUTPUT -d 207.126.144.0/20 -p tcp -m multiport --dports 80 -m comment --comment 600_google9 -j ACCEPT
            -A OUTPUT -m comment --comment "998 log all output " -m state --state NEW -j LOG
            -A OUTPUT -m comment --comment "999 drop ALL OUTGOING" -j REJECT --reject-with icmp-port-unreachable
            COMMIT
            # Completed on Mon Sep 26 08:00:55 2016

    Bien entendu il y a beaucoup de changement à réaliser afin de correspondre à votre besoin, car chaque règle inclut une destination spécifique qui est convenable pour MOI mais doit être évalué dans votre situation. Prendre note que les règles de __firewall__ sont appliquées sur des adresses IP , bien que l'on puisse mettre des nom de domaine lors de la définition ces derniers seront convertie en IP lors du chargement initiale.

6. Explications de la configuration des communications **sortante** 
    1. **ICMP** : tous comme pour les communications interne , je permet au paquet **ICMP** donc __ping__ de sortir de la machine , pour la même raison que lors de communication entrante soit facilité le diagnostique de problème.
    2. **Communication sur localhost** : Je désires bloquer vers l'extérieure mais toute communication sur l'interface __localhost__= 127.0.0.1 doit être autorisé , je ne vois pas la plus value de les bloquer.
    3. **related established rules** : C'est le GROS truc à pas oublier , généralement c'est cette règles que l'on oublie et qui fait que l'on perd l'accès à la machine. L'ensemble des règles de __firewall__ s'applique sur les nouveaux paquets transmit( **new** ) paquet **SYN** , par la suite pour alléger le traitement l'ensemble transige dans la règle __002__ (numéro arbitraire dans ce cas).
    4. **NTP** : Comme je désire que mon serveur soit toujours à l'heure je permet la communication vers les serveurs de temps. La communication se fait sur le port **123** en **UDP** , dans la configuration de mon service j'ai définie le pool **ca.pool.ntp.org**. Telle que mentionné plus tôt __iptables__ va faire le traitement uniquement par adresse IP je dois donc spécifier toute les IP qui seront utilisées. Quand je réalise la résolution __DNS__

            $ host ca.pool.ntp.org
            ca.pool.ntp.org has address 159.203.8.72
            ca.pool.ntp.org has address 192.95.27.155
            ca.pool.ntp.org has address 167.114.205.5
            ca.pool.ntp.org has address 198.50.135.212

       Voila pourquoi nous voyons 4 règles de __firewall__ pour ce service , et oui c'est contraignant !! Heureusement ça ne change pas beaucoup et honnêtement je vous conseille de mettre un système automatique qui fera la validation si les IP changent.
    5. **DNS** : Bien entendu nous devons permettre les communications vers les serveurs __DNS__ , les règles pour l'IP 127.0.0.1 sont complètement inutile car la règle __002__ va déjà permettre la communication. La règle est présente car en fait mes règles de __firewall__ sont générés :P . Le protocole __DNS__ utilise principalement le protocole __UDP__ sur le port 53. Si vous regardez ma configuration j'autorise l'__UDP__ et le __TCP__ , si la taille de la communication avec le serveur __DNS__ est trop grande le service va passer en __TCP__ donc je préfère avoir les 2 d'ouvert pour éviter des problèmes potentiel ! J'ai la définition des serveurs d'__DNS__ de __OVH__ , __google__.
    6. **APT** : Bien entendu moi aussi j'installe des logiciels et je les met à jour, j'ai donc l'autorisation de communications vers les serveurs __apt__ configurer , ici nous retrouvons le miroirs __d'ovh__ ainsi que le site web d'Ubuntu __security__ uniquement sur le port 80 , car il n'utilise pas le __httpS__.
    7. **IP de Google** : c'est le côté obscure de mes règles :-/, j'autorise l'ensemble des communications vers les IP de google, mais mais mais pourquoi, me direz vous !!! ??? !!! Le super site de __moodle__ utilise le système de __Captcha__ pour valider que les personnes qui s'inscrivent ne sont pas des robots. Ce dernier est fournit par google , le problème est que google ne garantie pas sur quelle IP ces services seront disponible ! Il demande que l'ensemble de ses segments IP soit ouvert : 
    TODO : Ajouter lien site web google !!

# <a name="test_recovery" /> Validation de la procédure de recouvrement 
