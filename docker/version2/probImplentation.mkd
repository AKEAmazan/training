<meta http-equiv='Content-Type' content='text/html; charset=utf-8' />
<style>
pre{background:#F8F8FF; border:black dashed 1px; padding:6px}
</style>

# Index


* [ Mise en contexte ](#context) 
* [ Création des images et conteneurs ](#conteneurPropre) 
       * [ Un conteneur pour une taches ](#ConteneurUnetache) 
       * [ Création du conteneur de BD centraliser.](#ConteneurCentraliser) 
       * [ Docker n'ajoute pas d'overheard, oui MAIS ...](#noOverHead) 
       * [ Utilisation du registry](#UseRegistry) 
       * [ Création d'un conteneur avec une image "moins belle"](#ConteneurCommité) 
* [ Orchestration des conteneurs](#orchestration) 
       * [ Organisation d'un changement de variable ou volume](#ChangeVarVol) 
       * [ Organisation des fichiers et volumes](#FileStructure) 
* [ Mise en place de réseau dédié à docker](#NetworkStructure) 
       * [ Redirection des ports](#Redirect_port) 
           * [ Détection des ip d'origine](#Redirect_port_srcip) 
           * [ Conteneur http utilisation des port 80/443](#Redictect_port_Http) 
           * [ Le défis des adresse IP dynamique](#ChallangeDynIP) 
       * [ Utilisation de conteneur exclusif au VPN](#ConteneurVPNonly) 
* [ Problème lors d'un disque dur remplie](#ProbHDFull) 
       * [ Limitation d'espace par conteneur](#SpaceLimitConteneur) 
* [ Optimisation de Dockers](#OptDocker) 
       * [ Assignation d'un Volume Groupe (LVM)](#OptDockerFS) 
       * [ Monitoring du système Docker](#MonitoringDck) 

# <a name="context" /> Mise en contexte 

Nous avons vu précédemment les grandes lignes de l'utilisation de docker, c'est les grands principes de l'utilisation du système après libre à vous de réaliser votre propre recette. L'informatique et plus particulièrement l'opensource c'est un peu comme les recettes de cuisine, il y a une recette qui est une base mais si vous aimez plus ingrédient rien vous empêches d'en mettre plus :P !

Par contre le gros problèmes de l'ensemble des documentations est qu'ils donnent rarement des trucs et astuce ou relater des problème lors de l'implémentation :-/. Je vais donne vous fournir de l'information sur des problèmes que j'ai rencontré ainsi que les solutions mise en place afin d'au moins vous orienter si un problème similaire vous arrive.
L'expérience couvre 1 an d'utilisation plus une mise en production pour un serveur personnel !


# <a name="conteneurPropre" /> Création des images et conteneurs 

Bien entendu en premier lieu il y a la création d'image, personnellement l'ensemble de mes images furent réalisé à 85 % dans le train sur un petit portable 64bits (__Lenovo T430__) on est loin d'un ultra portable. Les 15 % restant est sur mon poste de travail à la maison , le gros avantage est que ce fut un travail itératif, continue, le tous conservé avec **git** !

J'ai identifié les applications que je désirai avoir et analyser s'il y avait des conteneurs officiel disponible !

Voici les officiels que j'ai pu utiliser :

* **httpd**
* **mysql**
* **debian**
* **ubuntu**
* **ngnix**
* **gitlab/gitlab-ce:latest**

Comme vous pouvez le constater ceci est principalement des images de base , sauf **gitlab** qui est considéré comme non officiel sur le site [http://hub.docker.com](http://hub.docker.com), mais qui est créé par **gitlab**.

Bien entendu mon site à plus de service que __MySQL__ , __gitlab__ ou __ngnix__ ... 

J'ai donc du réalisé soit des **Dockerfile** ou utiliser des images dit public !! 
J'ai voulu mettre en place le service __tmate__ qui permet de partagé un **Shell** avec __tmux__ en __RO__ ou __RW__. Bon finalement ce n'est pas en place :P, j'ai tenté de faire le __Dockerfile__ mais les priorités ont changé en cours de réalisation. Si nous regardons sur le site de [http://hub.docker.com](http://hub.docker.com) vous trouverez une images disponible :

* [https://hub.docker.com/r/dakue/tmate-slave/~/dockerfile/](https://hub.docker.com/r/dakue/tmate-slave/~/dockerfile/) 

Je n'aime pas du tous cette configuration, voici pourquoi :

* La récupération d'un artefact est réalisé sur **circle-artifacts.com**, personnellement je ne connais pas ce qui ne me met pas en confiance !

Je n'ai pas d'autre exemple en tête mais l'important du propos est de bien valider les images que vous prenez , je vous dirai même dans le doute prenez comme référence un __Dockerfile__ et créez le votre.

Je vous invite **FORTEMENT** à utilisé un contrôleur de révision afin d'avoir une trace de l'évolution de vos images afin de pouvoir revenir en arrière ou vous inspirér des configurations réalisé.

## <a name="ConteneurUnetache" /> Un conteneur pour une taches 

Bon voilà , nous avons vue la théorie les principes le mode de fonctionnement et les principes. Maintenant on va voir la pratique, qui malheureusement diverge de la théorie. 

Prenons le conteneur officiel de **gitlab** [https://hub.docker.com/r/gitlab/gitlab-ce/](https://hub.docker.com/r/gitlab/gitlab-ce/), cette image est très bien créer et fonctionne à merveille. De plus comme ceci est la version officiel fournit par l'entreprise **gitlab** nous avons l'avantage d'avoir une version régulièrement mise à jour nous assurant le maintient de l'application autant au niveau __bug__ que patch de sécurité !

Malheureusement l'image ne suis pas le principe UNE image , UNE taches , l'images contient plusieurs application dans l'images formant un tous cohérent, mais les puristes diront qu'elles n'est pas BELLE.

L'image **gitlab** est composé de :

* __ngnix__ :  pour l'accès web ainsi que les commit via le protocole __http__
* __unicorn__ : serveur web en **ruby** pour faire le traitement des requêtes, permet d'utiliser l'ensemble des fonctions de __ruby__
* __postgress__ : Base de donnée pour stocker l'information
* __sidekiq__ : un système de traitement en arrière plan des requêtes permettant de traiter des jobs en __batch__
* __sshd__ : Permet de réaliser des commit dans les dépôts avec le protocole ssh

Bon on est loin d'une image = un processus, suivant le principe nous aurions du avoir 5 conteneurs qui interagisse ensemble pour fournir le service, mais bon de vous à moins j'avais pas envie de faire mon propre __Dockerfile__ et surtout de devoir le maintenir dans le temps. Comme je ne suis pas un puriste pour tous , sauf le logiciel libre , j'ai pris le conteneur et il fonctionne à merveille !!!

Je parle ici du conteneur __gitlab__, mais j'ai choisi de réaliser le même type de configuration pour le système de courriel, pourquoi ?
Soyons honnête avoir soit même par paresse , mais aussi car je n'ai pas de charge sur mon système qui pourrait m'amener à devoir augmenté le nombre de processus requis pour le traitement des spams par exemple. J'ai choisie une voix de simplicité , surtout que je n'ai pas dans la planification à court terme de partagé une partie telle que le service **imap** avec un autre conteneur.

Voici ce que contient mon images de courriel :

* **postfix** : service de __mta__ pour faire l'envoie et gérer la réception de courriel
* **spamd** : Réalise la traitement contre les spams
* **clam** : Service d'antivirus 
* **freshclam** : Service de mise à jour de la base de donnée de virus.
* **postgrey** : Permet de faire du gray listing , afin de réduire les spams ... (bon de vous a moins j'y crois pas mais bon ... :P )
* **opendkim** : Permet de signer les courriels sortant en lien avec les configurations réalisé dans les __DNS__ pour confirmer la provenance.
* **dovecot** : Service de **pop3** et **imap** pour permettre la récupération des courriels par le client
* **ngnix** : Serveur web pour fournir le __webmail__ ainsi que la page d'administration du système
* **SOGo** : Service de webmail
* **admin** : Service d'administration du service

Comme vous pouvez le constater, c'est pas l'image la plus belle mais c'est un tous complet !!

## <a name="ConteneurCentraliser" /> Création du conteneur de BD centraliser.

Il y a par contre un élément manquant dans mon image de gestion de mes courriels, la base de données contenant l'ensemble des informations des utilisateurs ( nom, courriel, alias, mot de passe , calendrier , contacts, ...). 
J'ai opté pour un service de base de données dans un conteneur pour l'ensemble de mes services , car en plus du service de courriels qui utilise une base de données __MySQL__ il y a le service **moodle**, mon **CMS** , mon système de facturation, ... Ils se reposent tous sur une base de donnée , comme je n'avais pas envie d'avoir **un** conteneurs de base de donnée pour chaque service il utilise tous le même pour la production.

Je précise pour la production, car dans le cadre du développement de mes images j'ai utiliser un base de donnée unique pour mes applications .

Voici une représentation graphique de l'utilisation des images et conteneurs :

* **Dev** :

![schema_imgs-conteneur_mysql-dev.png](./imgs/schema_imgs-conteneur_mysql-dev.png)

* **PROD** : 

![schema_imgs-conteneur_mysql-prod.png](./imgs/schema_imgs-conteneur_mysql-prod.png)

Comme vous pouvez le voir j'utilise toujours la même images, donc pas de différence au niveau du système __MySQL__ utilisé que ce soit en développement ou en production. 
Pourquoi cette configuration différente :

* **Dev** :
    * Dans le cadre du développement / validation de la configuration je veux pouvoir détruire ma base de donnée librement pour démarrer avec ma nouvelle image de l'application.
    * Je ne veux pas avoir aucune configuration à réaliser sur la base de donnée, donc quand elle démarrer l'utilisateur et la BD sont créer et dédier pour mon application.
    * Je vous être en mesure de démarrer mon application peut importe le lieu ou je suis portable, ordinateur à la maison sans aucune dépendance autre que mes conteneurs.
    * Si je réalise des stress teste applicatif aucune impacte sur d'autre application en cours.

Bon là vous vous dites pourquoi alors avoir eu une pratique différente pour la production car les raisons nommé ci-dessus s'appliquerait aussi bien en production, sauf peut-être la question de la suppression des données. Réponse ...

* **Prod** :
    * Je ne veux pas a avoir à réaliser des backups sur  4 ou 5 conteneurs de base de données __SQL__ . Je veux avoir un __dump__ complet de mes données dans un fichier . J'ai trop peur d'oublier de prendre une sauvegarde de mes données !!
    * Je n'ai qu'une base de donnée à __Monitorer__ , si nous parlons de performance ou de disponibilité.
    * S'il y a des interactions entre mes applications elles peuvent consulter les données de l'autre système avec le même utilisateur en ajustant les permissions.
    * Je cherche à réduire l'emprunte mémoire et CPU en réduisant le nombre de conteneur (voir section suivante).

Bien entendu ceci est MON choix libre à vous de trouvez cette solution idéal ou non , bien entendu il y a des coté négatif :

* Lors de maintenant l'ensemble des applications sont impacté !

## <a name="noOverHead" /> Docker n'ajoute pas d'overheard, oui MAIS ...

Mon dernier point pour le choix de la mutualisation des bases de données en production indique que je cherche à réduire l'emprunte CPU et mémoire !
C'est étrange, car lors de la présentation général de Docker j'avais spécifier que Docker ne rajoute pas de charge sur le système (__overhead__).

Effectivement Docker ne consomme pas plus de ressource que si l'application était exécuté native , mais si j'ai 5 applications WEB (apache + __MySQL__ ). 

Voici la configuration "classique" sans conteneur : 

![classique_Infra-5web-apps.png](./imgs/classique_Infra-5web-apps.png)

Nous avons donc 1 processus **apache** qui prend l'ensemble des requêtes , en mode __prefork__ par défaut le système démarrer 5 processus pour être en mesure de prendre les requêtes. Lors de la monté en charge il pourra démarrer jusque 150 processus et conservera toujours 10 processus  une fois la monté en charge réalisé.
La base de données aussi fournit le service pour l'ensemble des services, nous avons 1 processus __MySQL__ qui est démarrer pour les 5 applications.

Si nous regardons le mode de fonctionnement avec Docker , nous n'aurons plus 1 processus apache mais 5 , car chaque conteneur étant isolée il devra avoir son propre processus apache pour prendre en charge les requêtes qui arrive. Est-ce grave ?!?! Non pas  pas vraiment , faut juste s'assurer que la configuration de votre apache soit approprié pour votre application . Comme il y avait mutualisation des services sur une machine nous devions permettre à apache de conservé plus de processus "dormant" , alors que pour votre application peut-être que démarrer uniquement 2 processus au startup et en conserver que 4 en cas de monté en charge serait plus adéquat.

Voici la représentation graphique évidente du résultat avec des conteneurs. 

![docker_Infra-5web-apps.png](./imgs/docker_Infra-5web-apps.png)

Personnellement je trouve que ça vaut le coup, car si nous prenons l'économie de __l'overhead__ des __VM__ ce coût est minime.

Je pense que c'est important de le signaler , car il faut le prendre en considération !! 
Vous comprenez pourquoi j'ai mutualisé mon service de base de donnée, maintenant je ne voyais pas de plus values à avoir un processus __MySQL__ par application. L'avenir me donnera peut-être tord , il sera toujours temps de changer ma configuration à ce moment là car c'est la même image :D.

## <a name="UseRegistry" /> Utilisation du registry

Je vous suggère FORTEMENT d'utiliser un __registry__ pour vos images, je ne l'ai pas encore fait j'ai repousser cette opération par manque de temps , cependant sans __registry__ vous êtes obligé de compiler tous le temps vos images. Si vous utilisez un __registry__ ceci veut dire que si vous avez __buildé__ votre image sur une machine elle sera disponible sur les autres via le téléchargement depuis le __registry__ . 
C'est vraiment pénible de devoir recréer l'image sur une nouvelle machine quand vous savez pertinemment que vous l'avez déjà fait , de plus vous pouvez grâce au système de révision (__tag__) des images , vous assurez que vous utiliser toujours la même . Si vous recompilez toujours depuis le __Dockerfile__ , il est possible qu'il y est une modification réaliser dans le __SVN__ ou le GIT résultat vous ne construisez pas l'image à l'identique que ce qui fut testé.

## <a name="ConteneurCommité" /> Création d'un conteneur avec une image "moins belle"

TODO : a valider si je le fait !

# <a name="orchestration" /> Orchestration des conteneurs

Lors de l'introduction, j'ai démarrer mes conteneurs avec la commande **docker run** en passant le nom du conteneur , l'image de référence ainsi que les variables d'environnement utilisé par le conteneur. Ceci est la technique pour démarrer rapidement un conteneur, par contre ceci rencontre RAPIDEMENT la limitation car il faut mémoriser la ligne de commande avec l'ensemble des arguments. 
Quand vous avez un grand nombre de conteneur avec beaucoup de variable vous préférerez avoir un fichier conteneur l'ensemble de l'orchestration pour un service. Heureusement la communauté à pensé à tous , vous avez [docker-compose](https://docs.docker.com/compose/) disponible pour vous aider.

Voici un exemple d'un fichier docker-compose :

        version: '2'
        services:
            x3-cmsms:
                image: x3-cmsms
                container_name : 'x3-cmsms-l'
                hostname: website.x3rus.com
                environment:
                    - DB_HOST=mysql
                    - DB_DATABASE=cms
                    - DB_USERNAME=cms_user
                    - DB_PASSWORD=superPassWord
                    - TIMEZONE=America/Montreal
                    - TERM=xterm
                links:
                    - x3-cmsms-my:mysql
                port:
                    - 80:80
                volumes:
                    - /srv/docker/cms/upload:/var/www/html/cms/upload
            x3-cmsms-my:
                image: mysql:5.5
                container_name : 'x3-cmsms-my-l'
                hostname: cms-mysql.x3rus.com
                environment:
                    - MYSQL_ROOT_PASSWORD=superPatate
                    - TIMEZONE=America/Montreal
                    - TERM=xterm

Prenons une petite minute pour analyser ce fichier :

* **x3-cmsms** et **x3-cmsms-my** : ceci est les 2 services géré par le __docker-compose__ respectivement le service **CMS** et la base de donnée en __backend__.
* **x3-cmsms** :
    * Nous utilisons l'image **x3-cmsms** , nous lui assignons un nom pour le conteneur **x3-cmsms-l** et un hostname **website.x3rus.com**
    * Une liste de variables d'environnement serons assigné lors de l'exécution , principalement les paramètres d'authentification pour la BD ainsi que le fuseau horaire.
    * Bien entendu la service à besoin d'une base de donnée qui est définie dans le même fichier nous réalisons un lien entre les 2 conteneur **links**
    * Suivie de l'assignation de port et répertoire.
* **x3-cmsms-my** :
    * nous utilisons l'image officiel de __MySQL__ soit 5.5 
    * Assignation d'un nom et un nom de machine
    * encore une fois nous retrouvons les variables principalement le mot de passe __root__.

Comme vous pouvez le voir ceci est mon environnement de développement, car mon service de base de donnée est directement lié à l'application en production la dynamique est différente. Je n'utilise pas un **links** mais **external-links** car ma définition de base de donnée n'est pas écrite dans le fichier __docker-compose__ de l'applicatif.

En production j'ai aussi un paramètre indiquant que je veux que le service démarrer toujours après un redémarrage : **restart: always**

## <a name="ChangeVarVol" /> Organisation d'un changement de variable ou volume

Rappelons nous un point important que j'ai mentionné lors de la présentation précédente , lors du démarrage d'un conteneur nous lui assignons des variables lors de l'utilisation de l'instruction **docker run** par la suit nous utilisons **docker start** car nous ne pouvons plus changer les variables d'environnement ou les volumes  !!! 

Résultat regardons ma configuration pour **gitlab**  :


        cm-gitlab:
            image: 'gitlab/gitlab-ce:latest'
            restart: always
            container_name : 'cm-gitlab'
            hostname: source.x3rus.com
            environment:
                TZ: America/Montreal
                GITLAB_OMNIBUS_CONFIG: |
                    external_url 'https://source.x3rus.com'
                    gitlab_rails['time_zone'] = 'America/Montreal'
                    gitlab_rails['gitlab_email_from'] = 'noreply@x3rus.com'
                    gitlab_rails['manage_backup_path'] = true
                    gitlab_rails['backup_path'] = "/var/opt/gitlab/backups"
                    gitlab_rails['backup_archive_permissions'] = 0640
                    gitlab_rails['backup_keep_time'] = 604800
                    gitlab_rails['smtp_enable'] = true
                    gitlab_rails['smtp_address'] = "cm-mail"
                    gitlab_rails['smtp_port'] = 25
                    gitlab_rails['smtp_enable_starttls_auto'] = false
                    gitlab_rails['smtp_tls'] = false
                    pages_nginx['redirect_http_to_https_port'] = 80
                    registry['enable'] = true
                    registry_external_url 'https://rg.source.x3rus.com:8443'
                    gitlab_rails['registry_enabled'] = true
                    gitlab_rails['registry_host'] = "rg.source.x3rus.com"
            external_links:
                - /cm-mailrelay
            ports:
                - '192.99.82.212:22:22'
                - '192.99.82.212:80:80'
                - '192.99.82.212:443:443'
                - '192.99.82.212:8443:8443'
            volumes:
                - '/srv/source/vols/cm-gitlab/gitlab/etc:/etc/gitlab'
                - '/srv/source/vols/cm-gitlab/gitlab/logs:/var/log/gitlab'
                - '/srv/source/vols/cm-gitlab/gitlab/data/:/var/opt/gitlab'

Un des premiers service que j'ai mis en place est le service de **GIT**, évidement lors du démarrage initial j'ai pas mis toutes les configurations possible par manque de connaissance. Si nous regardons les variables ci-dessus nous voyons une liste significative disponible. 

Voici la situation à laquelle je fut confronté , j'avais mon service en place avec l'ensemble de dépôt dans mon serveur git. Je voulais activer la fonction de docker __registry__ dans __gitlab__ grâce au 4 variables suivante :

        registry['enable'] = true
        registry_external_url 'https://rg.source.x3rus.com:8443'
        gitlab_rails['registry_enabled'] = true
        gitlab_rails['registry_host'] = "rg.source.x3rus.com"

Mais pour que ces variables soit prisent en considération, il faut que je détruise mon conteneur actuellement en fonction et le recréer avec les nouvelles variables. Vous comprenez que j'ai commencé à transpirer un peu :P, j'ai fait l'ensemble de mes backups requis et je me suis dis quelle bordel :P. 

Finalement le conteneur de __gitlab__ est bien fait je n'ai rien perdu, je n'ai pas eu non plus a réimporter mes dépôts , car j'avais eu la présence d'esprit de bien suivre la documentation de __gitlab__ et que j'avais créer mes volumes adéquatement. Avec les données en dehors du conteneur le système fut en mesure de retomber sur ces pattes malgré la destruction du conteneur, incluant la Base de donnée __Postgres__ !!

Mais l'avertissement reste valide surtout pour VOS images !!

Vous devez être en mesure de configurer vos conteneurs afin qu'il soit possible de les supprimer et repartir avec d'autre variables, les données doivent donc être à l'extérieur du conteneur (volumes ou base de donnée EXTERNE). 

## <a name="FileStructure" /> Organisation des fichiers et volumes

Voici une suggestion d'organisation de structure que je vous offre, pour le moment ça fait le boulot pour moi, quand il y aura un problème j'ajusterai ...

J'ai structuré comme suit mes fichiers :

* /srv/dockers/
    * Dockerfiles/[Nom_images]/__Dockerfiles__ , __docker-compose__, ... : Ce répertoire contient pour une images donnée mes __dockerfiles__ ainsi que mes __docker-compose__. J'utilise le nom de l'image car une images peut démarrer plusieurs conteneur de même type. Cependant je veux un point de référence sur leur construction et surtout un lieu centralisé pour le démarrage incluant paramètres ...
    * Volumes/[Nom_conteneurs]/répertoires  : Ce répertoire contient les fichiers définie en volume par nom de conteneur me permettant d'avoir une structure intelligible quand je cherche quelque chose.

Avec la commande **docker ps** qui me retourne le nom de l'image et du conteneur en exécution je suis en mesure de __scripter__ des opérations autant sur l'image que sur le conteneur. 

# <a name="NetworkStructure" /> Mise en place de réseau dédié à docker

La structure de réseau présenté lors de la session dernière faisait mention de l'utilisation du réseau __Bridge__ par défaut qui vient avec le service docker.
C'est super bien d'avoir le réseau 172.17.0.0/16, mais voilà j'aime bien le réseau et la segmentation !! De plus je ne suis pas tous seul sur la machine je la partage avec un collègue , bien qu'il est possibilité d'avoir accès au conteneur en fonction, je voulais que les applications soit segmenté !!

J'ai donc utiliser l'instruction **docker network** pour créer d'autre réseau et ainsi avoir :

* Un réseau pour des application commun au 2 __sysadmins__.
* Un réseau pour mon collègue. 
* Un réseau pour moi.
* Un réseau "insécure" , pour les applications que je désire ISOLER complètement .

Ceci à générer un problème : **il n'est pas possible de linké des conteneurs dans 2 réseaux différents** .
C'est une limitation du système :-/, donc certain conteneur commun purent être utilisé avec l'option **links** du conteneur. Le gros problème est qu'il n'y a PAS d'erreur au démarrage, ça ne fonctionne simplement pas ... Ennuyant !! 
La solution à ce problème est d'utiliser l'adresse IP du conteneur, car au niveau réseau pas de problème par défaut , il est possible à une machine d'un réseau 172.18.0.5/24 de communiquer avec le réseau 172.19.0.10/24 !

## <a name="Redirect_port" /> Redirection des ports

En dehors de la mise en place de réseau dédier vous allez vouloir que vos conteneur soit disponible depuis l'extérieur, que ce soit du docker __host__ ou d'Internet directement. Je fut confronté à une réalité que je n'avais pas pensé lors de mes débuts avec __docker__ rien de dramatique, mais je vais le partager avec vous !

Petite précision sur le contexte mon serveur à des règles de __Firewall__ en entré ET en sortie ! C'est règle de __firewall__ sont définie et géré par __puppet__ afin de m'assurer qu'elles sont toujours intègre !!! En d'autre mot si une règle est ajouter manuellement au maximum 30 minutes après elle sera supprimé, car non définie dans __puppet__. 
On est jamais trop prudent :P !!

### <a name="Redirect_port_srcip" /> Détection des ip d'origine

Lors de la mise en place de docker, j'étais partie du principe que j'utiliserai le système de __docker-proxy__ pour faire la redirection des ports vers le conteneur. N'ayant pas un gros trafic l'utilisation d'un processus pour faire le travaille me semblait une bonne idée. De plus telle que mentionné plus tôt comme mes règles sont géré par __puppet__ c'était plus simple. 
Je n'ouvre que la communication pour l'IP externe puis le travail en arrière ce fait tous seul.

Ça fonctionne très bien, MAIS lors de l'analyse de mes logs du serveur web, j'ai constater une chose étrange , l'adresse IP de provenance été TOUJOURS l'IP de la passerelle de docker soit 172.17.0.1. Pour mes statistiques d'utilisation ou pour mettre en place des restrictions par adresse IP c'est une catastrophe !! 
J'ai donc du me rendre à l'évidence que je devrais mettre en place l'autre solution l'utilisation de la redirection de port (**dnat**) avec __iptables__ afin d'être en mesure d'avoir l'adresse IP source. Pour le protocole __http__ il est probable d'utiliser l'en-tête **X-Forwarded-For** , bien que je ne l'ai pas essayer je voulais avoir la connexion direct au moins pour les autres applications qui n'utilise pas le protocole __http__ par exemple __SMTP__ !

### <a name="Redictect_port_Http" /> Conteneur http utilisation des port 80/443

Autre problématique, mais ça je l'avais anticipé, l'utilisation des ports , si j'ai 3 conteneurs pour le service web , donc par exemple :

* [www.x3rus.com](http://www.x3rus.com)
* [moodle.x3rus.com](http://moodle.x3rus.com)
* [mail.x3rus.com](http://mail.x3rus.com)

C'est 3 conteneurs veulent utiliser le port 80 (au minimum) et éventuellement le port 443 , comment je vais 1 processus à la fois peut prendre 1 port sur la machine.

* Option 1 : Utiliser 3 adresses IP externe , heu ... __Ouin__ on est pas encore en __IPv6__ pas convaincu __qu'OVH__ dans mon cas sera d'accord avec l'idée
* Option 2 : Mettre un __proxy__ en avant qui réalise la redirection  , en voilà une bonne idée :D.

J'ai donc mis en place un __proxy__ avec Apache, bon là on peut me lancer des tomates autant que vous voulez disant que c'est pas optimal que apache est trop lourd pour ce type de service! Exacte je suis complètement d'accord avec mes détracteurs , mais attention je le rappel j'ai pas beaucoup de trafic le moment venu j'analyserai d'autre option. Ce que j'ai voulu en utilisant apache en avant plan, c'est  le couteau suisse que ceci m'offre. Apache offre PLEIN de possibilité module pour manipuler les requêtes __http__ et __httpS__. 

Donc voici voici une petit représentation du résultat :

![haproxy-ssl-offload.jpg](./imgs/haproxy-ssl-offload.jpg)


Je peux avoir maintenant un grand nombre de service qui sont fournit par le proxy avec comme critère :

* Un nom de domaine : __www.x3rus.com__ ou __moodle.x3rus.com__
* Un répertoire pour un sous domaine : __www.x3rus.com/cms__

### <a name="ChallangeDynIP" /> Le défis des adresse IP dynamique
## <a name="ConteneurVPNonly" /> Utilisation de conteneur exclusif au VPN

# <a name="ProbHDFull" /> Problème lors d'un disque dur remplie
## <a name="SpaceLimitConteneur" /> Limitation d'espace par conteneur
# <a name="OptDocker" /> Optimisation de Dockers
## <a name="OptDockerFS" /> Assignation d'un Volume Groupe (LVM)
## <a name="MonitoringDck" /> Monitoring du système Docker


